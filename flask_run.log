 * Serving Flask app 'app'
 * Debug mode: on
2025-12-14 18:07:18,898 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 18:07:18,898 INFO [33mPress CTRL+C to quit[0m
2025-12-14 18:07:18,899 INFO  * Restarting with stat
2025-12-14 18:07:19,001 WARNING  * Debugger is active!
2025-12-14 18:07:19,008 INFO  * Debugger PIN: 255-579-290
2025-12-14 18:07:19,701 INFO Received form responses; launching background generation
2025-12-14 18:07:19,701 INFO Background report generation started
2025-12-14 18:07:19,702 INFO 127.0.0.1 - - [14/Dec/2025 18:07:19] "POST /submit HTTP/1.1" 200 -
Starting report generation
2025-12-14 18:07:19,704 INFO Starting report generation
2025-12-14 18:07:33,595 INFO Received form responses; launching background generation
2025-12-14 18:07:33,599 INFO Background report generation started
2025-12-14 18:07:33,600 INFO 127.0.0.1 - - [14/Dec/2025 18:07:33] "POST /submit HTTP/1.1" 200 -
Starting report generation
2025-12-14 18:07:33,601 INFO Starting report generation
2025-12-14 18:08:00,902 INFO Loading faiss.
2025-12-14 18:08:01,263 INFO Successfully loaded faiss.
[nltk_data] Downloading package punkt to
[nltk_data]     /Users/nihaarikaagarwal/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt.zip.
[nltk_data] Downloading package punkt_tab to
[nltk_data]     /Users/nihaarikaagarwal/nltk_data...
[nltk_data]   Unzipping tokenizers/punkt_tab.zip.
2025-12-14 18:08:48,998 INFO Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d20,n5,w5,mc5,s0.001,t3>', 'datetime': '2025-12-14T18:08:48.976175', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'created'}
2025-12-14 18:08:48,998 INFO collecting all words and their counts
2025-12-14 18:08:48,998 INFO PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2025-12-14 18:08:49,011 INFO collected 8045 word types and 22 unique tags from a corpus of 22 examples and 182922 words
2025-12-14 18:08:49,011 INFO Creating a fresh vocabulary
2025-12-14 18:08:49,016 INFO Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 2492 unique words (30.98% of original 8045, drops 5553)', 'datetime': '2025-12-14T18:08:49.016067', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 18:08:49,016 INFO Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 174109 word corpus (95.18% of original 182922, drops 8813)', 'datetime': '2025-12-14T18:08:49.016164', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 18:08:49,022 INFO deleting the raw counts dictionary of 8045 items
2025-12-14 18:08:49,022 INFO sample=0.001 downsamples 48 most-common words
2025-12-14 18:08:49,022 INFO Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 117305.50818736776 word corpus (67.4%% of prior 174109)', 'datetime': '2025-12-14T18:08:49.022614', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 18:08:49,031 INFO estimated required memory for 2492 words and 20 dimensions: 1650880 bytes
2025-12-14 18:08:49,031 INFO resetting layer weights
2025-12-14 18:08:49,033 INFO Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 2492 vocabulary and 20 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-12-14T18:08:49.033140', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}
2025-12-14 18:08:49,056 INFO EPOCH 0: training on 182922 raw words (78566 effective words) took 0.0s, 3525128 effective words/s
2025-12-14 18:08:49,078 INFO EPOCH 1: training on 182922 raw words (78557 effective words) took 0.0s, 3653828 effective words/s
2025-12-14 18:08:49,097 INFO EPOCH 2: training on 182922 raw words (78449 effective words) took 0.0s, 4113721 effective words/s
2025-12-14 18:08:49,117 INFO EPOCH 3: training on 182922 raw words (78486 effective words) took 0.0s, 4046678 effective words/s
2025-12-14 18:08:49,136 INFO EPOCH 4: training on 182922 raw words (78540 effective words) took 0.0s, 4273830 effective words/s
2025-12-14 18:08:49,154 INFO EPOCH 5: training on 182922 raw words (78520 effective words) took 0.0s, 4249033 effective words/s
2025-12-14 18:08:49,173 INFO EPOCH 6: training on 182922 raw words (78551 effective words) took 0.0s, 4193356 effective words/s
2025-12-14 18:08:49,192 INFO EPOCH 7: training on 182922 raw words (78581 effective words) took 0.0s, 4254108 effective words/s
2025-12-14 18:08:49,211 INFO EPOCH 8: training on 182922 raw words (78558 effective words) took 0.0s, 4264377 effective words/s
2025-12-14 18:08:49,230 INFO EPOCH 9: training on 182922 raw words (78564 effective words) took 0.0s, 4194022 effective words/s
2025-12-14 18:08:49,248 INFO EPOCH 10: training on 182922 raw words (78599 effective words) took 0.0s, 4248767 effective words/s
2025-12-14 18:08:49,267 INFO EPOCH 11: training on 182922 raw words (78581 effective words) took 0.0s, 4187906 effective words/s
2025-12-14 18:08:49,286 INFO EPOCH 12: training on 182922 raw words (78503 effective words) took 0.0s, 4205265 effective words/s
2025-12-14 18:08:49,306 INFO EPOCH 13: training on 182922 raw words (78512 effective words) took 0.0s, 4090258 effective words/s
2025-12-14 18:08:49,325 INFO EPOCH 14: training on 182922 raw words (78649 effective words) took 0.0s, 4071649 effective words/s
2025-12-14 18:08:49,345 INFO EPOCH 15: training on 182922 raw words (78511 effective words) took 0.0s, 4036797 effective words/s
2025-12-14 18:08:49,365 INFO EPOCH 16: training on 182922 raw words (78496 effective words) took 0.0s, 4009151 effective words/s
2025-12-14 18:08:49,385 INFO EPOCH 17: training on 182922 raw words (78546 effective words) took 0.0s, 4073452 effective words/s
2025-12-14 18:08:49,405 INFO EPOCH 18: training on 182922 raw words (78555 effective words) took 0.0s, 3974475 effective words/s
2025-12-14 18:08:49,424 INFO EPOCH 19: training on 182922 raw words (78621 effective words) took 0.0s, 4102037 effective words/s
2025-12-14 18:08:49,443 INFO EPOCH 20: training on 182922 raw words (78694 effective words) took 0.0s, 4178748 effective words/s
2025-12-14 18:08:49,462 INFO EPOCH 21: training on 182922 raw words (78568 effective words) took 0.0s, 4119916 effective words/s
2025-12-14 18:08:49,482 INFO EPOCH 22: training on 182922 raw words (78520 effective words) took 0.0s, 4038740 effective words/s
2025-12-14 18:08:49,502 INFO EPOCH 23: training on 182922 raw words (78534 effective words) took 0.0s, 4072328 effective words/s
2025-12-14 18:08:49,521 INFO EPOCH 24: training on 182922 raw words (78626 effective words) took 0.0s, 4064348 effective words/s
2025-12-14 18:08:49,541 INFO EPOCH 25: training on 182922 raw words (78651 effective words) took 0.0s, 4309368 effective words/s
2025-12-14 18:08:49,561 INFO EPOCH 26: training on 182922 raw words (78647 effective words) took 0.0s, 4080101 effective words/s
2025-12-14 18:08:49,581 INFO EPOCH 27: training on 182922 raw words (78618 effective words) took 0.0s, 3944624 effective words/s
2025-12-14 18:08:49,602 INFO EPOCH 28: training on 182922 raw words (78610 effective words) took 0.0s, 3820695 effective words/s
2025-12-14 18:08:49,622 INFO EPOCH 29: training on 182922 raw words (78596 effective words) took 0.0s, 3959455 effective words/s
2025-12-14 18:08:49,642 INFO EPOCH 30: training on 182922 raw words (78571 effective words) took 0.0s, 4048938 effective words/s
2025-12-14 18:08:49,662 INFO EPOCH 31: training on 182922 raw words (78598 effective words) took 0.0s, 4029324 effective words/s
2025-12-14 18:08:49,682 INFO EPOCH 32: training on 182922 raw words (78604 effective words) took 0.0s, 3963169 effective words/s
2025-12-14 18:08:49,702 INFO EPOCH 33: training on 182922 raw words (78528 effective words) took 0.0s, 4056146 effective words/s
2025-12-14 18:08:49,722 INFO EPOCH 34: training on 182922 raw words (78591 effective words) took 0.0s, 4000068 effective words/s
2025-12-14 18:08:49,741 INFO EPOCH 35: training on 182922 raw words (78516 effective words) took 0.0s, 4004709 effective words/s
2025-12-14 18:08:49,762 INFO EPOCH 36: training on 182922 raw words (78628 effective words) took 0.0s, 3930540 effective words/s
2025-12-14 18:08:49,782 INFO EPOCH 37: training on 182922 raw words (78610 effective words) took 0.0s, 3979732 effective words/s
2025-12-14 18:08:49,802 INFO EPOCH 38: training on 182922 raw words (78671 effective words) took 0.0s, 4044972 effective words/s
2025-12-14 18:08:49,821 INFO EPOCH 39: training on 182922 raw words (78573 effective words) took 0.0s, 4073866 effective words/s
2025-12-14 18:08:49,843 INFO EPOCH 40: training on 182922 raw words (78475 effective words) took 0.0s, 3621477 effective words/s
2025-12-14 18:08:49,944 INFO EPOCH 41: training on 182922 raw words (78677 effective words) took 0.1s, 786732 effective words/s
2025-12-14 18:08:49,977 INFO EPOCH 42: training on 182922 raw words (78678 effective words) took 0.0s, 2462712 effective words/s
2025-12-14 18:08:49,997 INFO EPOCH 43: training on 182922 raw words (78587 effective words) took 0.0s, 3846576 effective words/s
2025-12-14 18:08:50,030 INFO EPOCH 44: training on 182922 raw words (78605 effective words) took 0.0s, 2429483 effective words/s
2025-12-14 18:08:50,053 INFO EPOCH 45: training on 182922 raw words (78594 effective words) took 0.0s, 3622087 effective words/s
2025-12-14 18:08:50,073 INFO EPOCH 46: training on 182922 raw words (78653 effective words) took 0.0s, 3924719 effective words/s
2025-12-14 18:08:50,093 INFO EPOCH 47: training on 182922 raw words (78637 effective words) took 0.0s, 4009236 effective words/s
2025-12-14 18:08:50,115 INFO EPOCH 48: training on 182922 raw words (78688 effective words) took 0.0s, 3697447 effective words/s
2025-12-14 18:08:50,134 INFO EPOCH 49: training on 182922 raw words (78570 effective words) took 0.0s, 4014742 effective words/s
2025-12-14 18:08:50,155 INFO EPOCH 50: training on 182922 raw words (78646 effective words) took 0.0s, 3870445 effective words/s
2025-12-14 18:08:50,176 INFO EPOCH 51: training on 182922 raw words (78584 effective words) took 0.0s, 3873375 effective words/s
2025-12-14 18:08:50,196 INFO EPOCH 52: training on 182922 raw words (78592 effective words) took 0.0s, 3979014 effective words/s
2025-12-14 18:08:50,218 INFO EPOCH 53: training on 182922 raw words (78616 effective words) took 0.0s, 3613885 effective words/s
2025-12-14 18:08:50,256 INFO EPOCH 54: training on 182922 raw words (78621 effective words) took 0.0s, 2081527 effective words/s
2025-12-14 18:08:50,277 INFO EPOCH 55: training on 182922 raw words (78645 effective words) took 0.0s, 3738517 effective words/s
2025-12-14 18:08:50,298 INFO EPOCH 56: training on 182922 raw words (78630 effective words) took 0.0s, 3733596 effective words/s
2025-12-14 18:08:50,319 INFO EPOCH 57: training on 182922 raw words (78649 effective words) took 0.0s, 3851198 effective words/s
2025-12-14 18:08:50,341 INFO EPOCH 58: training on 182922 raw words (78563 effective words) took 0.0s, 3657424 effective words/s
2025-12-14 18:08:50,362 INFO EPOCH 59: training on 182922 raw words (78623 effective words) took 0.0s, 3706388 effective words/s
2025-12-14 18:08:50,385 INFO EPOCH 60: training on 182922 raw words (78610 effective words) took 0.0s, 3551616 effective words/s
2025-12-14 18:08:50,406 INFO EPOCH 61: training on 182922 raw words (78612 effective words) took 0.0s, 3787633 effective words/s
2025-12-14 18:08:50,427 INFO EPOCH 62: training on 182922 raw words (78546 effective words) took 0.0s, 3875681 effective words/s
2025-12-14 18:08:50,449 INFO EPOCH 63: training on 182922 raw words (78645 effective words) took 0.0s, 3595001 effective words/s
2025-12-14 18:08:50,471 INFO EPOCH 64: training on 182922 raw words (78590 effective words) took 0.0s, 3626840 effective words/s
2025-12-14 18:08:50,493 INFO EPOCH 65: training on 182922 raw words (78542 effective words) took 0.0s, 3676300 effective words/s
2025-12-14 18:08:50,516 INFO EPOCH 66: training on 182922 raw words (78536 effective words) took 0.0s, 3439583 effective words/s
2025-12-14 18:08:50,540 INFO EPOCH 67: training on 182922 raw words (78574 effective words) took 0.0s, 3317114 effective words/s
2025-12-14 18:08:50,564 INFO EPOCH 68: training on 182922 raw words (78513 effective words) took 0.0s, 3239124 effective words/s
2025-12-14 18:08:50,588 INFO EPOCH 69: training on 182922 raw words (78576 effective words) took 0.0s, 3325141 effective words/s
2025-12-14 18:08:50,616 INFO EPOCH 70: training on 182922 raw words (78521 effective words) took 0.0s, 2913801 effective words/s
2025-12-14 18:08:50,660 INFO EPOCH 71: training on 182922 raw words (78618 effective words) took 0.0s, 1781812 effective words/s
2025-12-14 18:08:50,698 INFO EPOCH 72: training on 182922 raw words (78561 effective words) took 0.0s, 2072091 effective words/s
2025-12-14 18:08:50,722 INFO EPOCH 73: training on 182922 raw words (78509 effective words) took 0.0s, 3353408 effective words/s
2025-12-14 18:08:50,747 INFO EPOCH 74: training on 182922 raw words (78584 effective words) took 0.0s, 3198719 effective words/s
2025-12-14 18:08:50,772 INFO EPOCH 75: training on 182922 raw words (78561 effective words) took 0.0s, 3229900 effective words/s
2025-12-14 18:08:50,793 INFO EPOCH 76: training on 182922 raw words (78685 effective words) took 0.0s, 3884951 effective words/s
2025-12-14 18:08:50,815 INFO EPOCH 77: training on 182922 raw words (78648 effective words) took 0.0s, 3604544 effective words/s
2025-12-14 18:08:50,842 INFO EPOCH 78: training on 182922 raw words (78628 effective words) took 0.0s, 2974165 effective words/s
2025-12-14 18:08:50,863 INFO EPOCH 79: training on 182922 raw words (78717 effective words) took 0.0s, 3806654 effective words/s
2025-12-14 18:08:50,884 INFO EPOCH 80: training on 182922 raw words (78561 effective words) took 0.0s, 3802059 effective words/s
2025-12-14 18:08:50,906 INFO EPOCH 81: training on 182922 raw words (78644 effective words) took 0.0s, 3660407 effective words/s
2025-12-14 18:08:50,927 INFO EPOCH 82: training on 182922 raw words (78555 effective words) took 0.0s, 3769366 effective words/s
2025-12-14 18:08:50,948 INFO EPOCH 83: training on 182922 raw words (78565 effective words) took 0.0s, 3871469 effective words/s
2025-12-14 18:08:50,968 INFO EPOCH 84: training on 182922 raw words (78605 effective words) took 0.0s, 3938422 effective words/s
2025-12-14 18:08:50,989 INFO EPOCH 85: training on 182922 raw words (78569 effective words) took 0.0s, 3771078 effective words/s
2025-12-14 18:08:51,010 INFO EPOCH 86: training on 182922 raw words (78559 effective words) took 0.0s, 3952969 effective words/s
2025-12-14 18:08:51,029 INFO EPOCH 87: training on 182922 raw words (78595 effective words) took 0.0s, 4032590 effective words/s
2025-12-14 18:08:51,049 INFO EPOCH 88: training on 182922 raw words (78537 effective words) took 0.0s, 4050317 effective words/s
2025-12-14 18:08:51,069 INFO EPOCH 89: training on 182922 raw words (78584 effective words) took 0.0s, 3922483 effective words/s
2025-12-14 18:08:51,090 INFO EPOCH 90: training on 182922 raw words (78642 effective words) took 0.0s, 3906690 effective words/s
2025-12-14 18:08:51,111 INFO EPOCH 91: training on 182922 raw words (78643 effective words) took 0.0s, 3820109 effective words/s
2025-12-14 18:08:51,131 INFO EPOCH 92: training on 182922 raw words (78593 effective words) took 0.0s, 3889050 effective words/s
2025-12-14 18:08:51,152 INFO EPOCH 93: training on 182922 raw words (78611 effective words) took 0.0s, 3827293 effective words/s
2025-12-14 18:08:51,172 INFO EPOCH 94: training on 182922 raw words (78600 effective words) took 0.0s, 4019347 effective words/s
2025-12-14 18:08:51,201 INFO EPOCH 95: training on 182922 raw words (78528 effective words) took 0.0s, 2708730 effective words/s
2025-12-14 18:08:51,222 INFO EPOCH 96: training on 182922 raw words (78539 effective words) took 0.0s, 3847389 effective words/s
2025-12-14 18:08:51,243 INFO EPOCH 97: training on 182922 raw words (78512 effective words) took 0.0s, 3849933 effective words/s
2025-12-14 18:08:51,263 INFO EPOCH 98: training on 182922 raw words (78618 effective words) took 0.0s, 3858986 effective words/s
2025-12-14 18:08:51,284 INFO EPOCH 99: training on 182922 raw words (78638 effective words) took 0.0s, 3862290 effective words/s
2025-12-14 18:08:51,304 INFO EPOCH 100: training on 182922 raw words (78517 effective words) took 0.0s, 3908498 effective words/s
2025-12-14 18:08:51,325 INFO EPOCH 101: training on 182922 raw words (78555 effective words) took 0.0s, 3873767 effective words/s
2025-12-14 18:08:51,345 INFO EPOCH 102: training on 182922 raw words (78541 effective words) took 0.0s, 4016176 effective words/s
2025-12-14 18:08:51,364 INFO EPOCH 103: training on 182922 raw words (78593 effective words) took 0.0s, 4072704 effective words/s
2025-12-14 18:08:51,385 INFO EPOCH 104: training on 182922 raw words (78636 effective words) took 0.0s, 3956595 effective words/s
2025-12-14 18:08:51,404 INFO EPOCH 105: training on 182922 raw words (78670 effective words) took 0.0s, 4057054 effective words/s
2025-12-14 18:08:51,424 INFO EPOCH 106: training on 182922 raw words (78529 effective words) took 0.0s, 3994422 effective words/s
2025-12-14 18:08:51,444 INFO EPOCH 107: training on 182922 raw words (78563 effective words) took 0.0s, 4038001 effective words/s
2025-12-14 18:08:51,464 INFO EPOCH 108: training on 182922 raw words (78592 effective words) took 0.0s, 4000254 effective words/s
2025-12-14 18:08:51,484 INFO EPOCH 109: training on 182922 raw words (78592 effective words) took 0.0s, 3970371 effective words/s
2025-12-14 18:08:51,503 INFO EPOCH 110: training on 182922 raw words (78511 effective words) took 0.0s, 4036746 effective words/s
2025-12-14 18:08:51,523 INFO EPOCH 111: training on 182922 raw words (78614 effective words) took 0.0s, 3965797 effective words/s
2025-12-14 18:08:51,544 INFO EPOCH 112: training on 182922 raw words (78590 effective words) took 0.0s, 3838644 effective words/s
2025-12-14 18:08:51,564 INFO EPOCH 113: training on 182922 raw words (78586 effective words) took 0.0s, 3935835 effective words/s
2025-12-14 18:08:51,584 INFO EPOCH 114: training on 182922 raw words (78584 effective words) took 0.0s, 3992269 effective words/s
2025-12-14 18:08:51,605 INFO EPOCH 115: training on 182922 raw words (78625 effective words) took 0.0s, 3781381 effective words/s
2025-12-14 18:08:51,626 INFO EPOCH 116: training on 182922 raw words (78584 effective words) took 0.0s, 3849452 effective words/s
2025-12-14 18:08:51,647 INFO EPOCH 117: training on 182922 raw words (78662 effective words) took 0.0s, 3801604 effective words/s
2025-12-14 18:08:51,668 INFO EPOCH 118: training on 182922 raw words (78623 effective words) took 0.0s, 3877479 effective words/s
2025-12-14 18:08:51,739 INFO EPOCH 119: training on 182922 raw words (78590 effective words) took 0.1s, 1114441 effective words/s
2025-12-14 18:08:51,767 INFO EPOCH 120: training on 182922 raw words (78637 effective words) took 0.0s, 2882341 effective words/s
2025-12-14 18:08:51,787 INFO EPOCH 121: training on 182922 raw words (78641 effective words) took 0.0s, 3883834 effective words/s
2025-12-14 18:08:51,808 INFO EPOCH 122: training on 182922 raw words (78565 effective words) took 0.0s, 3846645 effective words/s
2025-12-14 18:08:51,828 INFO EPOCH 123: training on 182922 raw words (78631 effective words) took 0.0s, 3982451 effective words/s
2025-12-14 18:08:51,848 INFO EPOCH 124: training on 182922 raw words (78554 effective words) took 0.0s, 4039216 effective words/s
2025-12-14 18:08:51,869 INFO EPOCH 125: training on 182922 raw words (78704 effective words) took 0.0s, 3788179 effective words/s
2025-12-14 18:08:51,889 INFO EPOCH 126: training on 182922 raw words (78490 effective words) took 0.0s, 3992785 effective words/s
2025-12-14 18:08:51,909 INFO EPOCH 127: training on 182922 raw words (78574 effective words) took 0.0s, 3956362 effective words/s
2025-12-14 18:08:51,931 INFO EPOCH 128: training on 182922 raw words (78626 effective words) took 0.0s, 3635835 effective words/s
2025-12-14 18:08:51,952 INFO EPOCH 129: training on 182922 raw words (78560 effective words) took 0.0s, 3753307 effective words/s
2025-12-14 18:08:51,972 INFO EPOCH 130: training on 182922 raw words (78577 effective words) took 0.0s, 3979884 effective words/s
2025-12-14 18:08:51,992 INFO EPOCH 131: training on 182922 raw words (78616 effective words) took 0.0s, 4037819 effective words/s
2025-12-14 18:08:52,012 INFO EPOCH 132: training on 182922 raw words (78574 effective words) took 0.0s, 4010370 effective words/s
2025-12-14 18:08:52,031 INFO EPOCH 133: training on 182922 raw words (78517 effective words) took 0.0s, 4029319 effective words/s
2025-12-14 18:08:52,051 INFO EPOCH 134: training on 182922 raw words (78660 effective words) took 0.0s, 4052507 effective words/s
2025-12-14 18:08:52,071 INFO EPOCH 135: training on 182922 raw words (78565 effective words) took 0.0s, 3980628 effective words/s
2025-12-14 18:08:52,091 INFO EPOCH 136: training on 182922 raw words (78480 effective words) took 0.0s, 4009076 effective words/s
2025-12-14 18:08:52,111 INFO EPOCH 137: training on 182922 raw words (78582 effective words) took 0.0s, 3898763 effective words/s
2025-12-14 18:08:52,132 INFO EPOCH 138: training on 182922 raw words (78655 effective words) took 0.0s, 3858301 effective words/s
2025-12-14 18:08:52,153 INFO EPOCH 139: training on 182922 raw words (78610 effective words) took 0.0s, 3888809 effective words/s
2025-12-14 18:08:52,173 INFO EPOCH 140: training on 182922 raw words (78621 effective words) took 0.0s, 3854246 effective words/s
2025-12-14 18:08:52,194 INFO EPOCH 141: training on 182922 raw words (78630 effective words) took 0.0s, 3888892 effective words/s
2025-12-14 18:08:52,215 INFO EPOCH 142: training on 182922 raw words (78663 effective words) took 0.0s, 3762715 effective words/s
2025-12-14 18:08:52,235 INFO EPOCH 143: training on 182922 raw words (78637 effective words) took 0.0s, 3976084 effective words/s
2025-12-14 18:08:52,255 INFO EPOCH 144: training on 182922 raw words (78586 effective words) took 0.0s, 4027237 effective words/s
2025-12-14 18:08:52,275 INFO EPOCH 145: training on 182922 raw words (78719 effective words) took 0.0s, 3936901 effective words/s
2025-12-14 18:08:52,295 INFO EPOCH 146: training on 182922 raw words (78587 effective words) took 0.0s, 4003507 effective words/s
2025-12-14 18:08:52,315 INFO EPOCH 147: training on 182922 raw words (78723 effective words) took 0.0s, 3881494 effective words/s
2025-12-14 18:08:52,335 INFO EPOCH 148: training on 182922 raw words (78556 effective words) took 0.0s, 4008666 effective words/s
2025-12-14 18:08:52,355 INFO EPOCH 149: training on 182922 raw words (78633 effective words) took 0.0s, 3998627 effective words/s
2025-12-14 18:08:52,376 INFO EPOCH 150: training on 182922 raw words (78688 effective words) took 0.0s, 3854712 effective words/s
2025-12-14 18:08:52,396 INFO EPOCH 151: training on 182922 raw words (78656 effective words) took 0.0s, 3898195 effective words/s
2025-12-14 18:08:52,417 INFO EPOCH 152: training on 182922 raw words (78628 effective words) took 0.0s, 3800137 effective words/s
2025-12-14 18:08:52,438 INFO EPOCH 153: training on 182922 raw words (78651 effective words) took 0.0s, 3883680 effective words/s
2025-12-14 18:08:52,458 INFO EPOCH 154: training on 182922 raw words (78647 effective words) took 0.0s, 3885281 effective words/s
2025-12-14 18:08:52,479 INFO EPOCH 155: training on 182922 raw words (78613 effective words) took 0.0s, 3907943 effective words/s
2025-12-14 18:08:52,499 INFO EPOCH 156: training on 182922 raw words (78601 effective words) took 0.0s, 4004645 effective words/s
2025-12-14 18:08:52,519 INFO EPOCH 157: training on 182922 raw words (78573 effective words) took 0.0s, 4031995 effective words/s
2025-12-14 18:08:52,539 INFO EPOCH 158: training on 182922 raw words (78626 effective words) took 0.0s, 3926670 effective words/s
2025-12-14 18:08:52,559 INFO EPOCH 159: training on 182922 raw words (78591 effective words) took 0.0s, 4040651 effective words/s
2025-12-14 18:08:52,579 INFO EPOCH 160: training on 182922 raw words (78623 effective words) took 0.0s, 3968095 effective words/s
2025-12-14 18:08:52,599 INFO EPOCH 161: training on 182922 raw words (78611 effective words) took 0.0s, 3972050 effective words/s
2025-12-14 18:08:52,618 INFO EPOCH 162: training on 182922 raw words (78663 effective words) took 0.0s, 4058830 effective words/s
2025-12-14 18:08:52,638 INFO EPOCH 163: training on 182922 raw words (78626 effective words) took 0.0s, 4021850 effective words/s
2025-12-14 18:08:52,658 INFO EPOCH 164: training on 182922 raw words (78604 effective words) took 0.0s, 3947297 effective words/s
2025-12-14 18:08:52,678 INFO EPOCH 165: training on 182922 raw words (78566 effective words) took 0.0s, 3988417 effective words/s
2025-12-14 18:08:52,699 INFO EPOCH 166: training on 182922 raw words (78540 effective words) took 0.0s, 3851369 effective words/s
2025-12-14 18:08:52,719 INFO EPOCH 167: training on 182922 raw words (78589 effective words) took 0.0s, 4021235 effective words/s
2025-12-14 18:08:52,739 INFO EPOCH 168: training on 182922 raw words (78524 effective words) took 0.0s, 3978660 effective words/s
2025-12-14 18:08:52,759 INFO EPOCH 169: training on 182922 raw words (78518 effective words) took 0.0s, 3941411 effective words/s
2025-12-14 18:08:52,779 INFO EPOCH 170: training on 182922 raw words (78499 effective words) took 0.0s, 3922694 effective words/s
2025-12-14 18:08:52,800 INFO EPOCH 171: training on 182922 raw words (78591 effective words) took 0.0s, 3813007 effective words/s
2025-12-14 18:08:52,820 INFO EPOCH 172: training on 182922 raw words (78645 effective words) took 0.0s, 3937853 effective words/s
2025-12-14 18:08:52,842 INFO EPOCH 173: training on 182922 raw words (78668 effective words) took 0.0s, 3657184 effective words/s
2025-12-14 18:08:52,863 INFO EPOCH 174: training on 182922 raw words (78556 effective words) took 0.0s, 3917989 effective words/s
2025-12-14 18:08:52,884 INFO EPOCH 175: training on 182922 raw words (78632 effective words) took 0.0s, 3797004 effective words/s
2025-12-14 18:08:52,904 INFO EPOCH 176: training on 182922 raw words (78536 effective words) took 0.0s, 3934448 effective words/s
2025-12-14 18:08:52,925 INFO EPOCH 177: training on 182922 raw words (78631 effective words) took 0.0s, 3846722 effective words/s
2025-12-14 18:08:52,945 INFO EPOCH 178: training on 182922 raw words (78598 effective words) took 0.0s, 3970858 effective words/s
2025-12-14 18:08:52,966 INFO EPOCH 179: training on 182922 raw words (78585 effective words) took 0.0s, 3797080 effective words/s
2025-12-14 18:08:52,987 INFO EPOCH 180: training on 182922 raw words (78639 effective words) took 0.0s, 3834023 effective words/s
2025-12-14 18:08:53,007 INFO EPOCH 181: training on 182922 raw words (78593 effective words) took 0.0s, 3995264 effective words/s
2025-12-14 18:08:53,026 INFO EPOCH 182: training on 182922 raw words (78546 effective words) took 0.0s, 3994076 effective words/s
2025-12-14 18:08:53,047 INFO EPOCH 183: training on 182922 raw words (78555 effective words) took 0.0s, 3907618 effective words/s
2025-12-14 18:08:53,067 INFO EPOCH 184: training on 182922 raw words (78763 effective words) took 0.0s, 4003914 effective words/s
2025-12-14 18:08:53,087 INFO EPOCH 185: training on 182922 raw words (78538 effective words) took 0.0s, 3878779 effective words/s
2025-12-14 18:08:53,108 INFO EPOCH 186: training on 182922 raw words (78678 effective words) took 0.0s, 3789618 effective words/s
2025-12-14 18:08:53,129 INFO EPOCH 187: training on 182922 raw words (78651 effective words) took 0.0s, 3909338 effective words/s
2025-12-14 18:08:53,149 INFO EPOCH 188: training on 182922 raw words (78552 effective words) took 0.0s, 3969687 effective words/s
2025-12-14 18:08:53,170 INFO EPOCH 189: training on 182922 raw words (78576 effective words) took 0.0s, 3798901 effective words/s
2025-12-14 18:08:53,191 INFO EPOCH 190: training on 182922 raw words (78593 effective words) took 0.0s, 3789288 effective words/s
2025-12-14 18:08:53,211 INFO EPOCH 191: training on 182922 raw words (78617 effective words) took 0.0s, 3978333 effective words/s
2025-12-14 18:08:53,231 INFO EPOCH 192: training on 182922 raw words (78575 effective words) took 0.0s, 3890526 effective words/s
2025-12-14 18:08:53,252 INFO EPOCH 193: training on 182922 raw words (78587 effective words) took 0.0s, 3921719 effective words/s
2025-12-14 18:08:53,272 INFO EPOCH 194: training on 182922 raw words (78597 effective words) took 0.0s, 3929261 effective words/s
2025-12-14 18:08:53,294 INFO EPOCH 195: training on 182922 raw words (78612 effective words) took 0.0s, 3577772 effective words/s
2025-12-14 18:08:53,316 INFO EPOCH 196: training on 182922 raw words (78565 effective words) took 0.0s, 3703414 effective words/s
2025-12-14 18:08:53,341 INFO EPOCH 197: training on 182922 raw words (78553 effective words) took 0.0s, 3146420 effective words/s
2025-12-14 18:08:53,362 INFO EPOCH 198: training on 182922 raw words (78540 effective words) took 0.0s, 3893339 effective words/s
2025-12-14 18:08:53,383 INFO EPOCH 199: training on 182922 raw words (78564 effective words) took 0.0s, 3740742 effective words/s
2025-12-14 18:08:53,403 INFO EPOCH 200: training on 182922 raw words (78614 effective words) took 0.0s, 3956160 effective words/s
2025-12-14 18:08:53,427 INFO EPOCH 201: training on 182922 raw words (78607 effective words) took 0.0s, 3259171 effective words/s
2025-12-14 18:08:53,451 INFO EPOCH 202: training on 182922 raw words (78677 effective words) took 0.0s, 3429300 effective words/s
2025-12-14 18:08:53,471 INFO EPOCH 203: training on 182922 raw words (78640 effective words) took 0.0s, 3932008 effective words/s
2025-12-14 18:08:53,493 INFO EPOCH 204: training on 182922 raw words (78703 effective words) took 0.0s, 3594455 effective words/s
2025-12-14 18:08:53,515 INFO EPOCH 205: training on 182922 raw words (78646 effective words) took 0.0s, 3701373 effective words/s
2025-12-14 18:08:53,538 INFO EPOCH 206: training on 182922 raw words (78692 effective words) took 0.0s, 3516424 effective words/s
2025-12-14 18:08:53,558 INFO EPOCH 207: training on 182922 raw words (78614 effective words) took 0.0s, 3888606 effective words/s
2025-12-14 18:08:53,579 INFO EPOCH 208: training on 182922 raw words (78538 effective words) took 0.0s, 3848503 effective words/s
2025-12-14 18:08:53,599 INFO EPOCH 209: training on 182922 raw words (78613 effective words) took 0.0s, 3881325 effective words/s
2025-12-14 18:08:53,621 INFO EPOCH 210: training on 182922 raw words (78650 effective words) took 0.0s, 3672631 effective words/s
2025-12-14 18:08:53,642 INFO EPOCH 211: training on 182922 raw words (78626 effective words) took 0.0s, 3827914 effective words/s
2025-12-14 18:08:53,662 INFO EPOCH 212: training on 182922 raw words (78593 effective words) took 0.0s, 3925773 effective words/s
2025-12-14 18:08:53,683 INFO EPOCH 213: training on 182922 raw words (78663 effective words) took 0.0s, 3821437 effective words/s
2025-12-14 18:08:53,705 INFO EPOCH 214: training on 182922 raw words (78526 effective words) took 0.0s, 3652018 effective words/s
2025-12-14 18:08:53,726 INFO EPOCH 215: training on 182922 raw words (78666 effective words) took 0.0s, 3836110 effective words/s
2025-12-14 18:08:53,746 INFO EPOCH 216: training on 182922 raw words (78600 effective words) took 0.0s, 3907969 effective words/s
2025-12-14 18:08:53,767 INFO EPOCH 217: training on 182922 raw words (78675 effective words) took 0.0s, 3898139 effective words/s
2025-12-14 18:08:53,788 INFO EPOCH 218: training on 182922 raw words (78570 effective words) took 0.0s, 3822087 effective words/s
2025-12-14 18:08:53,850 INFO EPOCH 219: training on 182922 raw words (78573 effective words) took 0.1s, 1264996 effective words/s
2025-12-14 18:08:53,875 INFO EPOCH 220: training on 182922 raw words (78504 effective words) took 0.0s, 3184472 effective words/s
2025-12-14 18:08:53,905 INFO EPOCH 221: training on 182922 raw words (78557 effective words) took 0.0s, 2662205 effective words/s
2025-12-14 18:08:53,925 INFO EPOCH 222: training on 182922 raw words (78612 effective words) took 0.0s, 4013214 effective words/s
2025-12-14 18:08:53,945 INFO EPOCH 223: training on 182922 raw words (78577 effective words) took 0.0s, 3920315 effective words/s
2025-12-14 18:08:53,965 INFO EPOCH 224: training on 182922 raw words (78537 effective words) took 0.0s, 3984198 effective words/s
2025-12-14 18:08:53,985 INFO EPOCH 225: training on 182922 raw words (78565 effective words) took 0.0s, 4024915 effective words/s
2025-12-14 18:08:54,005 INFO EPOCH 226: training on 182922 raw words (78610 effective words) took 0.0s, 3956854 effective words/s
2025-12-14 18:08:54,026 INFO EPOCH 227: training on 182922 raw words (78630 effective words) took 0.0s, 3809224 effective words/s
2025-12-14 18:08:54,046 INFO EPOCH 228: training on 182922 raw words (78557 effective words) took 0.0s, 3864251 effective words/s
2025-12-14 18:08:54,067 INFO EPOCH 229: training on 182922 raw words (78492 effective words) took 0.0s, 3965068 effective words/s
2025-12-14 18:08:54,087 INFO EPOCH 230: training on 182922 raw words (78562 effective words) took 0.0s, 3814993 effective words/s
2025-12-14 18:08:54,108 INFO EPOCH 231: training on 182922 raw words (78528 effective words) took 0.0s, 3895906 effective words/s
2025-12-14 18:08:54,128 INFO EPOCH 232: training on 182922 raw words (78573 effective words) took 0.0s, 3946715 effective words/s
2025-12-14 18:08:54,149 INFO EPOCH 233: training on 182922 raw words (78532 effective words) took 0.0s, 3803993 effective words/s
2025-12-14 18:08:54,169 INFO EPOCH 234: training on 182922 raw words (78572 effective words) took 0.0s, 3942275 effective words/s
2025-12-14 18:08:54,189 INFO EPOCH 235: training on 182922 raw words (78601 effective words) took 0.0s, 4020572 effective words/s
2025-12-14 18:08:54,209 INFO EPOCH 236: training on 182922 raw words (78588 effective words) took 0.0s, 4041129 effective words/s
2025-12-14 18:08:54,229 INFO EPOCH 237: training on 182922 raw words (78657 effective words) took 0.0s, 3962012 effective words/s
2025-12-14 18:08:54,251 INFO EPOCH 238: training on 182922 raw words (78599 effective words) took 0.0s, 3671485 effective words/s
2025-12-14 18:08:54,271 INFO EPOCH 239: training on 182922 raw words (78650 effective words) took 0.0s, 3881267 effective words/s
2025-12-14 18:08:54,292 INFO EPOCH 240: training on 182922 raw words (78552 effective words) took 0.0s, 3849393 effective words/s
2025-12-14 18:08:54,312 INFO EPOCH 241: training on 182922 raw words (78573 effective words) took 0.0s, 3968099 effective words/s
2025-12-14 18:08:54,332 INFO EPOCH 242: training on 182922 raw words (78611 effective words) took 0.0s, 3902113 effective words/s
2025-12-14 18:08:54,352 INFO EPOCH 243: training on 182922 raw words (78568 effective words) took 0.0s, 3997431 effective words/s
2025-12-14 18:08:54,372 INFO EPOCH 244: training on 182922 raw words (78519 effective words) took 0.0s, 4028923 effective words/s
2025-12-14 18:08:54,392 INFO EPOCH 245: training on 182922 raw words (78565 effective words) took 0.0s, 3964667 effective words/s
2025-12-14 18:08:54,413 INFO EPOCH 246: training on 182922 raw words (78670 effective words) took 0.0s, 3909748 effective words/s
2025-12-14 18:08:54,433 INFO EPOCH 247: training on 182922 raw words (78644 effective words) took 0.0s, 3808810 effective words/s
2025-12-14 18:08:54,454 INFO EPOCH 248: training on 182922 raw words (78680 effective words) took 0.0s, 3893395 effective words/s
2025-12-14 18:08:54,475 INFO EPOCH 249: training on 182922 raw words (78569 effective words) took 0.0s, 3856620 effective words/s
2025-12-14 18:08:54,495 INFO EPOCH 250: training on 182922 raw words (78566 effective words) took 0.0s, 3859773 effective words/s
2025-12-14 18:08:54,516 INFO EPOCH 251: training on 182922 raw words (78619 effective words) took 0.0s, 3807292 effective words/s
2025-12-14 18:08:54,537 INFO EPOCH 252: training on 182922 raw words (78584 effective words) took 0.0s, 3864304 effective words/s
2025-12-14 18:08:54,558 INFO EPOCH 253: training on 182922 raw words (78596 effective words) took 0.0s, 3873235 effective words/s
2025-12-14 18:08:54,578 INFO EPOCH 254: training on 182922 raw words (78580 effective words) took 0.0s, 4003396 effective words/s
2025-12-14 18:08:54,598 INFO EPOCH 255: training on 182922 raw words (78587 effective words) took 0.0s, 3967671 effective words/s
2025-12-14 18:08:54,617 INFO EPOCH 256: training on 182922 raw words (78612 effective words) took 0.0s, 3998372 effective words/s
2025-12-14 18:08:54,637 INFO EPOCH 257: training on 182922 raw words (78603 effective words) took 0.0s, 4003812 effective words/s
2025-12-14 18:08:54,658 INFO EPOCH 258: training on 182922 raw words (78612 effective words) took 0.0s, 3926273 effective words/s
2025-12-14 18:08:54,677 INFO EPOCH 259: training on 182922 raw words (78686 effective words) took 0.0s, 4031045 effective words/s
2025-12-14 18:08:54,697 INFO EPOCH 260: training on 182922 raw words (78610 effective words) took 0.0s, 4006269 effective words/s
2025-12-14 18:08:54,718 INFO EPOCH 261: training on 182922 raw words (78609 effective words) took 0.0s, 3841581 effective words/s
2025-12-14 18:08:54,739 INFO EPOCH 262: training on 182922 raw words (78553 effective words) took 0.0s, 3806339 effective words/s
2025-12-14 18:08:54,790 INFO EPOCH 263: training on 182922 raw words (78592 effective words) took 0.1s, 1546038 effective words/s
2025-12-14 18:08:54,818 INFO EPOCH 264: training on 182922 raw words (78637 effective words) took 0.0s, 2862272 effective words/s
2025-12-14 18:08:54,839 INFO EPOCH 265: training on 182922 raw words (78463 effective words) took 0.0s, 3854429 effective words/s
2025-12-14 18:08:54,859 INFO EPOCH 266: training on 182922 raw words (78641 effective words) took 0.0s, 3935280 effective words/s
2025-12-14 18:08:54,879 INFO EPOCH 267: training on 182922 raw words (78594 effective words) took 0.0s, 3868989 effective words/s
2025-12-14 18:08:54,900 INFO EPOCH 268: training on 182922 raw words (78458 effective words) took 0.0s, 3945562 effective words/s
2025-12-14 18:08:54,921 INFO EPOCH 269: training on 182922 raw words (78543 effective words) took 0.0s, 3748957 effective words/s
2025-12-14 18:08:54,942 INFO EPOCH 270: training on 182922 raw words (78585 effective words) took 0.0s, 3809489 effective words/s
2025-12-14 18:08:54,962 INFO EPOCH 271: training on 182922 raw words (78453 effective words) took 0.0s, 3860686 effective words/s
2025-12-14 18:08:54,983 INFO EPOCH 272: training on 182922 raw words (78659 effective words) took 0.0s, 3928130 effective words/s
2025-12-14 18:08:55,004 INFO EPOCH 273: training on 182922 raw words (78649 effective words) took 0.0s, 3805720 effective words/s
2025-12-14 18:08:55,024 INFO EPOCH 274: training on 182922 raw words (78596 effective words) took 0.0s, 3834395 effective words/s
2025-12-14 18:08:55,046 INFO EPOCH 275: training on 182922 raw words (78463 effective words) took 0.0s, 3720301 effective words/s
2025-12-14 18:08:55,066 INFO EPOCH 276: training on 182922 raw words (78530 effective words) took 0.0s, 3939163 effective words/s
2025-12-14 18:08:55,086 INFO EPOCH 277: training on 182922 raw words (78538 effective words) took 0.0s, 3920488 effective words/s
2025-12-14 18:08:55,107 INFO EPOCH 278: training on 182922 raw words (78691 effective words) took 0.0s, 3877407 effective words/s
2025-12-14 18:08:55,128 INFO EPOCH 279: training on 182922 raw words (78496 effective words) took 0.0s, 3899833 effective words/s
2025-12-14 18:08:55,148 INFO EPOCH 280: training on 182922 raw words (78689 effective words) took 0.0s, 3935221 effective words/s
2025-12-14 18:08:55,169 INFO EPOCH 281: training on 182922 raw words (78592 effective words) took 0.0s, 3764067 effective words/s
2025-12-14 18:08:55,189 INFO EPOCH 282: training on 182922 raw words (78520 effective words) took 0.0s, 3936933 effective words/s
2025-12-14 18:08:55,209 INFO EPOCH 283: training on 182922 raw words (78630 effective words) took 0.0s, 3939124 effective words/s
2025-12-14 18:08:55,229 INFO EPOCH 284: training on 182922 raw words (78475 effective words) took 0.0s, 4036529 effective words/s
2025-12-14 18:08:55,249 INFO EPOCH 285: training on 182922 raw words (78634 effective words) took 0.0s, 4037905 effective words/s
2025-12-14 18:08:55,269 INFO EPOCH 286: training on 182922 raw words (78612 effective words) took 0.0s, 3938830 effective words/s
2025-12-14 18:08:55,289 INFO EPOCH 287: training on 182922 raw words (78667 effective words) took 0.0s, 3991257 effective words/s
2025-12-14 18:08:55,309 INFO EPOCH 288: training on 182922 raw words (78558 effective words) took 0.0s, 3963547 effective words/s
2025-12-14 18:08:55,329 INFO EPOCH 289: training on 182922 raw words (78540 effective words) took 0.0s, 4036023 effective words/s
2025-12-14 18:08:55,349 INFO EPOCH 290: training on 182922 raw words (78611 effective words) took 0.0s, 4030403 effective words/s
2025-12-14 18:08:55,370 INFO EPOCH 291: training on 182922 raw words (78553 effective words) took 0.0s, 3659862 effective words/s
2025-12-14 18:08:55,404 INFO EPOCH 292: training on 182922 raw words (78609 effective words) took 0.0s, 2457046 effective words/s
2025-12-14 18:08:55,456 INFO EPOCH 293: training on 182922 raw words (78613 effective words) took 0.1s, 1506674 effective words/s
2025-12-14 18:08:55,488 INFO EPOCH 294: training on 182922 raw words (78488 effective words) took 0.0s, 2912487 effective words/s
2025-12-14 18:08:55,508 INFO EPOCH 295: training on 182922 raw words (78538 effective words) took 0.0s, 3907630 effective words/s
2025-12-14 18:08:55,535 INFO EPOCH 296: training on 182922 raw words (78567 effective words) took 0.0s, 2968989 effective words/s
2025-12-14 18:08:55,557 INFO EPOCH 297: training on 182922 raw words (78569 effective words) took 0.0s, 3536582 effective words/s
2025-12-14 18:08:55,584 INFO EPOCH 298: training on 182922 raw words (78613 effective words) took 0.0s, 2925203 effective words/s
2025-12-14 18:08:55,608 INFO EPOCH 299: training on 182922 raw words (78563 effective words) took 0.0s, 3431567 effective words/s
2025-12-14 18:08:55,608 INFO Doc2Vec lifecycle event {'msg': 'training on 54876600 raw words (23577595 effective words) took 6.6s, 3585932 effective words/s', 'datetime': '2025-12-14T18:08:55.608279', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}
2025-12-14 18:08:55,608 INFO Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_model.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-12-14T18:08:55.608411', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'saving'}
2025-12-14 18:08:55,608 INFO not storing attribute cum_table
2025-12-14 18:08:55,610 INFO saved doc2vec_model.model
2025-12-14 18:08:55,613 INFO loading Doc2Vec object from doc2vec_model.model
2025-12-14 18:08:55,613 INFO loading Doc2Vec object from doc2vec_model.model
2025-12-14 18:08:55,617 INFO loading dv recursively from doc2vec_model.model.dv.* with mmap=None
2025-12-14 18:08:55,617 INFO loading dv recursively from doc2vec_model.model.dv.* with mmap=None
2025-12-14 18:08:55,617 INFO loading wv recursively from doc2vec_model.model.wv.* with mmap=None
2025-12-14 18:08:55,617 INFO loading wv recursively from doc2vec_model.model.wv.* with mmap=None
2025-12-14 18:08:55,617 INFO setting ignored attribute cum_table to None
2025-12-14 18:08:55,617 INFO setting ignored attribute cum_table to None
2025-12-14 18:08:55,625 INFO Doc2Vec lifecycle event {'fname': 'doc2vec_model.model', 'datetime': '2025-12-14T18:08:55.625387', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}
2025-12-14 18:08:55,633 INFO Doc2Vec lifecycle event {'fname': 'doc2vec_model.model', 'datetime': '2025-12-14T18:08:55.633440', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}
Loaded Doc2Vec model
Loaded Doc2Vec model
2025-12-14 18:08:55,633 INFO Loaded Doc2Vec model
2025-12-14 18:08:55,633 INFO Loaded Doc2Vec model
Loaded FAISS index
Loaded FAISS index
2025-12-14 18:08:55,634 INFO Loaded FAISS index
2025-12-14 18:08:55,634 INFO Loaded FAISS index
W1214 18:09:02.319000 74470 .venv310/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.
Initializing pipeline (device cuda? False)
Initializing pipeline (device cuda? False)
2025-12-14 18:09:02,379 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:09:02,379 INFO Initializing pipeline (device cuda? False)
LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f5faf-606cb53c4c22afc86f3feead;0bfcd43e-fc3f-4803-b57c-aa707bc175fe)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 102, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f5faf-606cb53c4c22afc86f3feead;0bfcd43e-fc3f-4803-b57c-aa707bc175fe)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:09:03,469 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f5faf-606cb53c4c22afc86f3feead;0bfcd43e-fc3f-4803-b57c-aa707bc175fe)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 102, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f5faf-606cb53c4c22afc86f3feead;0bfcd43e-fc3f-4803-b57c-aa707bc175fe)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
Processing question 1
2025-12-14 18:09:03,483 INFO Processing question 1
Processing question 2
2025-12-14 18:09:03,487 INFO Processing question 2
Processing question 3
2025-12-14 18:09:03,491 INFO Processing question 3
Processing question 4
2025-12-14 18:09:03,494 INFO Processing question 4
Processing question 5
2025-12-14 18:09:03,497 INFO Processing question 5
Processing question 6
2025-12-14 18:09:03,500 INFO Processing question 6
Processing question 7
2025-12-14 18:09:03,503 INFO Processing question 7
Processing question 8
2025-12-14 18:09:03,506 INFO Processing question 8
Processing question 9
2025-12-14 18:09:03,509 INFO Processing question 9
Processing question 10
2025-12-14 18:09:03,511 INFO Processing question 10
Processing question 11
2025-12-14 18:09:03,514 INFO Processing question 11
Processing question 12
2025-12-14 18:09:03,516 INFO Processing question 12
Processing question 13
2025-12-14 18:09:03,519 INFO Processing question 13
Processing question 14
2025-12-14 18:09:03,521 INFO Processing question 14
Processing question 15
2025-12-14 18:09:03,524 INFO Processing question 15
Wrote analysis to ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:09:03,524 INFO Wrote analysis to ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:09:03,524 INFO Report generation finished: ./llm_analyses/Test Title-llm-analysis.txt
LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f5faf-24c56ed66b591dbd1e349811;d42b99c1-1abe-4156-836d-2e123ba6af95)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 102, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f5faf-24c56ed66b591dbd1e349811;d42b99c1-1abe-4156-836d-2e123ba6af95)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:09:03,614 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f5faf-24c56ed66b591dbd1e349811;d42b99c1-1abe-4156-836d-2e123ba6af95)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 102, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f5faf-24c56ed66b591dbd1e349811;d42b99c1-1abe-4156-836d-2e123ba6af95)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
Processing question 1
2025-12-14 18:09:03,618 INFO Processing question 1
Processing question 2
2025-12-14 18:09:03,621 INFO Processing question 2
Processing question 3
2025-12-14 18:09:03,625 INFO Processing question 3
Processing question 4
2025-12-14 18:09:03,628 INFO Processing question 4
Processing question 5
2025-12-14 18:09:03,630 INFO Processing question 5
Processing question 6
2025-12-14 18:09:03,633 INFO Processing question 6
Processing question 7
2025-12-14 18:09:03,636 INFO Processing question 7
Processing question 8
2025-12-14 18:09:03,639 INFO Processing question 8
Processing question 9
2025-12-14 18:09:03,641 INFO Processing question 9
Processing question 10
2025-12-14 18:09:03,644 INFO Processing question 10
Processing question 11
2025-12-14 18:09:03,646 INFO Processing question 11
Processing question 12
2025-12-14 18:09:03,649 INFO Processing question 12
Processing question 13
2025-12-14 18:09:03,651 INFO Processing question 13
Processing question 14
2025-12-14 18:09:03,654 INFO Processing question 14
Processing question 15
2025-12-14 18:09:03,656 INFO Processing question 15
Wrote analysis to ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:09:03,656 INFO Wrote analysis to ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:09:03,656 INFO Report generation finished: ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:12:07,946 INFO  * Detected change in '/Users/nihaarikaagarwal/Downloads/moral-compass/app.py', reloading
2025-12-14 18:12:08,662 INFO  * Restarting with stat
2025-12-14 18:12:08,833 WARNING  * Debugger is active!
2025-12-14 18:12:08,838 INFO  * Debugger PIN: 255-579-290
/Users/nihaarikaagarwal/.pyenv/versions/3.10.19/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/Users/nihaarikaagarwal/.pyenv/versions/3.10.19/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
