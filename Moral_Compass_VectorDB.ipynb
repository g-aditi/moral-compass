{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/g-aditi/moral-compass/blob/Nihaarika/Moral_Compass_VectorDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZ-EFUX7i4zm",
    "outputId": "a6591369-e2d3-4d3c-8594-4cbf9b0f07c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aganap12/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/aganap12/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TvIhJ5emjSZ3",
    "outputId": "266f8e7e-5f88-4f83-85d0-1154efac82c1"
   },
   "outputs": [],
   "source": [
    "def pdf_to_text(pdf_data_directory, txt_data_directory):\n",
    "\n",
    "    if not os.path.exists(txt_data_directory):\n",
    "        os.makedirs(txt_data_directory)\n",
    "\n",
    "    for pdf_filename in os.listdir(pdf_data_directory):\n",
    "\n",
    "        if pdf_filename.endswith(\".pdf\"):\n",
    "\n",
    "            pdf_path = os.path.join(pdf_data_directory, pdf_filename)\n",
    "            #checkpoint\n",
    "            # print (pdf_filename)\n",
    "            txt_filename = os.path.splitext(pdf_filename)[0] + \".txt\"\n",
    "            txt_path = os.path.join(txt_data_directory, txt_filename)\n",
    "\n",
    "            with open(pdf_path, \"rb\") as pdf_file:\n",
    "                pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "                text = \"\"\n",
    "                for page_num in range(len(pdf_reader.pages)):\n",
    "                    page = pdf_reader.pages[page_num]\n",
    "                    text += page.extract_text()\n",
    "\n",
    "                with open(txt_path, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "                    txt_file.write(text)\n",
    "\n",
    "pdf_data_directory = \"./documents\"\n",
    "txt_data_directory = \"./txt_documents\"\n",
    "pdf_to_text(pdf_data_directory, txt_data_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcYJ9tAC0laj",
    "outputId": "9a13ca77-25d5-4d4c-a73c-2e308fdec8a5"
   },
   "outputs": [],
   "source": [
    "txt_file_paths = [os.path.join(txt_data_directory, file) for file in os.listdir(txt_data_directory) if file.endswith('.txt')]\n",
    "tagged_data = []\n",
    "for i, txt_file_path in enumerate(txt_file_paths):\n",
    "    with open(txt_file_path, 'r', encoding='utf-8') as file:\n",
    "         text = file.read()\n",
    "         words = word_tokenize(text)\n",
    "         words = [word.lower() for word in words]\n",
    "         tagged_data.append(TaggedDocument(words, tags=['doc_' + str(i)]))\n",
    "         model = Doc2Vec(vector_size=20, epochs=300)\n",
    "         model.build_vocab(tagged_data)\n",
    "         model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "document_vectors = [model.dv['doc_' + str(i)] for i in range(len(tagged_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Uu52UMph8__6"
   },
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhzC19S59FTA",
    "outputId": "7987c8ea-7376-4b09-bd73-cfb5d216ad06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "vector_dim = len(document_vectors[0])\n",
    "#checkpoint\n",
    "print (vector_dim)\n",
    "index = faiss.IndexFlatL2(vector_dim)\n",
    "vectors_np = np.array(document_vectors).astype('float32')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNopb+jh5sbRnL3YO36vw+w",
   "include_colab_link": true,
   "mount_file_id": "1YavZ7UmFBnaozWz-74MbjWAI5Q994wdT",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "moral-compass-env",
   "language": "python",
   "name": "moral-compass-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
