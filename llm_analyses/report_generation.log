2025-12-14 18:07:18,898 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 18:07:18,898 INFO [33mPress CTRL+C to quit[0m
2025-12-14 18:07:18,899 INFO  * Restarting with stat
2025-12-14 18:07:19,001 WARNING  * Debugger is active!
2025-12-14 18:07:19,008 INFO  * Debugger PIN: 255-579-290
2025-12-14 18:07:19,701 INFO Received form responses; launching background generation
2025-12-14 18:07:19,701 INFO Background report generation started
2025-12-14 18:07:19,702 INFO 127.0.0.1 - - [14/Dec/2025 18:07:19] "POST /submit HTTP/1.1" 200 -
2025-12-14 18:07:19,704 INFO Starting report generation
2025-12-14 18:07:19,704 INFO Starting report generation
2025-12-14 18:07:33,595 INFO Received form responses; launching background generation
2025-12-14 18:07:33,599 INFO Background report generation started
2025-12-14 18:07:33,600 INFO 127.0.0.1 - - [14/Dec/2025 18:07:33] "POST /submit HTTP/1.1" 200 -
2025-12-14 18:07:33,601 INFO Starting report generation
2025-12-14 18:07:33,601 INFO Starting report generation
2025-12-14 18:08:00,902 INFO Loading faiss.
2025-12-14 18:08:01,263 INFO Successfully loaded faiss.
2025-12-14 18:08:48,998 INFO Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d20,n5,w5,mc5,s0.001,t3>', 'datetime': '2025-12-14T18:08:48.976175', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'created'}
2025-12-14 18:08:48,998 INFO collecting all words and their counts
2025-12-14 18:08:48,998 INFO PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2025-12-14 18:08:49,011 INFO collected 8045 word types and 22 unique tags from a corpus of 22 examples and 182922 words
2025-12-14 18:08:49,011 INFO Creating a fresh vocabulary
2025-12-14 18:08:49,016 INFO Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 2492 unique words (30.98% of original 8045, drops 5553)', 'datetime': '2025-12-14T18:08:49.016067', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 18:08:49,016 INFO Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 174109 word corpus (95.18% of original 182922, drops 8813)', 'datetime': '2025-12-14T18:08:49.016164', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 18:08:49,022 INFO deleting the raw counts dictionary of 8045 items
2025-12-14 18:08:49,022 INFO sample=0.001 downsamples 48 most-common words
2025-12-14 18:08:49,022 INFO Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 117305.50818736776 word corpus (67.4%% of prior 174109)', 'datetime': '2025-12-14T18:08:49.022614', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 18:08:49,031 INFO estimated required memory for 2492 words and 20 dimensions: 1650880 bytes
2025-12-14 18:08:49,031 INFO resetting layer weights
2025-12-14 18:08:49,033 INFO Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 2492 vocabulary and 20 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-12-14T18:08:49.033140', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}
2025-12-14 18:08:49,056 INFO EPOCH 0: training on 182922 raw words (78566 effective words) took 0.0s, 3525128 effective words/s
2025-12-14 18:08:49,078 INFO EPOCH 1: training on 182922 raw words (78557 effective words) took 0.0s, 3653828 effective words/s
2025-12-14 18:08:49,097 INFO EPOCH 2: training on 182922 raw words (78449 effective words) took 0.0s, 4113721 effective words/s
2025-12-14 18:08:49,117 INFO EPOCH 3: training on 182922 raw words (78486 effective words) took 0.0s, 4046678 effective words/s
2025-12-14 18:08:49,136 INFO EPOCH 4: training on 182922 raw words (78540 effective words) took 0.0s, 4273830 effective words/s
2025-12-14 18:08:49,154 INFO EPOCH 5: training on 182922 raw words (78520 effective words) took 0.0s, 4249033 effective words/s
2025-12-14 18:08:49,173 INFO EPOCH 6: training on 182922 raw words (78551 effective words) took 0.0s, 4193356 effective words/s
2025-12-14 18:08:49,192 INFO EPOCH 7: training on 182922 raw words (78581 effective words) took 0.0s, 4254108 effective words/s
2025-12-14 18:08:49,211 INFO EPOCH 8: training on 182922 raw words (78558 effective words) took 0.0s, 4264377 effective words/s
2025-12-14 18:08:49,230 INFO EPOCH 9: training on 182922 raw words (78564 effective words) took 0.0s, 4194022 effective words/s
2025-12-14 18:08:49,248 INFO EPOCH 10: training on 182922 raw words (78599 effective words) took 0.0s, 4248767 effective words/s
2025-12-14 18:08:49,267 INFO EPOCH 11: training on 182922 raw words (78581 effective words) took 0.0s, 4187906 effective words/s
2025-12-14 18:08:49,286 INFO EPOCH 12: training on 182922 raw words (78503 effective words) took 0.0s, 4205265 effective words/s
2025-12-14 18:08:49,306 INFO EPOCH 13: training on 182922 raw words (78512 effective words) took 0.0s, 4090258 effective words/s
2025-12-14 18:08:49,325 INFO EPOCH 14: training on 182922 raw words (78649 effective words) took 0.0s, 4071649 effective words/s
2025-12-14 18:08:49,345 INFO EPOCH 15: training on 182922 raw words (78511 effective words) took 0.0s, 4036797 effective words/s
2025-12-14 18:08:49,365 INFO EPOCH 16: training on 182922 raw words (78496 effective words) took 0.0s, 4009151 effective words/s
2025-12-14 18:08:49,385 INFO EPOCH 17: training on 182922 raw words (78546 effective words) took 0.0s, 4073452 effective words/s
2025-12-14 18:08:49,405 INFO EPOCH 18: training on 182922 raw words (78555 effective words) took 0.0s, 3974475 effective words/s
2025-12-14 18:08:49,424 INFO EPOCH 19: training on 182922 raw words (78621 effective words) took 0.0s, 4102037 effective words/s
2025-12-14 18:08:49,443 INFO EPOCH 20: training on 182922 raw words (78694 effective words) took 0.0s, 4178748 effective words/s
2025-12-14 18:08:49,462 INFO EPOCH 21: training on 182922 raw words (78568 effective words) took 0.0s, 4119916 effective words/s
2025-12-14 18:08:49,482 INFO EPOCH 22: training on 182922 raw words (78520 effective words) took 0.0s, 4038740 effective words/s
2025-12-14 18:08:49,502 INFO EPOCH 23: training on 182922 raw words (78534 effective words) took 0.0s, 4072328 effective words/s
2025-12-14 18:08:49,521 INFO EPOCH 24: training on 182922 raw words (78626 effective words) took 0.0s, 4064348 effective words/s
2025-12-14 18:08:49,541 INFO EPOCH 25: training on 182922 raw words (78651 effective words) took 0.0s, 4309368 effective words/s
2025-12-14 18:08:49,561 INFO EPOCH 26: training on 182922 raw words (78647 effective words) took 0.0s, 4080101 effective words/s
2025-12-14 18:08:49,581 INFO EPOCH 27: training on 182922 raw words (78618 effective words) took 0.0s, 3944624 effective words/s
2025-12-14 18:08:49,602 INFO EPOCH 28: training on 182922 raw words (78610 effective words) took 0.0s, 3820695 effective words/s
2025-12-14 18:08:49,622 INFO EPOCH 29: training on 182922 raw words (78596 effective words) took 0.0s, 3959455 effective words/s
2025-12-14 18:08:49,642 INFO EPOCH 30: training on 182922 raw words (78571 effective words) took 0.0s, 4048938 effective words/s
2025-12-14 18:08:49,662 INFO EPOCH 31: training on 182922 raw words (78598 effective words) took 0.0s, 4029324 effective words/s
2025-12-14 18:08:49,682 INFO EPOCH 32: training on 182922 raw words (78604 effective words) took 0.0s, 3963169 effective words/s
2025-12-14 18:08:49,702 INFO EPOCH 33: training on 182922 raw words (78528 effective words) took 0.0s, 4056146 effective words/s
2025-12-14 18:08:49,722 INFO EPOCH 34: training on 182922 raw words (78591 effective words) took 0.0s, 4000068 effective words/s
2025-12-14 18:08:49,741 INFO EPOCH 35: training on 182922 raw words (78516 effective words) took 0.0s, 4004709 effective words/s
2025-12-14 18:08:49,762 INFO EPOCH 36: training on 182922 raw words (78628 effective words) took 0.0s, 3930540 effective words/s
2025-12-14 18:08:49,782 INFO EPOCH 37: training on 182922 raw words (78610 effective words) took 0.0s, 3979732 effective words/s
2025-12-14 18:08:49,802 INFO EPOCH 38: training on 182922 raw words (78671 effective words) took 0.0s, 4044972 effective words/s
2025-12-14 18:08:49,821 INFO EPOCH 39: training on 182922 raw words (78573 effective words) took 0.0s, 4073866 effective words/s
2025-12-14 18:08:49,843 INFO EPOCH 40: training on 182922 raw words (78475 effective words) took 0.0s, 3621477 effective words/s
2025-12-14 18:08:49,944 INFO EPOCH 41: training on 182922 raw words (78677 effective words) took 0.1s, 786732 effective words/s
2025-12-14 18:08:49,977 INFO EPOCH 42: training on 182922 raw words (78678 effective words) took 0.0s, 2462712 effective words/s
2025-12-14 18:08:49,997 INFO EPOCH 43: training on 182922 raw words (78587 effective words) took 0.0s, 3846576 effective words/s
2025-12-14 18:08:50,030 INFO EPOCH 44: training on 182922 raw words (78605 effective words) took 0.0s, 2429483 effective words/s
2025-12-14 18:08:50,053 INFO EPOCH 45: training on 182922 raw words (78594 effective words) took 0.0s, 3622087 effective words/s
2025-12-14 18:08:50,073 INFO EPOCH 46: training on 182922 raw words (78653 effective words) took 0.0s, 3924719 effective words/s
2025-12-14 18:08:50,093 INFO EPOCH 47: training on 182922 raw words (78637 effective words) took 0.0s, 4009236 effective words/s
2025-12-14 18:08:50,115 INFO EPOCH 48: training on 182922 raw words (78688 effective words) took 0.0s, 3697447 effective words/s
2025-12-14 18:08:50,134 INFO EPOCH 49: training on 182922 raw words (78570 effective words) took 0.0s, 4014742 effective words/s
2025-12-14 18:08:50,155 INFO EPOCH 50: training on 182922 raw words (78646 effective words) took 0.0s, 3870445 effective words/s
2025-12-14 18:08:50,176 INFO EPOCH 51: training on 182922 raw words (78584 effective words) took 0.0s, 3873375 effective words/s
2025-12-14 18:08:50,196 INFO EPOCH 52: training on 182922 raw words (78592 effective words) took 0.0s, 3979014 effective words/s
2025-12-14 18:08:50,218 INFO EPOCH 53: training on 182922 raw words (78616 effective words) took 0.0s, 3613885 effective words/s
2025-12-14 18:08:50,256 INFO EPOCH 54: training on 182922 raw words (78621 effective words) took 0.0s, 2081527 effective words/s
2025-12-14 18:08:50,277 INFO EPOCH 55: training on 182922 raw words (78645 effective words) took 0.0s, 3738517 effective words/s
2025-12-14 18:08:50,298 INFO EPOCH 56: training on 182922 raw words (78630 effective words) took 0.0s, 3733596 effective words/s
2025-12-14 18:08:50,319 INFO EPOCH 57: training on 182922 raw words (78649 effective words) took 0.0s, 3851198 effective words/s
2025-12-14 18:08:50,341 INFO EPOCH 58: training on 182922 raw words (78563 effective words) took 0.0s, 3657424 effective words/s
2025-12-14 18:08:50,362 INFO EPOCH 59: training on 182922 raw words (78623 effective words) took 0.0s, 3706388 effective words/s
2025-12-14 18:08:50,385 INFO EPOCH 60: training on 182922 raw words (78610 effective words) took 0.0s, 3551616 effective words/s
2025-12-14 18:08:50,406 INFO EPOCH 61: training on 182922 raw words (78612 effective words) took 0.0s, 3787633 effective words/s
2025-12-14 18:08:50,427 INFO EPOCH 62: training on 182922 raw words (78546 effective words) took 0.0s, 3875681 effective words/s
2025-12-14 18:08:50,449 INFO EPOCH 63: training on 182922 raw words (78645 effective words) took 0.0s, 3595001 effective words/s
2025-12-14 18:08:50,471 INFO EPOCH 64: training on 182922 raw words (78590 effective words) took 0.0s, 3626840 effective words/s
2025-12-14 18:08:50,493 INFO EPOCH 65: training on 182922 raw words (78542 effective words) took 0.0s, 3676300 effective words/s
2025-12-14 18:08:50,516 INFO EPOCH 66: training on 182922 raw words (78536 effective words) took 0.0s, 3439583 effective words/s
2025-12-14 18:08:50,540 INFO EPOCH 67: training on 182922 raw words (78574 effective words) took 0.0s, 3317114 effective words/s
2025-12-14 18:08:50,564 INFO EPOCH 68: training on 182922 raw words (78513 effective words) took 0.0s, 3239124 effective words/s
2025-12-14 18:08:50,588 INFO EPOCH 69: training on 182922 raw words (78576 effective words) took 0.0s, 3325141 effective words/s
2025-12-14 18:08:50,616 INFO EPOCH 70: training on 182922 raw words (78521 effective words) took 0.0s, 2913801 effective words/s
2025-12-14 18:08:50,660 INFO EPOCH 71: training on 182922 raw words (78618 effective words) took 0.0s, 1781812 effective words/s
2025-12-14 18:08:50,698 INFO EPOCH 72: training on 182922 raw words (78561 effective words) took 0.0s, 2072091 effective words/s
2025-12-14 18:08:50,722 INFO EPOCH 73: training on 182922 raw words (78509 effective words) took 0.0s, 3353408 effective words/s
2025-12-14 18:08:50,747 INFO EPOCH 74: training on 182922 raw words (78584 effective words) took 0.0s, 3198719 effective words/s
2025-12-14 18:08:50,772 INFO EPOCH 75: training on 182922 raw words (78561 effective words) took 0.0s, 3229900 effective words/s
2025-12-14 18:08:50,793 INFO EPOCH 76: training on 182922 raw words (78685 effective words) took 0.0s, 3884951 effective words/s
2025-12-14 18:08:50,815 INFO EPOCH 77: training on 182922 raw words (78648 effective words) took 0.0s, 3604544 effective words/s
2025-12-14 18:08:50,842 INFO EPOCH 78: training on 182922 raw words (78628 effective words) took 0.0s, 2974165 effective words/s
2025-12-14 18:08:50,863 INFO EPOCH 79: training on 182922 raw words (78717 effective words) took 0.0s, 3806654 effective words/s
2025-12-14 18:08:50,884 INFO EPOCH 80: training on 182922 raw words (78561 effective words) took 0.0s, 3802059 effective words/s
2025-12-14 18:08:50,906 INFO EPOCH 81: training on 182922 raw words (78644 effective words) took 0.0s, 3660407 effective words/s
2025-12-14 18:08:50,927 INFO EPOCH 82: training on 182922 raw words (78555 effective words) took 0.0s, 3769366 effective words/s
2025-12-14 18:08:50,948 INFO EPOCH 83: training on 182922 raw words (78565 effective words) took 0.0s, 3871469 effective words/s
2025-12-14 18:08:50,968 INFO EPOCH 84: training on 182922 raw words (78605 effective words) took 0.0s, 3938422 effective words/s
2025-12-14 18:08:50,989 INFO EPOCH 85: training on 182922 raw words (78569 effective words) took 0.0s, 3771078 effective words/s
2025-12-14 18:08:51,010 INFO EPOCH 86: training on 182922 raw words (78559 effective words) took 0.0s, 3952969 effective words/s
2025-12-14 18:08:51,029 INFO EPOCH 87: training on 182922 raw words (78595 effective words) took 0.0s, 4032590 effective words/s
2025-12-14 18:08:51,049 INFO EPOCH 88: training on 182922 raw words (78537 effective words) took 0.0s, 4050317 effective words/s
2025-12-14 18:08:51,069 INFO EPOCH 89: training on 182922 raw words (78584 effective words) took 0.0s, 3922483 effective words/s
2025-12-14 18:08:51,090 INFO EPOCH 90: training on 182922 raw words (78642 effective words) took 0.0s, 3906690 effective words/s
2025-12-14 18:08:51,111 INFO EPOCH 91: training on 182922 raw words (78643 effective words) took 0.0s, 3820109 effective words/s
2025-12-14 18:08:51,131 INFO EPOCH 92: training on 182922 raw words (78593 effective words) took 0.0s, 3889050 effective words/s
2025-12-14 18:08:51,152 INFO EPOCH 93: training on 182922 raw words (78611 effective words) took 0.0s, 3827293 effective words/s
2025-12-14 18:08:51,172 INFO EPOCH 94: training on 182922 raw words (78600 effective words) took 0.0s, 4019347 effective words/s
2025-12-14 18:08:51,201 INFO EPOCH 95: training on 182922 raw words (78528 effective words) took 0.0s, 2708730 effective words/s
2025-12-14 18:08:51,222 INFO EPOCH 96: training on 182922 raw words (78539 effective words) took 0.0s, 3847389 effective words/s
2025-12-14 18:08:51,243 INFO EPOCH 97: training on 182922 raw words (78512 effective words) took 0.0s, 3849933 effective words/s
2025-12-14 18:08:51,263 INFO EPOCH 98: training on 182922 raw words (78618 effective words) took 0.0s, 3858986 effective words/s
2025-12-14 18:08:51,284 INFO EPOCH 99: training on 182922 raw words (78638 effective words) took 0.0s, 3862290 effective words/s
2025-12-14 18:08:51,304 INFO EPOCH 100: training on 182922 raw words (78517 effective words) took 0.0s, 3908498 effective words/s
2025-12-14 18:08:51,325 INFO EPOCH 101: training on 182922 raw words (78555 effective words) took 0.0s, 3873767 effective words/s
2025-12-14 18:08:51,345 INFO EPOCH 102: training on 182922 raw words (78541 effective words) took 0.0s, 4016176 effective words/s
2025-12-14 18:08:51,364 INFO EPOCH 103: training on 182922 raw words (78593 effective words) took 0.0s, 4072704 effective words/s
2025-12-14 18:08:51,385 INFO EPOCH 104: training on 182922 raw words (78636 effective words) took 0.0s, 3956595 effective words/s
2025-12-14 18:08:51,404 INFO EPOCH 105: training on 182922 raw words (78670 effective words) took 0.0s, 4057054 effective words/s
2025-12-14 18:08:51,424 INFO EPOCH 106: training on 182922 raw words (78529 effective words) took 0.0s, 3994422 effective words/s
2025-12-14 18:08:51,444 INFO EPOCH 107: training on 182922 raw words (78563 effective words) took 0.0s, 4038001 effective words/s
2025-12-14 18:08:51,464 INFO EPOCH 108: training on 182922 raw words (78592 effective words) took 0.0s, 4000254 effective words/s
2025-12-14 18:08:51,484 INFO EPOCH 109: training on 182922 raw words (78592 effective words) took 0.0s, 3970371 effective words/s
2025-12-14 18:08:51,503 INFO EPOCH 110: training on 182922 raw words (78511 effective words) took 0.0s, 4036746 effective words/s
2025-12-14 18:08:51,523 INFO EPOCH 111: training on 182922 raw words (78614 effective words) took 0.0s, 3965797 effective words/s
2025-12-14 18:08:51,544 INFO EPOCH 112: training on 182922 raw words (78590 effective words) took 0.0s, 3838644 effective words/s
2025-12-14 18:08:51,564 INFO EPOCH 113: training on 182922 raw words (78586 effective words) took 0.0s, 3935835 effective words/s
2025-12-14 18:08:51,584 INFO EPOCH 114: training on 182922 raw words (78584 effective words) took 0.0s, 3992269 effective words/s
2025-12-14 18:08:51,605 INFO EPOCH 115: training on 182922 raw words (78625 effective words) took 0.0s, 3781381 effective words/s
2025-12-14 18:08:51,626 INFO EPOCH 116: training on 182922 raw words (78584 effective words) took 0.0s, 3849452 effective words/s
2025-12-14 18:08:51,647 INFO EPOCH 117: training on 182922 raw words (78662 effective words) took 0.0s, 3801604 effective words/s
2025-12-14 18:08:51,668 INFO EPOCH 118: training on 182922 raw words (78623 effective words) took 0.0s, 3877479 effective words/s
2025-12-14 18:08:51,739 INFO EPOCH 119: training on 182922 raw words (78590 effective words) took 0.1s, 1114441 effective words/s
2025-12-14 18:08:51,767 INFO EPOCH 120: training on 182922 raw words (78637 effective words) took 0.0s, 2882341 effective words/s
2025-12-14 18:08:51,787 INFO EPOCH 121: training on 182922 raw words (78641 effective words) took 0.0s, 3883834 effective words/s
2025-12-14 18:08:51,808 INFO EPOCH 122: training on 182922 raw words (78565 effective words) took 0.0s, 3846645 effective words/s
2025-12-14 18:08:51,828 INFO EPOCH 123: training on 182922 raw words (78631 effective words) took 0.0s, 3982451 effective words/s
2025-12-14 18:08:51,848 INFO EPOCH 124: training on 182922 raw words (78554 effective words) took 0.0s, 4039216 effective words/s
2025-12-14 18:08:51,869 INFO EPOCH 125: training on 182922 raw words (78704 effective words) took 0.0s, 3788179 effective words/s
2025-12-14 18:08:51,889 INFO EPOCH 126: training on 182922 raw words (78490 effective words) took 0.0s, 3992785 effective words/s
2025-12-14 18:08:51,909 INFO EPOCH 127: training on 182922 raw words (78574 effective words) took 0.0s, 3956362 effective words/s
2025-12-14 18:08:51,931 INFO EPOCH 128: training on 182922 raw words (78626 effective words) took 0.0s, 3635835 effective words/s
2025-12-14 18:08:51,952 INFO EPOCH 129: training on 182922 raw words (78560 effective words) took 0.0s, 3753307 effective words/s
2025-12-14 18:08:51,972 INFO EPOCH 130: training on 182922 raw words (78577 effective words) took 0.0s, 3979884 effective words/s
2025-12-14 18:08:51,992 INFO EPOCH 131: training on 182922 raw words (78616 effective words) took 0.0s, 4037819 effective words/s
2025-12-14 18:08:52,012 INFO EPOCH 132: training on 182922 raw words (78574 effective words) took 0.0s, 4010370 effective words/s
2025-12-14 18:08:52,031 INFO EPOCH 133: training on 182922 raw words (78517 effective words) took 0.0s, 4029319 effective words/s
2025-12-14 18:08:52,051 INFO EPOCH 134: training on 182922 raw words (78660 effective words) took 0.0s, 4052507 effective words/s
2025-12-14 18:08:52,071 INFO EPOCH 135: training on 182922 raw words (78565 effective words) took 0.0s, 3980628 effective words/s
2025-12-14 18:08:52,091 INFO EPOCH 136: training on 182922 raw words (78480 effective words) took 0.0s, 4009076 effective words/s
2025-12-14 18:08:52,111 INFO EPOCH 137: training on 182922 raw words (78582 effective words) took 0.0s, 3898763 effective words/s
2025-12-14 18:08:52,132 INFO EPOCH 138: training on 182922 raw words (78655 effective words) took 0.0s, 3858301 effective words/s
2025-12-14 18:08:52,153 INFO EPOCH 139: training on 182922 raw words (78610 effective words) took 0.0s, 3888809 effective words/s
2025-12-14 18:08:52,173 INFO EPOCH 140: training on 182922 raw words (78621 effective words) took 0.0s, 3854246 effective words/s
2025-12-14 18:08:52,194 INFO EPOCH 141: training on 182922 raw words (78630 effective words) took 0.0s, 3888892 effective words/s
2025-12-14 18:08:52,215 INFO EPOCH 142: training on 182922 raw words (78663 effective words) took 0.0s, 3762715 effective words/s
2025-12-14 18:08:52,235 INFO EPOCH 143: training on 182922 raw words (78637 effective words) took 0.0s, 3976084 effective words/s
2025-12-14 18:08:52,255 INFO EPOCH 144: training on 182922 raw words (78586 effective words) took 0.0s, 4027237 effective words/s
2025-12-14 18:08:52,275 INFO EPOCH 145: training on 182922 raw words (78719 effective words) took 0.0s, 3936901 effective words/s
2025-12-14 18:08:52,295 INFO EPOCH 146: training on 182922 raw words (78587 effective words) took 0.0s, 4003507 effective words/s
2025-12-14 18:08:52,315 INFO EPOCH 147: training on 182922 raw words (78723 effective words) took 0.0s, 3881494 effective words/s
2025-12-14 18:08:52,335 INFO EPOCH 148: training on 182922 raw words (78556 effective words) took 0.0s, 4008666 effective words/s
2025-12-14 18:08:52,355 INFO EPOCH 149: training on 182922 raw words (78633 effective words) took 0.0s, 3998627 effective words/s
2025-12-14 18:08:52,376 INFO EPOCH 150: training on 182922 raw words (78688 effective words) took 0.0s, 3854712 effective words/s
2025-12-14 18:08:52,396 INFO EPOCH 151: training on 182922 raw words (78656 effective words) took 0.0s, 3898195 effective words/s
2025-12-14 18:08:52,417 INFO EPOCH 152: training on 182922 raw words (78628 effective words) took 0.0s, 3800137 effective words/s
2025-12-14 18:08:52,438 INFO EPOCH 153: training on 182922 raw words (78651 effective words) took 0.0s, 3883680 effective words/s
2025-12-14 18:08:52,458 INFO EPOCH 154: training on 182922 raw words (78647 effective words) took 0.0s, 3885281 effective words/s
2025-12-14 18:08:52,479 INFO EPOCH 155: training on 182922 raw words (78613 effective words) took 0.0s, 3907943 effective words/s
2025-12-14 18:08:52,499 INFO EPOCH 156: training on 182922 raw words (78601 effective words) took 0.0s, 4004645 effective words/s
2025-12-14 18:08:52,519 INFO EPOCH 157: training on 182922 raw words (78573 effective words) took 0.0s, 4031995 effective words/s
2025-12-14 18:08:52,539 INFO EPOCH 158: training on 182922 raw words (78626 effective words) took 0.0s, 3926670 effective words/s
2025-12-14 18:08:52,559 INFO EPOCH 159: training on 182922 raw words (78591 effective words) took 0.0s, 4040651 effective words/s
2025-12-14 18:08:52,579 INFO EPOCH 160: training on 182922 raw words (78623 effective words) took 0.0s, 3968095 effective words/s
2025-12-14 18:08:52,599 INFO EPOCH 161: training on 182922 raw words (78611 effective words) took 0.0s, 3972050 effective words/s
2025-12-14 18:08:52,618 INFO EPOCH 162: training on 182922 raw words (78663 effective words) took 0.0s, 4058830 effective words/s
2025-12-14 18:08:52,638 INFO EPOCH 163: training on 182922 raw words (78626 effective words) took 0.0s, 4021850 effective words/s
2025-12-14 18:08:52,658 INFO EPOCH 164: training on 182922 raw words (78604 effective words) took 0.0s, 3947297 effective words/s
2025-12-14 18:08:52,678 INFO EPOCH 165: training on 182922 raw words (78566 effective words) took 0.0s, 3988417 effective words/s
2025-12-14 18:08:52,699 INFO EPOCH 166: training on 182922 raw words (78540 effective words) took 0.0s, 3851369 effective words/s
2025-12-14 18:08:52,719 INFO EPOCH 167: training on 182922 raw words (78589 effective words) took 0.0s, 4021235 effective words/s
2025-12-14 18:08:52,739 INFO EPOCH 168: training on 182922 raw words (78524 effective words) took 0.0s, 3978660 effective words/s
2025-12-14 18:08:52,759 INFO EPOCH 169: training on 182922 raw words (78518 effective words) took 0.0s, 3941411 effective words/s
2025-12-14 18:08:52,779 INFO EPOCH 170: training on 182922 raw words (78499 effective words) took 0.0s, 3922694 effective words/s
2025-12-14 18:08:52,800 INFO EPOCH 171: training on 182922 raw words (78591 effective words) took 0.0s, 3813007 effective words/s
2025-12-14 18:08:52,820 INFO EPOCH 172: training on 182922 raw words (78645 effective words) took 0.0s, 3937853 effective words/s
2025-12-14 18:08:52,842 INFO EPOCH 173: training on 182922 raw words (78668 effective words) took 0.0s, 3657184 effective words/s
2025-12-14 18:08:52,863 INFO EPOCH 174: training on 182922 raw words (78556 effective words) took 0.0s, 3917989 effective words/s
2025-12-14 18:08:52,884 INFO EPOCH 175: training on 182922 raw words (78632 effective words) took 0.0s, 3797004 effective words/s
2025-12-14 18:08:52,904 INFO EPOCH 176: training on 182922 raw words (78536 effective words) took 0.0s, 3934448 effective words/s
2025-12-14 18:08:52,925 INFO EPOCH 177: training on 182922 raw words (78631 effective words) took 0.0s, 3846722 effective words/s
2025-12-14 18:08:52,945 INFO EPOCH 178: training on 182922 raw words (78598 effective words) took 0.0s, 3970858 effective words/s
2025-12-14 18:08:52,966 INFO EPOCH 179: training on 182922 raw words (78585 effective words) took 0.0s, 3797080 effective words/s
2025-12-14 18:08:52,987 INFO EPOCH 180: training on 182922 raw words (78639 effective words) took 0.0s, 3834023 effective words/s
2025-12-14 18:08:53,007 INFO EPOCH 181: training on 182922 raw words (78593 effective words) took 0.0s, 3995264 effective words/s
2025-12-14 18:08:53,026 INFO EPOCH 182: training on 182922 raw words (78546 effective words) took 0.0s, 3994076 effective words/s
2025-12-14 18:08:53,047 INFO EPOCH 183: training on 182922 raw words (78555 effective words) took 0.0s, 3907618 effective words/s
2025-12-14 18:08:53,067 INFO EPOCH 184: training on 182922 raw words (78763 effective words) took 0.0s, 4003914 effective words/s
2025-12-14 18:08:53,087 INFO EPOCH 185: training on 182922 raw words (78538 effective words) took 0.0s, 3878779 effective words/s
2025-12-14 18:08:53,108 INFO EPOCH 186: training on 182922 raw words (78678 effective words) took 0.0s, 3789618 effective words/s
2025-12-14 18:08:53,129 INFO EPOCH 187: training on 182922 raw words (78651 effective words) took 0.0s, 3909338 effective words/s
2025-12-14 18:08:53,149 INFO EPOCH 188: training on 182922 raw words (78552 effective words) took 0.0s, 3969687 effective words/s
2025-12-14 18:08:53,170 INFO EPOCH 189: training on 182922 raw words (78576 effective words) took 0.0s, 3798901 effective words/s
2025-12-14 18:08:53,191 INFO EPOCH 190: training on 182922 raw words (78593 effective words) took 0.0s, 3789288 effective words/s
2025-12-14 18:08:53,211 INFO EPOCH 191: training on 182922 raw words (78617 effective words) took 0.0s, 3978333 effective words/s
2025-12-14 18:08:53,231 INFO EPOCH 192: training on 182922 raw words (78575 effective words) took 0.0s, 3890526 effective words/s
2025-12-14 18:08:53,252 INFO EPOCH 193: training on 182922 raw words (78587 effective words) took 0.0s, 3921719 effective words/s
2025-12-14 18:08:53,272 INFO EPOCH 194: training on 182922 raw words (78597 effective words) took 0.0s, 3929261 effective words/s
2025-12-14 18:08:53,294 INFO EPOCH 195: training on 182922 raw words (78612 effective words) took 0.0s, 3577772 effective words/s
2025-12-14 18:08:53,316 INFO EPOCH 196: training on 182922 raw words (78565 effective words) took 0.0s, 3703414 effective words/s
2025-12-14 18:08:53,341 INFO EPOCH 197: training on 182922 raw words (78553 effective words) took 0.0s, 3146420 effective words/s
2025-12-14 18:08:53,362 INFO EPOCH 198: training on 182922 raw words (78540 effective words) took 0.0s, 3893339 effective words/s
2025-12-14 18:08:53,383 INFO EPOCH 199: training on 182922 raw words (78564 effective words) took 0.0s, 3740742 effective words/s
2025-12-14 18:08:53,403 INFO EPOCH 200: training on 182922 raw words (78614 effective words) took 0.0s, 3956160 effective words/s
2025-12-14 18:08:53,427 INFO EPOCH 201: training on 182922 raw words (78607 effective words) took 0.0s, 3259171 effective words/s
2025-12-14 18:08:53,451 INFO EPOCH 202: training on 182922 raw words (78677 effective words) took 0.0s, 3429300 effective words/s
2025-12-14 18:08:53,471 INFO EPOCH 203: training on 182922 raw words (78640 effective words) took 0.0s, 3932008 effective words/s
2025-12-14 18:08:53,493 INFO EPOCH 204: training on 182922 raw words (78703 effective words) took 0.0s, 3594455 effective words/s
2025-12-14 18:08:53,515 INFO EPOCH 205: training on 182922 raw words (78646 effective words) took 0.0s, 3701373 effective words/s
2025-12-14 18:08:53,538 INFO EPOCH 206: training on 182922 raw words (78692 effective words) took 0.0s, 3516424 effective words/s
2025-12-14 18:08:53,558 INFO EPOCH 207: training on 182922 raw words (78614 effective words) took 0.0s, 3888606 effective words/s
2025-12-14 18:08:53,579 INFO EPOCH 208: training on 182922 raw words (78538 effective words) took 0.0s, 3848503 effective words/s
2025-12-14 18:08:53,599 INFO EPOCH 209: training on 182922 raw words (78613 effective words) took 0.0s, 3881325 effective words/s
2025-12-14 18:08:53,621 INFO EPOCH 210: training on 182922 raw words (78650 effective words) took 0.0s, 3672631 effective words/s
2025-12-14 18:08:53,642 INFO EPOCH 211: training on 182922 raw words (78626 effective words) took 0.0s, 3827914 effective words/s
2025-12-14 18:08:53,662 INFO EPOCH 212: training on 182922 raw words (78593 effective words) took 0.0s, 3925773 effective words/s
2025-12-14 18:08:53,683 INFO EPOCH 213: training on 182922 raw words (78663 effective words) took 0.0s, 3821437 effective words/s
2025-12-14 18:08:53,705 INFO EPOCH 214: training on 182922 raw words (78526 effective words) took 0.0s, 3652018 effective words/s
2025-12-14 18:08:53,726 INFO EPOCH 215: training on 182922 raw words (78666 effective words) took 0.0s, 3836110 effective words/s
2025-12-14 18:08:53,746 INFO EPOCH 216: training on 182922 raw words (78600 effective words) took 0.0s, 3907969 effective words/s
2025-12-14 18:08:53,767 INFO EPOCH 217: training on 182922 raw words (78675 effective words) took 0.0s, 3898139 effective words/s
2025-12-14 18:08:53,788 INFO EPOCH 218: training on 182922 raw words (78570 effective words) took 0.0s, 3822087 effective words/s
2025-12-14 18:08:53,850 INFO EPOCH 219: training on 182922 raw words (78573 effective words) took 0.1s, 1264996 effective words/s
2025-12-14 18:08:53,875 INFO EPOCH 220: training on 182922 raw words (78504 effective words) took 0.0s, 3184472 effective words/s
2025-12-14 18:08:53,905 INFO EPOCH 221: training on 182922 raw words (78557 effective words) took 0.0s, 2662205 effective words/s
2025-12-14 18:08:53,925 INFO EPOCH 222: training on 182922 raw words (78612 effective words) took 0.0s, 4013214 effective words/s
2025-12-14 18:08:53,945 INFO EPOCH 223: training on 182922 raw words (78577 effective words) took 0.0s, 3920315 effective words/s
2025-12-14 18:08:53,965 INFO EPOCH 224: training on 182922 raw words (78537 effective words) took 0.0s, 3984198 effective words/s
2025-12-14 18:08:53,985 INFO EPOCH 225: training on 182922 raw words (78565 effective words) took 0.0s, 4024915 effective words/s
2025-12-14 18:08:54,005 INFO EPOCH 226: training on 182922 raw words (78610 effective words) took 0.0s, 3956854 effective words/s
2025-12-14 18:08:54,026 INFO EPOCH 227: training on 182922 raw words (78630 effective words) took 0.0s, 3809224 effective words/s
2025-12-14 18:08:54,046 INFO EPOCH 228: training on 182922 raw words (78557 effective words) took 0.0s, 3864251 effective words/s
2025-12-14 18:08:54,067 INFO EPOCH 229: training on 182922 raw words (78492 effective words) took 0.0s, 3965068 effective words/s
2025-12-14 18:08:54,087 INFO EPOCH 230: training on 182922 raw words (78562 effective words) took 0.0s, 3814993 effective words/s
2025-12-14 18:08:54,108 INFO EPOCH 231: training on 182922 raw words (78528 effective words) took 0.0s, 3895906 effective words/s
2025-12-14 18:08:54,128 INFO EPOCH 232: training on 182922 raw words (78573 effective words) took 0.0s, 3946715 effective words/s
2025-12-14 18:08:54,149 INFO EPOCH 233: training on 182922 raw words (78532 effective words) took 0.0s, 3803993 effective words/s
2025-12-14 18:08:54,169 INFO EPOCH 234: training on 182922 raw words (78572 effective words) took 0.0s, 3942275 effective words/s
2025-12-14 18:08:54,189 INFO EPOCH 235: training on 182922 raw words (78601 effective words) took 0.0s, 4020572 effective words/s
2025-12-14 18:08:54,209 INFO EPOCH 236: training on 182922 raw words (78588 effective words) took 0.0s, 4041129 effective words/s
2025-12-14 18:08:54,229 INFO EPOCH 237: training on 182922 raw words (78657 effective words) took 0.0s, 3962012 effective words/s
2025-12-14 18:08:54,251 INFO EPOCH 238: training on 182922 raw words (78599 effective words) took 0.0s, 3671485 effective words/s
2025-12-14 18:08:54,271 INFO EPOCH 239: training on 182922 raw words (78650 effective words) took 0.0s, 3881267 effective words/s
2025-12-14 18:08:54,292 INFO EPOCH 240: training on 182922 raw words (78552 effective words) took 0.0s, 3849393 effective words/s
2025-12-14 18:08:54,312 INFO EPOCH 241: training on 182922 raw words (78573 effective words) took 0.0s, 3968099 effective words/s
2025-12-14 18:08:54,332 INFO EPOCH 242: training on 182922 raw words (78611 effective words) took 0.0s, 3902113 effective words/s
2025-12-14 18:08:54,352 INFO EPOCH 243: training on 182922 raw words (78568 effective words) took 0.0s, 3997431 effective words/s
2025-12-14 18:08:54,372 INFO EPOCH 244: training on 182922 raw words (78519 effective words) took 0.0s, 4028923 effective words/s
2025-12-14 18:08:54,392 INFO EPOCH 245: training on 182922 raw words (78565 effective words) took 0.0s, 3964667 effective words/s
2025-12-14 18:08:54,413 INFO EPOCH 246: training on 182922 raw words (78670 effective words) took 0.0s, 3909748 effective words/s
2025-12-14 18:08:54,433 INFO EPOCH 247: training on 182922 raw words (78644 effective words) took 0.0s, 3808810 effective words/s
2025-12-14 18:08:54,454 INFO EPOCH 248: training on 182922 raw words (78680 effective words) took 0.0s, 3893395 effective words/s
2025-12-14 18:08:54,475 INFO EPOCH 249: training on 182922 raw words (78569 effective words) took 0.0s, 3856620 effective words/s
2025-12-14 18:08:54,495 INFO EPOCH 250: training on 182922 raw words (78566 effective words) took 0.0s, 3859773 effective words/s
2025-12-14 18:08:54,516 INFO EPOCH 251: training on 182922 raw words (78619 effective words) took 0.0s, 3807292 effective words/s
2025-12-14 18:08:54,537 INFO EPOCH 252: training on 182922 raw words (78584 effective words) took 0.0s, 3864304 effective words/s
2025-12-14 18:08:54,558 INFO EPOCH 253: training on 182922 raw words (78596 effective words) took 0.0s, 3873235 effective words/s
2025-12-14 18:08:54,578 INFO EPOCH 254: training on 182922 raw words (78580 effective words) took 0.0s, 4003396 effective words/s
2025-12-14 18:08:54,598 INFO EPOCH 255: training on 182922 raw words (78587 effective words) took 0.0s, 3967671 effective words/s
2025-12-14 18:08:54,617 INFO EPOCH 256: training on 182922 raw words (78612 effective words) took 0.0s, 3998372 effective words/s
2025-12-14 18:08:54,637 INFO EPOCH 257: training on 182922 raw words (78603 effective words) took 0.0s, 4003812 effective words/s
2025-12-14 18:08:54,658 INFO EPOCH 258: training on 182922 raw words (78612 effective words) took 0.0s, 3926273 effective words/s
2025-12-14 18:08:54,677 INFO EPOCH 259: training on 182922 raw words (78686 effective words) took 0.0s, 4031045 effective words/s
2025-12-14 18:08:54,697 INFO EPOCH 260: training on 182922 raw words (78610 effective words) took 0.0s, 4006269 effective words/s
2025-12-14 18:08:54,718 INFO EPOCH 261: training on 182922 raw words (78609 effective words) took 0.0s, 3841581 effective words/s
2025-12-14 18:08:54,739 INFO EPOCH 262: training on 182922 raw words (78553 effective words) took 0.0s, 3806339 effective words/s
2025-12-14 18:08:54,790 INFO EPOCH 263: training on 182922 raw words (78592 effective words) took 0.1s, 1546038 effective words/s
2025-12-14 18:08:54,818 INFO EPOCH 264: training on 182922 raw words (78637 effective words) took 0.0s, 2862272 effective words/s
2025-12-14 18:08:54,839 INFO EPOCH 265: training on 182922 raw words (78463 effective words) took 0.0s, 3854429 effective words/s
2025-12-14 18:08:54,859 INFO EPOCH 266: training on 182922 raw words (78641 effective words) took 0.0s, 3935280 effective words/s
2025-12-14 18:08:54,879 INFO EPOCH 267: training on 182922 raw words (78594 effective words) took 0.0s, 3868989 effective words/s
2025-12-14 18:08:54,900 INFO EPOCH 268: training on 182922 raw words (78458 effective words) took 0.0s, 3945562 effective words/s
2025-12-14 18:08:54,921 INFO EPOCH 269: training on 182922 raw words (78543 effective words) took 0.0s, 3748957 effective words/s
2025-12-14 18:08:54,942 INFO EPOCH 270: training on 182922 raw words (78585 effective words) took 0.0s, 3809489 effective words/s
2025-12-14 18:08:54,962 INFO EPOCH 271: training on 182922 raw words (78453 effective words) took 0.0s, 3860686 effective words/s
2025-12-14 18:08:54,983 INFO EPOCH 272: training on 182922 raw words (78659 effective words) took 0.0s, 3928130 effective words/s
2025-12-14 18:08:55,004 INFO EPOCH 273: training on 182922 raw words (78649 effective words) took 0.0s, 3805720 effective words/s
2025-12-14 18:08:55,024 INFO EPOCH 274: training on 182922 raw words (78596 effective words) took 0.0s, 3834395 effective words/s
2025-12-14 18:08:55,046 INFO EPOCH 275: training on 182922 raw words (78463 effective words) took 0.0s, 3720301 effective words/s
2025-12-14 18:08:55,066 INFO EPOCH 276: training on 182922 raw words (78530 effective words) took 0.0s, 3939163 effective words/s
2025-12-14 18:08:55,086 INFO EPOCH 277: training on 182922 raw words (78538 effective words) took 0.0s, 3920488 effective words/s
2025-12-14 18:08:55,107 INFO EPOCH 278: training on 182922 raw words (78691 effective words) took 0.0s, 3877407 effective words/s
2025-12-14 18:08:55,128 INFO EPOCH 279: training on 182922 raw words (78496 effective words) took 0.0s, 3899833 effective words/s
2025-12-14 18:08:55,148 INFO EPOCH 280: training on 182922 raw words (78689 effective words) took 0.0s, 3935221 effective words/s
2025-12-14 18:08:55,169 INFO EPOCH 281: training on 182922 raw words (78592 effective words) took 0.0s, 3764067 effective words/s
2025-12-14 18:08:55,189 INFO EPOCH 282: training on 182922 raw words (78520 effective words) took 0.0s, 3936933 effective words/s
2025-12-14 18:08:55,209 INFO EPOCH 283: training on 182922 raw words (78630 effective words) took 0.0s, 3939124 effective words/s
2025-12-14 18:08:55,229 INFO EPOCH 284: training on 182922 raw words (78475 effective words) took 0.0s, 4036529 effective words/s
2025-12-14 18:08:55,249 INFO EPOCH 285: training on 182922 raw words (78634 effective words) took 0.0s, 4037905 effective words/s
2025-12-14 18:08:55,269 INFO EPOCH 286: training on 182922 raw words (78612 effective words) took 0.0s, 3938830 effective words/s
2025-12-14 18:08:55,289 INFO EPOCH 287: training on 182922 raw words (78667 effective words) took 0.0s, 3991257 effective words/s
2025-12-14 18:08:55,309 INFO EPOCH 288: training on 182922 raw words (78558 effective words) took 0.0s, 3963547 effective words/s
2025-12-14 18:08:55,329 INFO EPOCH 289: training on 182922 raw words (78540 effective words) took 0.0s, 4036023 effective words/s
2025-12-14 18:08:55,349 INFO EPOCH 290: training on 182922 raw words (78611 effective words) took 0.0s, 4030403 effective words/s
2025-12-14 18:08:55,370 INFO EPOCH 291: training on 182922 raw words (78553 effective words) took 0.0s, 3659862 effective words/s
2025-12-14 18:08:55,404 INFO EPOCH 292: training on 182922 raw words (78609 effective words) took 0.0s, 2457046 effective words/s
2025-12-14 18:08:55,456 INFO EPOCH 293: training on 182922 raw words (78613 effective words) took 0.1s, 1506674 effective words/s
2025-12-14 18:08:55,488 INFO EPOCH 294: training on 182922 raw words (78488 effective words) took 0.0s, 2912487 effective words/s
2025-12-14 18:08:55,508 INFO EPOCH 295: training on 182922 raw words (78538 effective words) took 0.0s, 3907630 effective words/s
2025-12-14 18:08:55,535 INFO EPOCH 296: training on 182922 raw words (78567 effective words) took 0.0s, 2968989 effective words/s
2025-12-14 18:08:55,557 INFO EPOCH 297: training on 182922 raw words (78569 effective words) took 0.0s, 3536582 effective words/s
2025-12-14 18:08:55,584 INFO EPOCH 298: training on 182922 raw words (78613 effective words) took 0.0s, 2925203 effective words/s
2025-12-14 18:08:55,608 INFO EPOCH 299: training on 182922 raw words (78563 effective words) took 0.0s, 3431567 effective words/s
2025-12-14 18:08:55,608 INFO Doc2Vec lifecycle event {'msg': 'training on 54876600 raw words (23577595 effective words) took 6.6s, 3585932 effective words/s', 'datetime': '2025-12-14T18:08:55.608279', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}
2025-12-14 18:08:55,608 INFO Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_model.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-12-14T18:08:55.608411', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'saving'}
2025-12-14 18:08:55,608 INFO not storing attribute cum_table
2025-12-14 18:08:55,610 INFO saved doc2vec_model.model
2025-12-14 18:08:55,613 INFO loading Doc2Vec object from doc2vec_model.model
2025-12-14 18:08:55,613 INFO loading Doc2Vec object from doc2vec_model.model
2025-12-14 18:08:55,617 INFO loading dv recursively from doc2vec_model.model.dv.* with mmap=None
2025-12-14 18:08:55,617 INFO loading dv recursively from doc2vec_model.model.dv.* with mmap=None
2025-12-14 18:08:55,617 INFO loading wv recursively from doc2vec_model.model.wv.* with mmap=None
2025-12-14 18:08:55,617 INFO loading wv recursively from doc2vec_model.model.wv.* with mmap=None
2025-12-14 18:08:55,617 INFO setting ignored attribute cum_table to None
2025-12-14 18:08:55,617 INFO setting ignored attribute cum_table to None
2025-12-14 18:08:55,625 INFO Doc2Vec lifecycle event {'fname': 'doc2vec_model.model', 'datetime': '2025-12-14T18:08:55.625387', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}
2025-12-14 18:08:55,633 INFO Doc2Vec lifecycle event {'fname': 'doc2vec_model.model', 'datetime': '2025-12-14T18:08:55.633440', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}
2025-12-14 18:08:55,633 INFO Loaded Doc2Vec model
2025-12-14 18:08:55,633 INFO Loaded Doc2Vec model
2025-12-14 18:08:55,633 INFO Loaded Doc2Vec model
2025-12-14 18:08:55,633 INFO Loaded Doc2Vec model
2025-12-14 18:08:55,634 INFO Loaded FAISS index
2025-12-14 18:08:55,634 INFO Loaded FAISS index
2025-12-14 18:08:55,634 INFO Loaded FAISS index
2025-12-14 18:08:55,634 INFO Loaded FAISS index
2025-12-14 18:09:02,379 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:09:02,379 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:09:02,379 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:09:02,379 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:09:03,469 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f5faf-606cb53c4c22afc86f3feead;0bfcd43e-fc3f-4803-b57c-aa707bc175fe)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 102, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f5faf-606cb53c4c22afc86f3feead;0bfcd43e-fc3f-4803-b57c-aa707bc175fe)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:09:03,469 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f5faf-606cb53c4c22afc86f3feead;0bfcd43e-fc3f-4803-b57c-aa707bc175fe)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 102, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f5faf-606cb53c4c22afc86f3feead;0bfcd43e-fc3f-4803-b57c-aa707bc175fe)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:09:03,483 INFO Processing question 1
2025-12-14 18:09:03,483 INFO Processing question 1
2025-12-14 18:09:03,487 INFO Processing question 2
2025-12-14 18:09:03,487 INFO Processing question 2
2025-12-14 18:09:03,491 INFO Processing question 3
2025-12-14 18:09:03,491 INFO Processing question 3
2025-12-14 18:09:03,494 INFO Processing question 4
2025-12-14 18:09:03,494 INFO Processing question 4
2025-12-14 18:09:03,497 INFO Processing question 5
2025-12-14 18:09:03,497 INFO Processing question 5
2025-12-14 18:09:03,500 INFO Processing question 6
2025-12-14 18:09:03,500 INFO Processing question 6
2025-12-14 18:09:03,503 INFO Processing question 7
2025-12-14 18:09:03,503 INFO Processing question 7
2025-12-14 18:09:03,506 INFO Processing question 8
2025-12-14 18:09:03,506 INFO Processing question 8
2025-12-14 18:09:03,509 INFO Processing question 9
2025-12-14 18:09:03,509 INFO Processing question 9
2025-12-14 18:09:03,511 INFO Processing question 10
2025-12-14 18:09:03,511 INFO Processing question 10
2025-12-14 18:09:03,514 INFO Processing question 11
2025-12-14 18:09:03,514 INFO Processing question 11
2025-12-14 18:09:03,516 INFO Processing question 12
2025-12-14 18:09:03,516 INFO Processing question 12
2025-12-14 18:09:03,519 INFO Processing question 13
2025-12-14 18:09:03,519 INFO Processing question 13
2025-12-14 18:09:03,521 INFO Processing question 14
2025-12-14 18:09:03,521 INFO Processing question 14
2025-12-14 18:09:03,524 INFO Processing question 15
2025-12-14 18:09:03,524 INFO Processing question 15
2025-12-14 18:09:03,524 INFO Wrote analysis to ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:09:03,524 INFO Wrote analysis to ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:09:03,524 INFO Report generation finished: ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:09:03,614 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f5faf-24c56ed66b591dbd1e349811;d42b99c1-1abe-4156-836d-2e123ba6af95)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 102, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f5faf-24c56ed66b591dbd1e349811;d42b99c1-1abe-4156-836d-2e123ba6af95)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:09:03,614 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f5faf-24c56ed66b591dbd1e349811;d42b99c1-1abe-4156-836d-2e123ba6af95)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 102, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f5faf-24c56ed66b591dbd1e349811;d42b99c1-1abe-4156-836d-2e123ba6af95)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:09:03,618 INFO Processing question 1
2025-12-14 18:09:03,618 INFO Processing question 1
2025-12-14 18:09:03,621 INFO Processing question 2
2025-12-14 18:09:03,621 INFO Processing question 2
2025-12-14 18:09:03,625 INFO Processing question 3
2025-12-14 18:09:03,625 INFO Processing question 3
2025-12-14 18:09:03,628 INFO Processing question 4
2025-12-14 18:09:03,628 INFO Processing question 4
2025-12-14 18:09:03,630 INFO Processing question 5
2025-12-14 18:09:03,630 INFO Processing question 5
2025-12-14 18:09:03,633 INFO Processing question 6
2025-12-14 18:09:03,633 INFO Processing question 6
2025-12-14 18:09:03,636 INFO Processing question 7
2025-12-14 18:09:03,636 INFO Processing question 7
2025-12-14 18:09:03,639 INFO Processing question 8
2025-12-14 18:09:03,639 INFO Processing question 8
2025-12-14 18:09:03,641 INFO Processing question 9
2025-12-14 18:09:03,641 INFO Processing question 9
2025-12-14 18:09:03,644 INFO Processing question 10
2025-12-14 18:09:03,644 INFO Processing question 10
2025-12-14 18:09:03,646 INFO Processing question 11
2025-12-14 18:09:03,646 INFO Processing question 11
2025-12-14 18:09:03,649 INFO Processing question 12
2025-12-14 18:09:03,649 INFO Processing question 12
2025-12-14 18:09:03,651 INFO Processing question 13
2025-12-14 18:09:03,651 INFO Processing question 13
2025-12-14 18:09:03,654 INFO Processing question 14
2025-12-14 18:09:03,654 INFO Processing question 14
2025-12-14 18:09:03,656 INFO Processing question 15
2025-12-14 18:09:03,656 INFO Processing question 15
2025-12-14 18:09:03,656 INFO Wrote analysis to ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:09:03,656 INFO Wrote analysis to ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:09:03,656 INFO Report generation finished: ./llm_analyses/Test Title-llm-analysis.txt
2025-12-14 18:12:07,946 INFO  * Detected change in '/Users/nihaarikaagarwal/Downloads/moral-compass/app.py', reloading
2025-12-14 18:12:08,662 INFO  * Restarting with stat
2025-12-14 18:12:08,833 WARNING  * Debugger is active!
2025-12-14 18:12:08,838 INFO  * Debugger PIN: 255-579-290
2025-12-14 18:52:07,972 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 18:52:07,972 INFO [33mPress CTRL+C to quit[0m
2025-12-14 18:52:18,874 INFO 127.0.0.1 - - [14/Dec/2025 18:52:18] "GET / HTTP/1.1" 200 -
2025-12-14 18:52:18,975 INFO 127.0.0.1 - - [14/Dec/2025 18:52:18] "GET /static/css/form.css HTTP/1.1" 200 -
2025-12-14 18:52:18,975 INFO 127.0.0.1 - - [14/Dec/2025 18:52:18] "GET /static/js/form.js HTTP/1.1" 200 -
2025-12-14 18:52:19,074 INFO 127.0.0.1 - - [14/Dec/2025 18:52:19] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-12-14 18:53:19,002 INFO Received form responses; launching background generation
2025-12-14 18:53:19,003 INFO Background report generation started
2025-12-14 18:53:19,005 INFO 127.0.0.1 - - [14/Dec/2025 18:53:19] "POST /submit HTTP/1.1" 200 -
2025-12-14 18:53:19,010 INFO Starting report generation
2025-12-14 18:53:19,010 INFO Starting report generation
2025-12-14 18:53:19,054 INFO 127.0.0.1 - - [14/Dec/2025 18:53:19] "GET /static/css/submit_success.css HTTP/1.1" 200 -
2025-12-14 18:53:19,075 INFO 127.0.0.1 - - [14/Dec/2025 18:53:19] "GET /reports/status HTTP/1.1" 200 -
2025-12-14 18:53:20,702 INFO Loading faiss.
2025-12-14 18:53:20,730 INFO Successfully loaded faiss.
2025-12-14 18:53:23,790 INFO 127.0.0.1 - - [14/Dec/2025 18:53:23] "GET /reports/latest HTTP/1.1" 200 -
2025-12-14 18:53:31,901 INFO Received form responses; launching background generation
2025-12-14 18:53:31,919 INFO Background report generation started
2025-12-14 18:53:31,919 INFO 127.0.0.1 - - [14/Dec/2025 18:53:31] "POST /submit HTTP/1.1" 200 -
2025-12-14 18:53:31,925 INFO Starting report generation
2025-12-14 18:53:31,925 INFO Starting report generation
2025-12-14 18:53:31,956 INFO 127.0.0.1 - - [14/Dec/2025 18:53:31] "[36mGET /static/css/submit_success.css HTTP/1.1[0m" 304 -
2025-12-14 18:53:31,993 INFO 127.0.0.1 - - [14/Dec/2025 18:53:31] "GET /reports/status HTTP/1.1" 200 -
2025-12-14 18:53:34,241 INFO Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d20,n5,w5,mc5,s0.001,t3>', 'datetime': '2025-12-14T18:53:34.228053', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'created'}
2025-12-14 18:53:34,241 INFO collecting all words and their counts
2025-12-14 18:53:34,241 INFO PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2025-12-14 18:53:34,254 INFO collected 8045 word types and 22 unique tags from a corpus of 22 examples and 182922 words
2025-12-14 18:53:34,254 INFO Creating a fresh vocabulary
2025-12-14 18:53:34,258 INFO Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 2492 unique words (30.98% of original 8045, drops 5553)', 'datetime': '2025-12-14T18:53:34.258822', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 18:53:34,258 INFO Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 174109 word corpus (95.18% of original 182922, drops 8813)', 'datetime': '2025-12-14T18:53:34.258870', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 18:53:34,263 INFO deleting the raw counts dictionary of 8045 items
2025-12-14 18:53:34,263 INFO sample=0.001 downsamples 48 most-common words
2025-12-14 18:53:34,263 INFO Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 117305.50818736776 word corpus (67.4%% of prior 174109)', 'datetime': '2025-12-14T18:53:34.263664', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 18:53:34,271 INFO estimated required memory for 2492 words and 20 dimensions: 1650880 bytes
2025-12-14 18:53:34,271 INFO resetting layer weights
2025-12-14 18:53:34,271 INFO Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 2492 vocabulary and 20 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-12-14T18:53:34.271846', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}
2025-12-14 18:53:34,292 INFO EPOCH 0: training on 182922 raw words (78527 effective words) took 0.0s, 4040563 effective words/s
2025-12-14 18:53:34,311 INFO EPOCH 1: training on 182922 raw words (78601 effective words) took 0.0s, 4191383 effective words/s
2025-12-14 18:53:34,330 INFO EPOCH 2: training on 182922 raw words (78615 effective words) took 0.0s, 4220543 effective words/s
2025-12-14 18:53:34,349 INFO EPOCH 3: training on 182922 raw words (78603 effective words) took 0.0s, 4189888 effective words/s
2025-12-14 18:53:34,368 INFO EPOCH 4: training on 182922 raw words (78569 effective words) took 0.0s, 4170707 effective words/s
2025-12-14 18:53:34,387 INFO EPOCH 5: training on 182922 raw words (78634 effective words) took 0.0s, 4177392 effective words/s
2025-12-14 18:53:34,406 INFO EPOCH 6: training on 182922 raw words (78567 effective words) took 0.0s, 4176217 effective words/s
2025-12-14 18:53:34,425 INFO EPOCH 7: training on 182922 raw words (78612 effective words) took 0.0s, 4153669 effective words/s
2025-12-14 18:53:34,444 INFO EPOCH 8: training on 182922 raw words (78576 effective words) took 0.0s, 4173506 effective words/s
2025-12-14 18:53:34,464 INFO EPOCH 9: training on 182922 raw words (78584 effective words) took 0.0s, 4147013 effective words/s
2025-12-14 18:53:34,483 INFO EPOCH 10: training on 182922 raw words (78638 effective words) took 0.0s, 4138579 effective words/s
2025-12-14 18:53:34,502 INFO EPOCH 11: training on 182922 raw words (78622 effective words) took 0.0s, 4107545 effective words/s
2025-12-14 18:53:34,521 INFO EPOCH 12: training on 182922 raw words (78606 effective words) took 0.0s, 4144493 effective words/s
2025-12-14 18:53:34,541 INFO EPOCH 13: training on 182922 raw words (78558 effective words) took 0.0s, 4107509 effective words/s
2025-12-14 18:53:34,560 INFO EPOCH 14: training on 182922 raw words (78546 effective words) took 0.0s, 4112338 effective words/s
2025-12-14 18:53:34,579 INFO EPOCH 15: training on 182922 raw words (78569 effective words) took 0.0s, 4111192 effective words/s
2025-12-14 18:53:34,598 INFO EPOCH 16: training on 182922 raw words (78593 effective words) took 0.0s, 4116774 effective words/s
2025-12-14 18:53:34,618 INFO EPOCH 17: training on 182922 raw words (78543 effective words) took 0.0s, 4136055 effective words/s
2025-12-14 18:53:34,637 INFO EPOCH 18: training on 182922 raw words (78561 effective words) took 0.0s, 4093353 effective words/s
2025-12-14 18:53:34,656 INFO EPOCH 19: training on 182922 raw words (78585 effective words) took 0.0s, 4084230 effective words/s
2025-12-14 18:53:34,676 INFO EPOCH 20: training on 182922 raw words (78672 effective words) took 0.0s, 4105170 effective words/s
2025-12-14 18:53:34,695 INFO EPOCH 21: training on 182922 raw words (78571 effective words) took 0.0s, 4114509 effective words/s
2025-12-14 18:53:34,715 INFO EPOCH 22: training on 182922 raw words (78600 effective words) took 0.0s, 4084010 effective words/s
2025-12-14 18:53:34,734 INFO EPOCH 23: training on 182922 raw words (78552 effective words) took 0.0s, 4070649 effective words/s
2025-12-14 18:53:34,753 INFO EPOCH 24: training on 182922 raw words (78576 effective words) took 0.0s, 4097159 effective words/s
2025-12-14 18:53:34,773 INFO EPOCH 25: training on 182922 raw words (78609 effective words) took 0.0s, 4049523 effective words/s
2025-12-14 18:53:34,793 INFO EPOCH 26: training on 182922 raw words (78543 effective words) took 0.0s, 4058309 effective words/s
2025-12-14 18:53:34,812 INFO EPOCH 27: training on 182922 raw words (78618 effective words) took 0.0s, 4062885 effective words/s
2025-12-14 18:53:34,832 INFO EPOCH 28: training on 182922 raw words (78555 effective words) took 0.0s, 4071332 effective words/s
2025-12-14 18:53:34,851 INFO EPOCH 29: training on 182922 raw words (78594 effective words) took 0.0s, 4055427 effective words/s
2025-12-14 18:53:34,871 INFO EPOCH 30: training on 182922 raw words (78572 effective words) took 0.0s, 4064121 effective words/s
2025-12-14 18:53:34,890 INFO EPOCH 31: training on 182922 raw words (78641 effective words) took 0.0s, 4071947 effective words/s
2025-12-14 18:53:34,910 INFO EPOCH 32: training on 182922 raw words (78581 effective words) took 0.0s, 4037974 effective words/s
2025-12-14 18:53:34,929 INFO EPOCH 33: training on 182922 raw words (78673 effective words) took 0.0s, 4068758 effective words/s
2025-12-14 18:53:34,949 INFO EPOCH 34: training on 182922 raw words (78483 effective words) took 0.0s, 4021143 effective words/s
2025-12-14 18:53:34,969 INFO EPOCH 35: training on 182922 raw words (78588 effective words) took 0.0s, 4055414 effective words/s
2025-12-14 18:53:34,988 INFO EPOCH 36: training on 182922 raw words (78548 effective words) took 0.0s, 4068299 effective words/s
2025-12-14 18:53:35,008 INFO EPOCH 37: training on 182922 raw words (78714 effective words) took 0.0s, 4054314 effective words/s
2025-12-14 18:53:35,033 INFO EPOCH 38: training on 182922 raw words (78528 effective words) took 0.0s, 3088447 effective words/s
2025-12-14 18:53:35,056 INFO EPOCH 39: training on 182922 raw words (78565 effective words) took 0.0s, 3498373 effective words/s
2025-12-14 18:53:35,083 INFO EPOCH 40: training on 182922 raw words (78578 effective words) took 0.0s, 3763374 effective words/s
2025-12-14 18:53:35,104 INFO EPOCH 41: training on 182922 raw words (78632 effective words) took 0.0s, 3734430 effective words/s
2025-12-14 18:53:35,125 INFO EPOCH 42: training on 182922 raw words (78617 effective words) took 0.0s, 3859845 effective words/s
2025-12-14 18:53:35,146 INFO EPOCH 43: training on 182922 raw words (78519 effective words) took 0.0s, 3803117 effective words/s
2025-12-14 18:53:35,166 INFO EPOCH 44: training on 182922 raw words (78549 effective words) took 0.0s, 4007798 effective words/s
2025-12-14 18:53:35,186 INFO EPOCH 45: training on 182922 raw words (78599 effective words) took 0.0s, 3985498 effective words/s
2025-12-14 18:53:35,206 INFO EPOCH 46: training on 182922 raw words (78622 effective words) took 0.0s, 4001332 effective words/s
2025-12-14 18:53:35,235 INFO EPOCH 47: training on 182922 raw words (78579 effective words) took 0.0s, 2708154 effective words/s
2025-12-14 18:53:35,255 INFO EPOCH 48: training on 182922 raw words (78612 effective words) took 0.0s, 3976881 effective words/s
2025-12-14 18:53:35,275 INFO EPOCH 49: training on 182922 raw words (78632 effective words) took 0.0s, 3999186 effective words/s
2025-12-14 18:53:35,295 INFO EPOCH 50: training on 182922 raw words (78545 effective words) took 0.0s, 3980313 effective words/s
2025-12-14 18:53:35,315 INFO EPOCH 51: training on 182922 raw words (78575 effective words) took 0.0s, 4009909 effective words/s
2025-12-14 18:53:35,335 INFO EPOCH 52: training on 182922 raw words (78550 effective words) took 0.0s, 3991522 effective words/s
2025-12-14 18:53:35,354 INFO EPOCH 53: training on 182922 raw words (78537 effective words) took 0.0s, 3993754 effective words/s
2025-12-14 18:53:35,374 INFO EPOCH 54: training on 182922 raw words (78589 effective words) took 0.0s, 4021046 effective words/s
2025-12-14 18:53:35,394 INFO EPOCH 55: training on 182922 raw words (78618 effective words) took 0.0s, 3975500 effective words/s
2025-12-14 18:53:35,414 INFO EPOCH 56: training on 182922 raw words (78500 effective words) took 0.0s, 3981117 effective words/s
2025-12-14 18:53:35,434 INFO EPOCH 57: training on 182922 raw words (78603 effective words) took 0.0s, 3962536 effective words/s
2025-12-14 18:53:35,454 INFO EPOCH 58: training on 182922 raw words (78545 effective words) took 0.0s, 4007066 effective words/s
2025-12-14 18:53:35,474 INFO EPOCH 59: training on 182922 raw words (78570 effective words) took 0.0s, 3990832 effective words/s
2025-12-14 18:53:35,493 INFO EPOCH 60: training on 182922 raw words (78572 effective words) took 0.0s, 4031918 effective words/s
2025-12-14 18:53:35,513 INFO EPOCH 61: training on 182922 raw words (78598 effective words) took 0.0s, 4020050 effective words/s
2025-12-14 18:53:35,533 INFO EPOCH 62: training on 182922 raw words (78585 effective words) took 0.0s, 3997787 effective words/s
2025-12-14 18:53:35,555 INFO EPOCH 63: training on 182922 raw words (78609 effective words) took 0.0s, 3632068 effective words/s
2025-12-14 18:53:35,576 INFO EPOCH 64: training on 182922 raw words (78639 effective words) took 0.0s, 3809344 effective words/s
2025-12-14 18:53:35,598 INFO EPOCH 65: training on 182922 raw words (78589 effective words) took 0.0s, 3554884 effective words/s
2025-12-14 18:53:35,619 INFO EPOCH 66: training on 182922 raw words (78587 effective words) took 0.0s, 3906036 effective words/s
2025-12-14 18:53:35,640 INFO EPOCH 67: training on 182922 raw words (78552 effective words) took 0.0s, 3777204 effective words/s
2025-12-14 18:53:35,662 INFO EPOCH 68: training on 182922 raw words (78706 effective words) took 0.0s, 3603363 effective words/s
2025-12-14 18:53:35,682 INFO EPOCH 69: training on 182922 raw words (78675 effective words) took 0.0s, 3963401 effective words/s
2025-12-14 18:53:35,702 INFO EPOCH 70: training on 182922 raw words (78599 effective words) took 0.0s, 3947516 effective words/s
2025-12-14 18:53:35,722 INFO EPOCH 71: training on 182922 raw words (78566 effective words) took 0.0s, 3953313 effective words/s
2025-12-14 18:53:35,742 INFO EPOCH 72: training on 182922 raw words (78538 effective words) took 0.0s, 3971856 effective words/s
2025-12-14 18:53:35,762 INFO EPOCH 73: training on 182922 raw words (78581 effective words) took 0.0s, 3957470 effective words/s
2025-12-14 18:53:35,782 INFO EPOCH 74: training on 182922 raw words (78671 effective words) took 0.0s, 3987144 effective words/s
2025-12-14 18:53:35,802 INFO EPOCH 75: training on 182922 raw words (78607 effective words) took 0.0s, 3999983 effective words/s
2025-12-14 18:53:35,822 INFO EPOCH 76: training on 182922 raw words (78593 effective words) took 0.0s, 3975467 effective words/s
2025-12-14 18:53:35,842 INFO EPOCH 77: training on 182922 raw words (78626 effective words) took 0.0s, 3973385 effective words/s
2025-12-14 18:53:35,862 INFO EPOCH 78: training on 182922 raw words (78611 effective words) took 0.0s, 3945329 effective words/s
2025-12-14 18:53:35,882 INFO EPOCH 79: training on 182922 raw words (78603 effective words) took 0.0s, 3975713 effective words/s
2025-12-14 18:53:35,902 INFO EPOCH 80: training on 182922 raw words (78620 effective words) took 0.0s, 3981028 effective words/s
2025-12-14 18:53:35,922 INFO EPOCH 81: training on 182922 raw words (78612 effective words) took 0.0s, 3972209 effective words/s
2025-12-14 18:53:35,942 INFO EPOCH 82: training on 182922 raw words (78580 effective words) took 0.0s, 4002233 effective words/s
2025-12-14 18:53:35,962 INFO EPOCH 83: training on 182922 raw words (78608 effective words) took 0.0s, 3947539 effective words/s
2025-12-14 18:53:35,982 INFO EPOCH 84: training on 182922 raw words (78538 effective words) took 0.0s, 3966758 effective words/s
2025-12-14 18:53:36,002 INFO EPOCH 85: training on 182922 raw words (78661 effective words) took 0.0s, 3975405 effective words/s
2025-12-14 18:53:36,022 INFO EPOCH 86: training on 182922 raw words (78564 effective words) took 0.0s, 3974662 effective words/s
2025-12-14 18:53:36,042 INFO EPOCH 87: training on 182922 raw words (78548 effective words) took 0.0s, 3921534 effective words/s
2025-12-14 18:53:36,063 INFO EPOCH 88: training on 182922 raw words (78624 effective words) took 0.0s, 3941119 effective words/s
2025-12-14 18:53:36,083 INFO EPOCH 89: training on 182922 raw words (78578 effective words) took 0.0s, 3971938 effective words/s
2025-12-14 18:53:36,103 INFO EPOCH 90: training on 182922 raw words (78621 effective words) took 0.0s, 3917648 effective words/s
2025-12-14 18:53:36,123 INFO EPOCH 91: training on 182922 raw words (78598 effective words) took 0.0s, 3930408 effective words/s
2025-12-14 18:53:36,143 INFO EPOCH 92: training on 182922 raw words (78587 effective words) took 0.0s, 3942121 effective words/s
2025-12-14 18:53:36,163 INFO EPOCH 93: training on 182922 raw words (78641 effective words) took 0.0s, 3962994 effective words/s
2025-12-14 18:53:36,185 INFO EPOCH 94: training on 182922 raw words (78549 effective words) took 0.0s, 3976032 effective words/s
2025-12-14 18:53:36,205 INFO EPOCH 95: training on 182922 raw words (78602 effective words) took 0.0s, 3978019 effective words/s
2025-12-14 18:53:36,225 INFO EPOCH 96: training on 182922 raw words (78618 effective words) took 0.0s, 3943437 effective words/s
2025-12-14 18:53:36,245 INFO EPOCH 97: training on 182922 raw words (78558 effective words) took 0.0s, 3942520 effective words/s
2025-12-14 18:53:36,266 INFO EPOCH 98: training on 182922 raw words (78657 effective words) took 0.0s, 3908633 effective words/s
2025-12-14 18:53:36,286 INFO EPOCH 99: training on 182922 raw words (78580 effective words) took 0.0s, 3951739 effective words/s
2025-12-14 18:53:36,306 INFO EPOCH 100: training on 182922 raw words (78605 effective words) took 0.0s, 3915282 effective words/s
2025-12-14 18:53:36,326 INFO EPOCH 101: training on 182922 raw words (78642 effective words) took 0.0s, 3985287 effective words/s
2025-12-14 18:53:36,346 INFO EPOCH 102: training on 182922 raw words (78600 effective words) took 0.0s, 3959847 effective words/s
2025-12-14 18:53:36,368 INFO EPOCH 103: training on 182922 raw words (78556 effective words) took 0.0s, 3578060 effective words/s
2025-12-14 18:53:36,389 INFO EPOCH 104: training on 182922 raw words (78530 effective words) took 0.0s, 3842783 effective words/s
2025-12-14 18:53:36,409 INFO EPOCH 105: training on 182922 raw words (78638 effective words) took 0.0s, 3931245 effective words/s
2025-12-14 18:53:36,429 INFO EPOCH 106: training on 182922 raw words (78558 effective words) took 0.0s, 3987733 effective words/s
2025-12-14 18:53:36,450 INFO EPOCH 107: training on 182922 raw words (78585 effective words) took 0.0s, 3890764 effective words/s
2025-12-14 18:53:36,472 INFO EPOCH 108: training on 182922 raw words (78655 effective words) took 0.0s, 3532886 effective words/s
2025-12-14 18:53:36,493 INFO EPOCH 109: training on 182922 raw words (78568 effective words) took 0.0s, 3849218 effective words/s
2025-12-14 18:53:36,516 INFO EPOCH 110: training on 182922 raw words (78590 effective words) took 0.0s, 3429650 effective words/s
2025-12-14 18:53:36,537 INFO EPOCH 111: training on 182922 raw words (78587 effective words) took 0.0s, 3817853 effective words/s
2025-12-14 18:53:36,557 INFO EPOCH 112: training on 182922 raw words (78541 effective words) took 0.0s, 3970828 effective words/s
2025-12-14 18:53:36,577 INFO EPOCH 113: training on 182922 raw words (78571 effective words) took 0.0s, 3941656 effective words/s
2025-12-14 18:53:36,597 INFO EPOCH 114: training on 182922 raw words (78574 effective words) took 0.0s, 3972815 effective words/s
2025-12-14 18:53:36,617 INFO EPOCH 115: training on 182922 raw words (78497 effective words) took 0.0s, 3954335 effective words/s
2025-12-14 18:53:36,637 INFO EPOCH 116: training on 182922 raw words (78602 effective words) took 0.0s, 3964125 effective words/s
2025-12-14 18:53:36,658 INFO EPOCH 117: training on 182922 raw words (78632 effective words) took 0.0s, 3960063 effective words/s
2025-12-14 18:53:36,678 INFO EPOCH 118: training on 182922 raw words (78650 effective words) took 0.0s, 3977420 effective words/s
2025-12-14 18:53:36,698 INFO EPOCH 119: training on 182922 raw words (78607 effective words) took 0.0s, 3978271 effective words/s
2025-12-14 18:53:36,717 INFO EPOCH 120: training on 182922 raw words (78571 effective words) took 0.0s, 3984861 effective words/s
2025-12-14 18:53:36,737 INFO EPOCH 121: training on 182922 raw words (78602 effective words) took 0.0s, 3985608 effective words/s
2025-12-14 18:53:36,757 INFO EPOCH 122: training on 182922 raw words (78636 effective words) took 0.0s, 3996299 effective words/s
2025-12-14 18:53:36,777 INFO EPOCH 123: training on 182922 raw words (78592 effective words) took 0.0s, 3954629 effective words/s
2025-12-14 18:53:36,797 INFO EPOCH 124: training on 182922 raw words (78558 effective words) took 0.0s, 3977284 effective words/s
2025-12-14 18:53:36,817 INFO EPOCH 125: training on 182922 raw words (78624 effective words) took 0.0s, 3962945 effective words/s
2025-12-14 18:53:36,837 INFO EPOCH 126: training on 182922 raw words (78546 effective words) took 0.0s, 3973911 effective words/s
2025-12-14 18:53:36,857 INFO EPOCH 127: training on 182922 raw words (78619 effective words) took 0.0s, 3981347 effective words/s
2025-12-14 18:53:36,877 INFO EPOCH 128: training on 182922 raw words (78471 effective words) took 0.0s, 3968351 effective words/s
2025-12-14 18:53:36,897 INFO EPOCH 129: training on 182922 raw words (78601 effective words) took 0.0s, 3952099 effective words/s
2025-12-14 18:53:36,917 INFO EPOCH 130: training on 182922 raw words (78648 effective words) took 0.0s, 3952765 effective words/s
2025-12-14 18:53:36,937 INFO EPOCH 131: training on 182922 raw words (78599 effective words) took 0.0s, 3954285 effective words/s
2025-12-14 18:53:36,957 INFO EPOCH 132: training on 182922 raw words (78510 effective words) took 0.0s, 3965210 effective words/s
2025-12-14 18:53:36,977 INFO EPOCH 133: training on 182922 raw words (78601 effective words) took 0.0s, 3962360 effective words/s
2025-12-14 18:53:36,998 INFO EPOCH 134: training on 182922 raw words (78597 effective words) took 0.0s, 3950979 effective words/s
2025-12-14 18:53:37,018 INFO EPOCH 135: training on 182922 raw words (78599 effective words) took 0.0s, 3966191 effective words/s
2025-12-14 18:53:37,037 INFO EPOCH 136: training on 182922 raw words (78537 effective words) took 0.0s, 3989037 effective words/s
2025-12-14 18:53:37,058 INFO EPOCH 137: training on 182922 raw words (78605 effective words) took 0.0s, 3944384 effective words/s
2025-12-14 18:53:37,078 INFO EPOCH 138: training on 182922 raw words (78635 effective words) took 0.0s, 3956918 effective words/s
2025-12-14 18:53:37,098 INFO EPOCH 139: training on 182922 raw words (78621 effective words) took 0.0s, 3979072 effective words/s
2025-12-14 18:53:37,118 INFO EPOCH 140: training on 182922 raw words (78574 effective words) took 0.0s, 3963604 effective words/s
2025-12-14 18:53:37,138 INFO EPOCH 141: training on 182922 raw words (78690 effective words) took 0.0s, 3973055 effective words/s
2025-12-14 18:53:37,158 INFO EPOCH 142: training on 182922 raw words (78619 effective words) took 0.0s, 3966266 effective words/s
2025-12-14 18:53:37,178 INFO EPOCH 143: training on 182922 raw words (78611 effective words) took 0.0s, 3967264 effective words/s
2025-12-14 18:53:37,198 INFO EPOCH 144: training on 182922 raw words (78556 effective words) took 0.0s, 3967767 effective words/s
2025-12-14 18:53:37,218 INFO EPOCH 145: training on 182922 raw words (78602 effective words) took 0.0s, 3982284 effective words/s
2025-12-14 18:53:37,238 INFO EPOCH 146: training on 182922 raw words (78649 effective words) took 0.0s, 3974656 effective words/s
2025-12-14 18:53:37,258 INFO EPOCH 147: training on 182922 raw words (78675 effective words) took 0.0s, 3972582 effective words/s
2025-12-14 18:53:37,277 INFO EPOCH 148: training on 182922 raw words (78571 effective words) took 0.0s, 4003065 effective words/s
2025-12-14 18:53:37,297 INFO EPOCH 149: training on 182922 raw words (78723 effective words) took 0.0s, 3969369 effective words/s
2025-12-14 18:53:37,317 INFO EPOCH 150: training on 182922 raw words (78592 effective words) took 0.0s, 3977219 effective words/s
2025-12-14 18:53:37,337 INFO EPOCH 151: training on 182922 raw words (78567 effective words) took 0.0s, 3963010 effective words/s
2025-12-14 18:53:37,357 INFO EPOCH 152: training on 182922 raw words (78554 effective words) took 0.0s, 3980752 effective words/s
2025-12-14 18:53:37,377 INFO EPOCH 153: training on 182922 raw words (78667 effective words) took 0.0s, 3985712 effective words/s
2025-12-14 18:53:37,397 INFO EPOCH 154: training on 182922 raw words (78590 effective words) took 0.0s, 3982938 effective words/s
2025-12-14 18:53:37,417 INFO EPOCH 155: training on 182922 raw words (78553 effective words) took 0.0s, 3986163 effective words/s
2025-12-14 18:53:37,437 INFO EPOCH 156: training on 182922 raw words (78628 effective words) took 0.0s, 3977950 effective words/s
2025-12-14 18:53:37,457 INFO EPOCH 157: training on 182922 raw words (78614 effective words) took 0.0s, 3983919 effective words/s
2025-12-14 18:53:37,477 INFO EPOCH 158: training on 182922 raw words (78660 effective words) took 0.0s, 3995911 effective words/s
2025-12-14 18:53:37,497 INFO EPOCH 159: training on 182922 raw words (78498 effective words) took 0.0s, 3989944 effective words/s
2025-12-14 18:53:37,517 INFO EPOCH 160: training on 182922 raw words (78610 effective words) took 0.0s, 3952196 effective words/s
2025-12-14 18:53:37,537 INFO EPOCH 161: training on 182922 raw words (78635 effective words) took 0.0s, 3948977 effective words/s
2025-12-14 18:53:37,557 INFO EPOCH 162: training on 182922 raw words (78588 effective words) took 0.0s, 3979609 effective words/s
2025-12-14 18:53:37,577 INFO EPOCH 163: training on 182922 raw words (78557 effective words) took 0.0s, 3970709 effective words/s
2025-12-14 18:53:37,597 INFO EPOCH 164: training on 182922 raw words (78551 effective words) took 0.0s, 3970130 effective words/s
2025-12-14 18:53:37,617 INFO EPOCH 165: training on 182922 raw words (78563 effective words) took 0.0s, 3984876 effective words/s
2025-12-14 18:53:37,637 INFO EPOCH 166: training on 182922 raw words (78653 effective words) took 0.0s, 3979207 effective words/s
2025-12-14 18:53:37,657 INFO EPOCH 167: training on 182922 raw words (78582 effective words) took 0.0s, 3994391 effective words/s
2025-12-14 18:53:37,677 INFO EPOCH 168: training on 182922 raw words (78640 effective words) took 0.0s, 3963218 effective words/s
2025-12-14 18:53:37,697 INFO EPOCH 169: training on 182922 raw words (78633 effective words) took 0.0s, 3972534 effective words/s
2025-12-14 18:53:37,717 INFO EPOCH 170: training on 182922 raw words (78530 effective words) took 0.0s, 3973646 effective words/s
2025-12-14 18:53:37,737 INFO EPOCH 171: training on 182922 raw words (78586 effective words) took 0.0s, 3978752 effective words/s
2025-12-14 18:53:37,757 INFO EPOCH 172: training on 182922 raw words (78700 effective words) took 0.0s, 3964536 effective words/s
2025-12-14 18:53:37,778 INFO EPOCH 173: training on 182922 raw words (78672 effective words) took 0.0s, 3625507 effective words/s
2025-12-14 18:53:37,799 INFO EPOCH 174: training on 182922 raw words (78643 effective words) took 0.0s, 3942458 effective words/s
2025-12-14 18:53:37,819 INFO EPOCH 175: training on 182922 raw words (78542 effective words) took 0.0s, 3914866 effective words/s
2025-12-14 18:53:37,839 INFO EPOCH 176: training on 182922 raw words (78623 effective words) took 0.0s, 3922904 effective words/s
2025-12-14 18:53:37,859 INFO EPOCH 177: training on 182922 raw words (78612 effective words) took 0.0s, 3975088 effective words/s
2025-12-14 18:53:37,879 INFO EPOCH 178: training on 182922 raw words (78611 effective words) took 0.0s, 3955926 effective words/s
2025-12-14 18:53:37,900 INFO EPOCH 179: training on 182922 raw words (78548 effective words) took 0.0s, 3926713 effective words/s
2025-12-14 18:53:37,921 INFO EPOCH 180: training on 182922 raw words (78574 effective words) took 0.0s, 3783014 effective words/s
2025-12-14 18:53:37,942 INFO EPOCH 181: training on 182922 raw words (78636 effective words) took 0.0s, 3717655 effective words/s
2025-12-14 18:53:37,962 INFO EPOCH 182: training on 182922 raw words (78653 effective words) took 0.0s, 3944401 effective words/s
2025-12-14 18:53:37,982 INFO EPOCH 183: training on 182922 raw words (78625 effective words) took 0.0s, 3957750 effective words/s
2025-12-14 18:53:38,002 INFO EPOCH 184: training on 182922 raw words (78620 effective words) took 0.0s, 3954397 effective words/s
2025-12-14 18:53:38,023 INFO EPOCH 185: training on 182922 raw words (78631 effective words) took 0.0s, 3946514 effective words/s
2025-12-14 18:53:38,042 INFO EPOCH 186: training on 182922 raw words (78527 effective words) took 0.0s, 3971443 effective words/s
2025-12-14 18:53:38,063 INFO EPOCH 187: training on 182922 raw words (78584 effective words) took 0.0s, 3939286 effective words/s
2025-12-14 18:53:38,083 INFO EPOCH 188: training on 182922 raw words (78584 effective words) took 0.0s, 3936556 effective words/s
2025-12-14 18:53:38,103 INFO EPOCH 189: training on 182922 raw words (78560 effective words) took 0.0s, 3962365 effective words/s
2025-12-14 18:53:38,124 INFO EPOCH 190: training on 182922 raw words (78547 effective words) took 0.0s, 3800884 effective words/s
2025-12-14 18:53:38,144 INFO EPOCH 191: training on 182922 raw words (78552 effective words) took 0.0s, 3861377 effective words/s
2025-12-14 18:53:38,165 INFO EPOCH 192: training on 182922 raw words (78533 effective words) took 0.0s, 3935694 effective words/s
2025-12-14 18:53:38,185 INFO EPOCH 193: training on 182922 raw words (78614 effective words) took 0.0s, 3919244 effective words/s
2025-12-14 18:53:38,205 INFO EPOCH 194: training on 182922 raw words (78582 effective words) took 0.0s, 3940305 effective words/s
2025-12-14 18:53:38,226 INFO EPOCH 195: training on 182922 raw words (78669 effective words) took 0.0s, 3789002 effective words/s
2025-12-14 18:53:38,246 INFO EPOCH 196: training on 182922 raw words (78507 effective words) took 0.0s, 3901963 effective words/s
2025-12-14 18:53:38,267 INFO EPOCH 197: training on 182922 raw words (78613 effective words) took 0.0s, 3934109 effective words/s
2025-12-14 18:53:38,287 INFO EPOCH 198: training on 182922 raw words (78585 effective words) took 0.0s, 3932757 effective words/s
2025-12-14 18:53:38,307 INFO EPOCH 199: training on 182922 raw words (78641 effective words) took 0.0s, 3946389 effective words/s
2025-12-14 18:53:38,327 INFO EPOCH 200: training on 182922 raw words (78625 effective words) took 0.0s, 3966477 effective words/s
2025-12-14 18:53:38,347 INFO EPOCH 201: training on 182922 raw words (78694 effective words) took 0.0s, 3966165 effective words/s
2025-12-14 18:53:38,367 INFO EPOCH 202: training on 182922 raw words (78603 effective words) took 0.0s, 3964068 effective words/s
2025-12-14 18:53:38,387 INFO EPOCH 203: training on 182922 raw words (78540 effective words) took 0.0s, 3966683 effective words/s
2025-12-14 18:53:38,407 INFO EPOCH 204: training on 182922 raw words (78633 effective words) took 0.0s, 3958801 effective words/s
2025-12-14 18:53:38,427 INFO EPOCH 205: training on 182922 raw words (78679 effective words) took 0.0s, 3973219 effective words/s
2025-12-14 18:53:38,447 INFO EPOCH 206: training on 182922 raw words (78661 effective words) took 0.0s, 3959015 effective words/s
2025-12-14 18:53:38,467 INFO EPOCH 207: training on 182922 raw words (78544 effective words) took 0.0s, 3970303 effective words/s
2025-12-14 18:53:38,487 INFO EPOCH 208: training on 182922 raw words (78598 effective words) took 0.0s, 3954293 effective words/s
2025-12-14 18:53:38,507 INFO EPOCH 209: training on 182922 raw words (78619 effective words) took 0.0s, 3957183 effective words/s
2025-12-14 18:53:38,527 INFO EPOCH 210: training on 182922 raw words (78544 effective words) took 0.0s, 3967144 effective words/s
2025-12-14 18:53:38,547 INFO EPOCH 211: training on 182922 raw words (78642 effective words) took 0.0s, 3966201 effective words/s
2025-12-14 18:53:38,567 INFO EPOCH 212: training on 182922 raw words (78673 effective words) took 0.0s, 3973526 effective words/s
2025-12-14 18:53:38,587 INFO EPOCH 213: training on 182922 raw words (78575 effective words) took 0.0s, 3954122 effective words/s
2025-12-14 18:53:38,607 INFO EPOCH 214: training on 182922 raw words (78538 effective words) took 0.0s, 3984038 effective words/s
2025-12-14 18:53:38,627 INFO EPOCH 215: training on 182922 raw words (78589 effective words) took 0.0s, 3923222 effective words/s
2025-12-14 18:53:38,647 INFO EPOCH 216: training on 182922 raw words (78637 effective words) took 0.0s, 3978884 effective words/s
2025-12-14 18:53:38,667 INFO EPOCH 217: training on 182922 raw words (78566 effective words) took 0.0s, 3956424 effective words/s
2025-12-14 18:53:38,687 INFO EPOCH 218: training on 182922 raw words (78598 effective words) took 0.0s, 3972380 effective words/s
2025-12-14 18:53:38,707 INFO EPOCH 219: training on 182922 raw words (78541 effective words) took 0.0s, 3968529 effective words/s
2025-12-14 18:53:38,727 INFO EPOCH 220: training on 182922 raw words (78638 effective words) took 0.0s, 3977886 effective words/s
2025-12-14 18:53:38,747 INFO EPOCH 221: training on 182922 raw words (78620 effective words) took 0.0s, 3979886 effective words/s
2025-12-14 18:53:38,767 INFO EPOCH 222: training on 182922 raw words (78564 effective words) took 0.0s, 3943687 effective words/s
2025-12-14 18:53:38,788 INFO EPOCH 223: training on 182922 raw words (78562 effective words) took 0.0s, 3907950 effective words/s
2025-12-14 18:53:38,808 INFO EPOCH 224: training on 182922 raw words (78566 effective words) took 0.0s, 3920475 effective words/s
2025-12-14 18:53:38,828 INFO EPOCH 225: training on 182922 raw words (78583 effective words) took 0.0s, 3945161 effective words/s
2025-12-14 18:53:38,848 INFO EPOCH 226: training on 182922 raw words (78601 effective words) took 0.0s, 3943540 effective words/s
2025-12-14 18:53:38,868 INFO EPOCH 227: training on 182922 raw words (78548 effective words) took 0.0s, 3957444 effective words/s
2025-12-14 18:53:38,888 INFO EPOCH 228: training on 182922 raw words (78552 effective words) took 0.0s, 3965137 effective words/s
2025-12-14 18:53:38,908 INFO EPOCH 229: training on 182922 raw words (78547 effective words) took 0.0s, 3975386 effective words/s
2025-12-14 18:53:38,928 INFO EPOCH 230: training on 182922 raw words (78528 effective words) took 0.0s, 3955722 effective words/s
2025-12-14 18:53:38,948 INFO EPOCH 231: training on 182922 raw words (78557 effective words) took 0.0s, 3974291 effective words/s
2025-12-14 18:53:38,968 INFO EPOCH 232: training on 182922 raw words (78580 effective words) took 0.0s, 3983861 effective words/s
2025-12-14 18:53:38,988 INFO EPOCH 233: training on 182922 raw words (78481 effective words) took 0.0s, 3943835 effective words/s
2025-12-14 18:53:39,008 INFO EPOCH 234: training on 182922 raw words (78503 effective words) took 0.0s, 3976530 effective words/s
2025-12-14 18:53:39,028 INFO EPOCH 235: training on 182922 raw words (78621 effective words) took 0.0s, 3991893 effective words/s
2025-12-14 18:53:39,048 INFO EPOCH 236: training on 182922 raw words (78616 effective words) took 0.0s, 3968709 effective words/s
2025-12-14 18:53:39,068 INFO EPOCH 237: training on 182922 raw words (78598 effective words) took 0.0s, 3946153 effective words/s
2025-12-14 18:53:39,089 INFO EPOCH 238: training on 182922 raw words (78572 effective words) took 0.0s, 3903568 effective words/s
2025-12-14 18:53:39,109 INFO EPOCH 239: training on 182922 raw words (78620 effective words) took 0.0s, 3846097 effective words/s
2025-12-14 18:53:39,130 INFO EPOCH 240: training on 182922 raw words (78525 effective words) took 0.0s, 3872638 effective words/s
2025-12-14 18:53:39,150 INFO EPOCH 241: training on 182922 raw words (78670 effective words) took 0.0s, 3904485 effective words/s
2025-12-14 18:53:39,170 INFO EPOCH 242: training on 182922 raw words (78610 effective words) took 0.0s, 3961549 effective words/s
2025-12-14 18:53:39,190 INFO EPOCH 243: training on 182922 raw words (78552 effective words) took 0.0s, 3947386 effective words/s
2025-12-14 18:53:39,211 INFO EPOCH 244: training on 182922 raw words (78554 effective words) took 0.0s, 3958618 effective words/s
2025-12-14 18:53:39,230 INFO EPOCH 245: training on 182922 raw words (78637 effective words) took 0.0s, 3971850 effective words/s
2025-12-14 18:53:39,250 INFO EPOCH 246: training on 182922 raw words (78587 effective words) took 0.0s, 3971422 effective words/s
2025-12-14 18:53:39,271 INFO EPOCH 247: training on 182922 raw words (78652 effective words) took 0.0s, 3961270 effective words/s
2025-12-14 18:53:39,290 INFO EPOCH 248: training on 182922 raw words (78564 effective words) took 0.0s, 3970285 effective words/s
2025-12-14 18:53:39,311 INFO EPOCH 249: training on 182922 raw words (78609 effective words) took 0.0s, 3958066 effective words/s
2025-12-14 18:53:39,331 INFO EPOCH 250: training on 182922 raw words (78539 effective words) took 0.0s, 3955578 effective words/s
2025-12-14 18:53:39,351 INFO EPOCH 251: training on 182922 raw words (78584 effective words) took 0.0s, 3959590 effective words/s
2025-12-14 18:53:39,371 INFO EPOCH 252: training on 182922 raw words (78556 effective words) took 0.0s, 3953547 effective words/s
2025-12-14 18:53:39,391 INFO EPOCH 253: training on 182922 raw words (78584 effective words) took 0.0s, 3938266 effective words/s
2025-12-14 18:53:39,411 INFO EPOCH 254: training on 182922 raw words (78534 effective words) took 0.0s, 3948540 effective words/s
2025-12-14 18:53:39,431 INFO EPOCH 255: training on 182922 raw words (78536 effective words) took 0.0s, 3966965 effective words/s
2025-12-14 18:53:39,451 INFO EPOCH 256: training on 182922 raw words (78579 effective words) took 0.0s, 3927796 effective words/s
2025-12-14 18:53:39,471 INFO EPOCH 257: training on 182922 raw words (78500 effective words) took 0.0s, 3923480 effective words/s
2025-12-14 18:53:39,492 INFO EPOCH 258: training on 182922 raw words (78621 effective words) took 0.0s, 3915258 effective words/s
2025-12-14 18:53:39,512 INFO EPOCH 259: training on 182922 raw words (78604 effective words) took 0.0s, 3915119 effective words/s
2025-12-14 18:53:39,532 INFO EPOCH 260: training on 182922 raw words (78616 effective words) took 0.0s, 3933644 effective words/s
2025-12-14 18:53:39,554 INFO EPOCH 261: training on 182922 raw words (78600 effective words) took 0.0s, 3715251 effective words/s
2025-12-14 18:53:39,577 INFO EPOCH 262: training on 182922 raw words (78562 effective words) took 0.0s, 3415857 effective words/s
2025-12-14 18:53:39,599 INFO EPOCH 263: training on 182922 raw words (78632 effective words) took 0.0s, 3614856 effective words/s
2025-12-14 18:53:39,620 INFO EPOCH 264: training on 182922 raw words (78617 effective words) took 0.0s, 3701569 effective words/s
2025-12-14 18:53:39,642 INFO EPOCH 265: training on 182922 raw words (78558 effective words) took 0.0s, 3672429 effective words/s
2025-12-14 18:53:39,667 INFO EPOCH 266: training on 182922 raw words (78629 effective words) took 0.0s, 3189084 effective words/s
2025-12-14 18:53:39,695 INFO EPOCH 267: training on 182922 raw words (78466 effective words) took 0.0s, 2836552 effective words/s
2025-12-14 18:53:39,723 INFO EPOCH 268: training on 182922 raw words (78534 effective words) took 0.0s, 2864414 effective words/s
2025-12-14 18:53:39,747 INFO EPOCH 269: training on 182922 raw words (78563 effective words) took 0.0s, 3337987 effective words/s
2025-12-14 18:53:39,770 INFO EPOCH 270: training on 182922 raw words (78589 effective words) took 0.0s, 3399889 effective words/s
2025-12-14 18:53:39,792 INFO EPOCH 271: training on 182922 raw words (78554 effective words) took 0.0s, 3609009 effective words/s
2025-12-14 18:53:39,818 INFO EPOCH 272: training on 182922 raw words (78597 effective words) took 0.0s, 3106299 effective words/s
2025-12-14 18:53:39,840 INFO EPOCH 273: training on 182922 raw words (78609 effective words) took 0.0s, 3558941 effective words/s
2025-12-14 18:53:39,865 INFO EPOCH 274: training on 182922 raw words (78592 effective words) took 0.0s, 3179192 effective words/s
2025-12-14 18:53:39,890 INFO EPOCH 275: training on 182922 raw words (78640 effective words) took 0.0s, 3303617 effective words/s
2025-12-14 18:53:39,931 INFO EPOCH 276: training on 182922 raw words (78534 effective words) took 0.0s, 1936905 effective words/s
2025-12-14 18:53:40,120 INFO EPOCH 277: training on 182922 raw words (78555 effective words) took 0.0s, 1795262 effective words/s
2025-12-14 18:53:40,152 INFO EPOCH 278: training on 182922 raw words (78523 effective words) took 0.0s, 3866025 effective words/s
2025-12-14 18:53:40,172 INFO EPOCH 279: training on 182922 raw words (78552 effective words) took 0.0s, 3925784 effective words/s
2025-12-14 18:53:40,192 INFO EPOCH 280: training on 182922 raw words (78552 effective words) took 0.0s, 3948213 effective words/s
2025-12-14 18:53:40,213 INFO EPOCH 281: training on 182922 raw words (78651 effective words) took 0.0s, 3882307 effective words/s
2025-12-14 18:53:40,277 INFO EPOCH 282: training on 182922 raw words (78587 effective words) took 0.1s, 1231713 effective words/s
2025-12-14 18:53:40,303 INFO EPOCH 283: training on 182922 raw words (78614 effective words) took 0.0s, 3265266 effective words/s
2025-12-14 18:53:40,324 INFO EPOCH 284: training on 182922 raw words (78703 effective words) took 0.0s, 3857352 effective words/s
2025-12-14 18:53:40,344 INFO EPOCH 285: training on 182922 raw words (78568 effective words) took 0.0s, 3931365 effective words/s
2025-12-14 18:53:40,364 INFO EPOCH 286: training on 182922 raw words (78597 effective words) took 0.0s, 3931586 effective words/s
2025-12-14 18:53:40,384 INFO EPOCH 287: training on 182922 raw words (78533 effective words) took 0.0s, 3924982 effective words/s
2025-12-14 18:53:40,405 INFO EPOCH 288: training on 182922 raw words (78545 effective words) took 0.0s, 3932739 effective words/s
2025-12-14 18:53:40,425 INFO EPOCH 289: training on 182922 raw words (78573 effective words) took 0.0s, 3872984 effective words/s
2025-12-14 18:53:40,445 INFO EPOCH 290: training on 182922 raw words (78564 effective words) took 0.0s, 3931091 effective words/s
2025-12-14 18:53:40,465 INFO EPOCH 291: training on 182922 raw words (78467 effective words) took 0.0s, 3934613 effective words/s
2025-12-14 18:53:40,486 INFO EPOCH 292: training on 182922 raw words (78583 effective words) took 0.0s, 3925069 effective words/s
2025-12-14 18:53:40,506 INFO EPOCH 293: training on 182922 raw words (78605 effective words) took 0.0s, 3944194 effective words/s
2025-12-14 18:53:40,526 INFO EPOCH 294: training on 182922 raw words (78655 effective words) took 0.0s, 3938140 effective words/s
2025-12-14 18:53:40,546 INFO EPOCH 295: training on 182922 raw words (78636 effective words) took 0.0s, 3938865 effective words/s
2025-12-14 18:53:40,566 INFO EPOCH 296: training on 182922 raw words (78557 effective words) took 0.0s, 3912226 effective words/s
2025-12-14 18:53:40,587 INFO EPOCH 297: training on 182922 raw words (78549 effective words) took 0.0s, 3931488 effective words/s
2025-12-14 18:53:40,607 INFO EPOCH 298: training on 182922 raw words (78722 effective words) took 0.0s, 3938192 effective words/s
2025-12-14 18:53:40,627 INFO EPOCH 299: training on 182922 raw words (78555 effective words) took 0.0s, 3934217 effective words/s
2025-12-14 18:53:40,627 INFO Doc2Vec lifecycle event {'msg': 'training on 54876600 raw words (23577274 effective words) took 6.4s, 3709659 effective words/s', 'datetime': '2025-12-14T18:53:40.627594', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}
2025-12-14 18:53:40,627 INFO Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_model.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-12-14T18:53:40.627780', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'saving'}
2025-12-14 18:53:40,628 INFO not storing attribute cum_table
2025-12-14 18:53:40,631 INFO saved doc2vec_model.model
2025-12-14 18:53:40,632 INFO loading Doc2Vec object from doc2vec_model.model
2025-12-14 18:53:40,632 INFO loading Doc2Vec object from doc2vec_model.model
2025-12-14 18:53:40,634 INFO loading dv recursively from doc2vec_model.model.dv.* with mmap=None
2025-12-14 18:53:40,634 INFO loading dv recursively from doc2vec_model.model.dv.* with mmap=None
2025-12-14 18:53:40,634 INFO loading wv recursively from doc2vec_model.model.wv.* with mmap=None
2025-12-14 18:53:40,634 INFO loading wv recursively from doc2vec_model.model.wv.* with mmap=None
2025-12-14 18:53:40,634 INFO setting ignored attribute cum_table to None
2025-12-14 18:53:40,634 INFO setting ignored attribute cum_table to None
2025-12-14 18:53:40,640 INFO Doc2Vec lifecycle event {'fname': 'doc2vec_model.model', 'datetime': '2025-12-14T18:53:40.640929', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}
2025-12-14 18:53:40,646 INFO Loaded Doc2Vec model
2025-12-14 18:53:40,646 INFO Loaded Doc2Vec model
2025-12-14 18:53:40,647 INFO Doc2Vec lifecycle event {'fname': 'doc2vec_model.model', 'datetime': '2025-12-14T18:53:40.647723', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}
2025-12-14 18:53:40,647 INFO Loaded Doc2Vec model
2025-12-14 18:53:40,647 INFO Loaded Doc2Vec model
2025-12-14 18:53:40,648 INFO Loaded FAISS index
2025-12-14 18:53:40,648 INFO Loaded FAISS index
2025-12-14 18:53:40,648 INFO Loaded FAISS index
2025-12-14 18:53:40,648 INFO Loaded FAISS index
2025-12-14 18:53:42,252 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:53:42,252 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:53:42,252 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:53:42,252 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:53:43,034 INFO Received form responses; launching background generation
2025-12-14 18:53:43,034 INFO Background report generation started
2025-12-14 18:53:43,035 INFO 127.0.0.1 - - [14/Dec/2025 18:53:43] "POST /submit HTTP/1.1" 200 -
2025-12-14 18:53:43,035 INFO Starting report generation
2025-12-14 18:53:43,035 INFO Starting report generation
2025-12-14 18:53:43,035 INFO loading Doc2Vec object from doc2vec_model.model
2025-12-14 18:53:43,036 INFO loading dv recursively from doc2vec_model.model.dv.* with mmap=None
2025-12-14 18:53:43,036 INFO loading wv recursively from doc2vec_model.model.wv.* with mmap=None
2025-12-14 18:53:43,037 INFO setting ignored attribute cum_table to None
2025-12-14 18:53:43,048 INFO Doc2Vec lifecycle event {'fname': 'doc2vec_model.model', 'datetime': '2025-12-14T18:53:43.048847', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}
2025-12-14 18:53:43,049 INFO Loaded Doc2Vec model
2025-12-14 18:53:43,049 INFO Loaded Doc2Vec model
2025-12-14 18:53:43,049 INFO Loaded FAISS index
2025-12-14 18:53:43,049 INFO Loaded FAISS index
2025-12-14 18:53:43,059 INFO 127.0.0.1 - - [14/Dec/2025 18:53:43] "[36mGET /static/css/submit_success.css HTTP/1.1[0m" 304 -
2025-12-14 18:53:43,064 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:53:43,064 INFO Initializing pipeline (device cuda? False)
2025-12-14 18:53:43,097 INFO 127.0.0.1 - - [14/Dec/2025 18:53:43] "GET /reports/status HTTP/1.1" 200 -
2025-12-14 18:53:43,249 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f6a27-2f1b24675e8692da14457b79;236dec5d-e886-426c-a9f9-79836b05ccea)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 243, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f6a27-2f1b24675e8692da14457b79;236dec5d-e886-426c-a9f9-79836b05ccea)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:53:43,249 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f6a27-2f1b24675e8692da14457b79;236dec5d-e886-426c-a9f9-79836b05ccea)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 243, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f6a27-2f1b24675e8692da14457b79;236dec5d-e886-426c-a9f9-79836b05ccea)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:53:43,257 INFO Processing question 1
2025-12-14 18:53:43,257 INFO Processing question 1
2025-12-14 18:53:43,295 INFO Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-12-14 18:53:43,600 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f6a27-2a29e6285098c6a928487e8f;8aff9bac-2585-462d-bd63-28b4e6f0eb99)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 243, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f6a27-2a29e6285098c6a928487e8f;8aff9bac-2585-462d-bd63-28b4e6f0eb99)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:53:43,600 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f6a27-2a29e6285098c6a928487e8f;8aff9bac-2585-462d-bd63-28b4e6f0eb99)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 243, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f6a27-2a29e6285098c6a928487e8f;8aff9bac-2585-462d-bd63-28b4e6f0eb99)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:53:43,602 INFO Processing question 1
2025-12-14 18:53:43,602 INFO Processing question 1
2025-12-14 18:53:43,614 INFO Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-12-14 18:53:44,212 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f6a28-19bb03856bd6c99e1f43200d;bd8008e1-e638-4ddd-895d-27091dab7e86)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 243, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f6a28-19bb03856bd6c99e1f43200d;bd8008e1-e638-4ddd-895d-27091dab7e86)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:53:44,212 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f6a28-19bb03856bd6c99e1f43200d;bd8008e1-e638-4ddd-895d-27091dab7e86)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 243, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f6a28-19bb03856bd6c99e1f43200d;bd8008e1-e638-4ddd-895d-27091dab7e86)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 18:53:44,214 INFO Processing question 1
2025-12-14 18:53:44,214 INFO Processing question 1
2025-12-14 18:53:44,225 INFO Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-12-14 18:53:47,601 INFO 127.0.0.1 - - [14/Dec/2025 18:53:47] "GET / HTTP/1.1" 200 -
2025-12-14 18:53:47,625 INFO 127.0.0.1 - - [14/Dec/2025 18:53:47] "[36mGET /static/css/form.css HTTP/1.1[0m" 304 -
2025-12-14 18:53:47,626 INFO 127.0.0.1 - - [14/Dec/2025 18:53:47] "[36mGET /static/js/form.js HTTP/1.1[0m" 304 -
2025-12-14 19:01:06,161 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 19:01:06,162 INFO [33mPress CTRL+C to quit[0m
2025-12-14 19:01:40,963 INFO Received form responses; launching background generation
2025-12-14 19:01:40,963 INFO Background report generation started
2025-12-14 19:01:40,968 INFO 127.0.0.1 - - [14/Dec/2025 19:01:40] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:01:40,970 INFO Starting report generation
2025-12-14 19:01:40,970 INFO Starting report generation
2025-12-14 19:01:42,431 INFO Loading faiss.
2025-12-14 19:01:42,464 INFO Successfully loaded faiss.
2025-12-14 19:01:55,773 INFO Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d20,n5,w5,mc5,s0.001,t3>', 'datetime': '2025-12-14T19:01:55.754091', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'created'}
2025-12-14 19:01:55,774 INFO collecting all words and their counts
2025-12-14 19:01:55,774 INFO PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2025-12-14 19:01:55,788 INFO collected 8045 word types and 22 unique tags from a corpus of 22 examples and 182922 words
2025-12-14 19:01:55,788 INFO Creating a fresh vocabulary
2025-12-14 19:01:55,792 INFO Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 2492 unique words (30.98% of original 8045, drops 5553)', 'datetime': '2025-12-14T19:01:55.792663', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 19:01:55,792 INFO Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 174109 word corpus (95.18% of original 182922, drops 8813)', 'datetime': '2025-12-14T19:01:55.792759', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 19:01:55,797 INFO deleting the raw counts dictionary of 8045 items
2025-12-14 19:01:55,798 INFO sample=0.001 downsamples 48 most-common words
2025-12-14 19:01:55,798 INFO Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 117305.50818736776 word corpus (67.4%% of prior 174109)', 'datetime': '2025-12-14T19:01:55.798137', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 19:01:55,806 INFO estimated required memory for 2492 words and 20 dimensions: 1650880 bytes
2025-12-14 19:01:55,806 INFO resetting layer weights
2025-12-14 19:01:55,807 INFO Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 2492 vocabulary and 20 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-12-14T19:01:55.807199', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}
2025-12-14 19:01:55,829 INFO EPOCH 0: training on 182922 raw words (78566 effective words) took 0.0s, 3580588 effective words/s
2025-12-14 19:01:55,849 INFO EPOCH 1: training on 182922 raw words (78623 effective words) took 0.0s, 4059812 effective words/s
2025-12-14 19:01:55,868 INFO EPOCH 2: training on 182922 raw words (78587 effective words) took 0.0s, 4179613 effective words/s
2025-12-14 19:01:55,887 INFO EPOCH 3: training on 182922 raw words (78584 effective words) took 0.0s, 4199396 effective words/s
2025-12-14 19:01:55,907 INFO EPOCH 4: training on 182922 raw words (78569 effective words) took 0.0s, 4113614 effective words/s
2025-12-14 19:01:55,925 INFO EPOCH 5: training on 182922 raw words (78646 effective words) took 0.0s, 4207966 effective words/s
2025-12-14 19:01:55,944 INFO EPOCH 6: training on 182922 raw words (78551 effective words) took 0.0s, 4208146 effective words/s
2025-12-14 19:01:55,964 INFO EPOCH 7: training on 182922 raw words (78619 effective words) took 0.0s, 4165843 effective words/s
2025-12-14 19:01:55,983 INFO EPOCH 8: training on 182922 raw words (78600 effective words) took 0.0s, 4191236 effective words/s
2025-12-14 19:01:56,002 INFO EPOCH 9: training on 182922 raw words (78535 effective words) took 0.0s, 4093865 effective words/s
2025-12-14 19:01:56,022 INFO EPOCH 10: training on 182922 raw words (78658 effective words) took 0.0s, 4158370 effective words/s
2025-12-14 19:01:56,041 INFO EPOCH 11: training on 182922 raw words (78536 effective words) took 0.0s, 4190291 effective words/s
2025-12-14 19:01:56,060 INFO EPOCH 12: training on 182922 raw words (78580 effective words) took 0.0s, 4087165 effective words/s
2025-12-14 19:01:56,079 INFO EPOCH 13: training on 182922 raw words (78625 effective words) took 0.0s, 4140591 effective words/s
2025-12-14 19:01:56,099 INFO EPOCH 14: training on 182922 raw words (78593 effective words) took 0.0s, 4094798 effective words/s
2025-12-14 19:01:56,118 INFO EPOCH 15: training on 182922 raw words (78546 effective words) took 0.0s, 4084157 effective words/s
2025-12-14 19:01:56,138 INFO EPOCH 16: training on 182922 raw words (78585 effective words) took 0.0s, 4118369 effective words/s
2025-12-14 19:01:56,157 INFO EPOCH 17: training on 182922 raw words (78574 effective words) took 0.0s, 4049119 effective words/s
2025-12-14 19:01:56,177 INFO EPOCH 18: training on 182922 raw words (78626 effective words) took 0.0s, 4066389 effective words/s
2025-12-14 19:01:56,197 INFO EPOCH 19: training on 182922 raw words (78598 effective words) took 0.0s, 4057168 effective words/s
2025-12-14 19:01:56,216 INFO EPOCH 20: training on 182922 raw words (78628 effective words) took 0.0s, 4088944 effective words/s
2025-12-14 19:01:56,236 INFO EPOCH 21: training on 182922 raw words (78591 effective words) took 0.0s, 4108895 effective words/s
2025-12-14 19:01:56,255 INFO EPOCH 22: training on 182922 raw words (78545 effective words) took 0.0s, 4106830 effective words/s
2025-12-14 19:01:56,274 INFO EPOCH 23: training on 182922 raw words (78601 effective words) took 0.0s, 4088771 effective words/s
2025-12-14 19:01:56,294 INFO EPOCH 24: training on 182922 raw words (78512 effective words) took 0.0s, 4023050 effective words/s
2025-12-14 19:01:56,314 INFO EPOCH 25: training on 182922 raw words (78616 effective words) took 0.0s, 4040266 effective words/s
2025-12-14 19:01:56,333 INFO EPOCH 26: training on 182922 raw words (78526 effective words) took 0.0s, 4115421 effective words/s
2025-12-14 19:01:56,353 INFO EPOCH 27: training on 182922 raw words (78533 effective words) took 0.0s, 4005364 effective words/s
2025-12-14 19:01:56,373 INFO EPOCH 28: training on 182922 raw words (78653 effective words) took 0.0s, 4004438 effective words/s
2025-12-14 19:01:56,392 INFO EPOCH 29: training on 182922 raw words (78578 effective words) took 0.0s, 4089312 effective words/s
2025-12-14 19:01:56,413 INFO EPOCH 30: training on 182922 raw words (78586 effective words) took 0.0s, 3863144 effective words/s
2025-12-14 19:01:56,433 INFO EPOCH 31: training on 182922 raw words (78631 effective words) took 0.0s, 4041989 effective words/s
2025-12-14 19:01:56,453 INFO EPOCH 32: training on 182922 raw words (78604 effective words) took 0.0s, 4038931 effective words/s
2025-12-14 19:01:56,473 INFO EPOCH 33: training on 182922 raw words (78589 effective words) took 0.0s, 3979811 effective words/s
2025-12-14 19:01:56,492 INFO EPOCH 34: training on 182922 raw words (78609 effective words) took 0.0s, 4076305 effective words/s
2025-12-14 19:01:56,512 INFO EPOCH 35: training on 182922 raw words (78535 effective words) took 0.0s, 4002778 effective words/s
2025-12-14 19:01:56,532 INFO EPOCH 36: training on 182922 raw words (78538 effective words) took 0.0s, 4054272 effective words/s
2025-12-14 19:01:56,551 INFO EPOCH 37: training on 182922 raw words (78714 effective words) took 0.0s, 4076800 effective words/s
2025-12-14 19:01:56,571 INFO EPOCH 38: training on 182922 raw words (78601 effective words) took 0.0s, 3997593 effective words/s
2025-12-14 19:01:56,621 INFO EPOCH 39: training on 182922 raw words (78497 effective words) took 0.0s, 1580556 effective words/s
2025-12-14 19:01:56,648 INFO EPOCH 40: training on 182922 raw words (78571 effective words) took 0.0s, 3085163 effective words/s
2025-12-14 19:01:56,668 INFO EPOCH 41: training on 182922 raw words (78501 effective words) took 0.0s, 4018385 effective words/s
2025-12-14 19:01:56,687 INFO EPOCH 42: training on 182922 raw words (78627 effective words) took 0.0s, 4041974 effective words/s
2025-12-14 19:01:56,707 INFO EPOCH 43: training on 182922 raw words (78496 effective words) took 0.0s, 4028879 effective words/s
2025-12-14 19:01:56,727 INFO EPOCH 44: training on 182922 raw words (78624 effective words) took 0.0s, 4022391 effective words/s
2025-12-14 19:01:56,746 INFO EPOCH 45: training on 182922 raw words (78541 effective words) took 0.0s, 4062579 effective words/s
2025-12-14 19:01:56,766 INFO EPOCH 46: training on 182922 raw words (78599 effective words) took 0.0s, 4087037 effective words/s
2025-12-14 19:01:56,787 INFO EPOCH 47: training on 182922 raw words (78667 effective words) took 0.0s, 3762546 effective words/s
2025-12-14 19:01:56,813 INFO EPOCH 48: training on 182922 raw words (78543 effective words) took 0.0s, 3156085 effective words/s
2025-12-14 19:01:56,832 INFO EPOCH 49: training on 182922 raw words (78553 effective words) took 0.0s, 4031296 effective words/s
2025-12-14 19:01:56,852 INFO EPOCH 50: training on 182922 raw words (78587 effective words) took 0.0s, 4074619 effective words/s
2025-12-14 19:01:56,871 INFO EPOCH 51: training on 182922 raw words (78525 effective words) took 0.0s, 4067160 effective words/s
2025-12-14 19:01:56,891 INFO EPOCH 52: training on 182922 raw words (78556 effective words) took 0.0s, 4037105 effective words/s
2025-12-14 19:01:56,911 INFO EPOCH 53: training on 182922 raw words (78624 effective words) took 0.0s, 4034336 effective words/s
2025-12-14 19:01:56,930 INFO EPOCH 54: training on 182922 raw words (78608 effective words) took 0.0s, 4073041 effective words/s
2025-12-14 19:01:56,950 INFO EPOCH 55: training on 182922 raw words (78573 effective words) took 0.0s, 4070665 effective words/s
2025-12-14 19:01:56,969 INFO EPOCH 56: training on 182922 raw words (78576 effective words) took 0.0s, 4070135 effective words/s
2025-12-14 19:01:56,989 INFO EPOCH 57: training on 182922 raw words (78601 effective words) took 0.0s, 4068655 effective words/s
2025-12-14 19:01:57,009 INFO EPOCH 58: training on 182922 raw words (78506 effective words) took 0.0s, 4052384 effective words/s
2025-12-14 19:01:57,028 INFO EPOCH 59: training on 182922 raw words (78486 effective words) took 0.0s, 4058440 effective words/s
2025-12-14 19:01:57,048 INFO EPOCH 60: training on 182922 raw words (78572 effective words) took 0.0s, 4054544 effective words/s
2025-12-14 19:01:57,067 INFO EPOCH 61: training on 182922 raw words (78654 effective words) took 0.0s, 4060260 effective words/s
2025-12-14 19:01:57,087 INFO EPOCH 62: training on 182922 raw words (78560 effective words) took 0.0s, 4076777 effective words/s
2025-12-14 19:01:57,106 INFO EPOCH 63: training on 182922 raw words (78483 effective words) took 0.0s, 4063809 effective words/s
2025-12-14 19:01:57,126 INFO EPOCH 64: training on 182922 raw words (78562 effective words) took 0.0s, 4049179 effective words/s
2025-12-14 19:01:57,146 INFO EPOCH 65: training on 182922 raw words (78605 effective words) took 0.0s, 4058245 effective words/s
2025-12-14 19:01:57,166 INFO EPOCH 66: training on 182922 raw words (78529 effective words) took 0.0s, 3911773 effective words/s
2025-12-14 19:01:57,186 INFO EPOCH 67: training on 182922 raw words (78592 effective words) took 0.0s, 4029231 effective words/s
2025-12-14 19:01:57,205 INFO EPOCH 68: training on 182922 raw words (78488 effective words) took 0.0s, 4032065 effective words/s
2025-12-14 19:01:57,225 INFO EPOCH 69: training on 182922 raw words (78587 effective words) took 0.0s, 4016243 effective words/s
2025-12-14 19:01:57,245 INFO EPOCH 70: training on 182922 raw words (78628 effective words) took 0.0s, 4002146 effective words/s
2025-12-14 19:01:57,265 INFO EPOCH 71: training on 182922 raw words (78533 effective words) took 0.0s, 4052654 effective words/s
2025-12-14 19:01:57,284 INFO EPOCH 72: training on 182922 raw words (78538 effective words) took 0.0s, 4041805 effective words/s
2025-12-14 19:01:57,304 INFO EPOCH 73: training on 182922 raw words (78520 effective words) took 0.0s, 4069747 effective words/s
2025-12-14 19:01:57,324 INFO EPOCH 74: training on 182922 raw words (78680 effective words) took 0.0s, 4036528 effective words/s
2025-12-14 19:01:57,343 INFO EPOCH 75: training on 182922 raw words (78615 effective words) took 0.0s, 4061409 effective words/s
2025-12-14 19:01:57,363 INFO EPOCH 76: training on 182922 raw words (78584 effective words) took 0.0s, 4032758 effective words/s
2025-12-14 19:01:57,383 INFO EPOCH 77: training on 182922 raw words (78615 effective words) took 0.0s, 4045941 effective words/s
2025-12-14 19:01:57,402 INFO EPOCH 78: training on 182922 raw words (78556 effective words) took 0.0s, 4033192 effective words/s
2025-12-14 19:01:57,422 INFO EPOCH 79: training on 182922 raw words (78552 effective words) took 0.0s, 4042248 effective words/s
2025-12-14 19:01:57,442 INFO EPOCH 80: training on 182922 raw words (78532 effective words) took 0.0s, 4038535 effective words/s
2025-12-14 19:01:57,461 INFO EPOCH 81: training on 182922 raw words (78544 effective words) took 0.0s, 4033103 effective words/s
2025-12-14 19:01:57,481 INFO EPOCH 82: training on 182922 raw words (78700 effective words) took 0.0s, 4052749 effective words/s
2025-12-14 19:01:57,501 INFO EPOCH 83: training on 182922 raw words (78617 effective words) took 0.0s, 4039297 effective words/s
2025-12-14 19:01:57,520 INFO EPOCH 84: training on 182922 raw words (78538 effective words) took 0.0s, 4051265 effective words/s
2025-12-14 19:01:57,540 INFO EPOCH 85: training on 182922 raw words (78579 effective words) took 0.0s, 4073289 effective words/s
2025-12-14 19:01:57,559 INFO EPOCH 86: training on 182922 raw words (78659 effective words) took 0.0s, 4062117 effective words/s
2025-12-14 19:01:57,579 INFO EPOCH 87: training on 182922 raw words (78616 effective words) took 0.0s, 4057207 effective words/s
2025-12-14 19:01:57,598 INFO EPOCH 88: training on 182922 raw words (78558 effective words) took 0.0s, 4067974 effective words/s
2025-12-14 19:01:57,618 INFO EPOCH 89: training on 182922 raw words (78698 effective words) took 0.0s, 4046690 effective words/s
2025-12-14 19:01:57,638 INFO EPOCH 90: training on 182922 raw words (78547 effective words) took 0.0s, 4048093 effective words/s
2025-12-14 19:01:57,657 INFO EPOCH 91: training on 182922 raw words (78595 effective words) took 0.0s, 4036965 effective words/s
2025-12-14 19:01:57,677 INFO EPOCH 92: training on 182922 raw words (78614 effective words) took 0.0s, 4034280 effective words/s
2025-12-14 19:01:57,697 INFO EPOCH 93: training on 182922 raw words (78686 effective words) took 0.0s, 4049674 effective words/s
2025-12-14 19:01:57,716 INFO EPOCH 94: training on 182922 raw words (78538 effective words) took 0.0s, 4041407 effective words/s
2025-12-14 19:01:57,736 INFO EPOCH 95: training on 182922 raw words (78630 effective words) took 0.0s, 4016405 effective words/s
2025-12-14 19:01:57,756 INFO EPOCH 96: training on 182922 raw words (78574 effective words) took 0.0s, 4035912 effective words/s
2025-12-14 19:01:57,776 INFO EPOCH 97: training on 182922 raw words (78560 effective words) took 0.0s, 4009220 effective words/s
2025-12-14 19:01:57,796 INFO EPOCH 98: training on 182922 raw words (78635 effective words) took 0.0s, 3834840 effective words/s
2025-12-14 19:01:57,816 INFO EPOCH 99: training on 182922 raw words (78633 effective words) took 0.0s, 3981367 effective words/s
2025-12-14 19:01:57,836 INFO EPOCH 100: training on 182922 raw words (78528 effective words) took 0.0s, 3987374 effective words/s
2025-12-14 19:01:57,856 INFO EPOCH 101: training on 182922 raw words (78498 effective words) took 0.0s, 3966682 effective words/s
2025-12-14 19:01:57,876 INFO EPOCH 102: training on 182922 raw words (78556 effective words) took 0.0s, 4000857 effective words/s
2025-12-14 19:01:57,897 INFO EPOCH 103: training on 182922 raw words (78612 effective words) took 0.0s, 3926355 effective words/s
2025-12-14 19:01:57,917 INFO EPOCH 104: training on 182922 raw words (78578 effective words) took 0.0s, 3906689 effective words/s
2025-12-14 19:01:57,937 INFO EPOCH 105: training on 182922 raw words (78624 effective words) took 0.0s, 3988341 effective words/s
2025-12-14 19:01:57,957 INFO EPOCH 106: training on 182922 raw words (78553 effective words) took 0.0s, 4044494 effective words/s
2025-12-14 19:01:57,977 INFO EPOCH 107: training on 182922 raw words (78483 effective words) took 0.0s, 3994681 effective words/s
2025-12-14 19:01:57,996 INFO EPOCH 108: training on 182922 raw words (78597 effective words) took 0.0s, 4026185 effective words/s
2025-12-14 19:01:58,016 INFO EPOCH 109: training on 182922 raw words (78563 effective words) took 0.0s, 3981334 effective words/s
2025-12-14 19:01:58,036 INFO EPOCH 110: training on 182922 raw words (78615 effective words) took 0.0s, 4044016 effective words/s
2025-12-14 19:01:58,056 INFO EPOCH 111: training on 182922 raw words (78531 effective words) took 0.0s, 4001996 effective words/s
2025-12-14 19:01:58,075 INFO EPOCH 112: training on 182922 raw words (78605 effective words) took 0.0s, 4035958 effective words/s
2025-12-14 19:01:58,095 INFO EPOCH 113: training on 182922 raw words (78709 effective words) took 0.0s, 4036247 effective words/s
2025-12-14 19:01:58,115 INFO EPOCH 114: training on 182922 raw words (78686 effective words) took 0.0s, 3967386 effective words/s
2025-12-14 19:01:58,135 INFO EPOCH 115: training on 182922 raw words (78572 effective words) took 0.0s, 3997287 effective words/s
2025-12-14 19:01:58,155 INFO EPOCH 116: training on 182922 raw words (78630 effective words) took 0.0s, 3944096 effective words/s
2025-12-14 19:01:58,175 INFO EPOCH 117: training on 182922 raw words (78585 effective words) took 0.0s, 4002496 effective words/s
2025-12-14 19:01:58,195 INFO EPOCH 118: training on 182922 raw words (78672 effective words) took 0.0s, 3996097 effective words/s
2025-12-14 19:01:58,215 INFO EPOCH 119: training on 182922 raw words (78513 effective words) took 0.0s, 3986502 effective words/s
2025-12-14 19:01:58,235 INFO EPOCH 120: training on 182922 raw words (78633 effective words) took 0.0s, 3997924 effective words/s
2025-12-14 19:01:58,255 INFO EPOCH 121: training on 182922 raw words (78525 effective words) took 0.0s, 3937817 effective words/s
2025-12-14 19:01:58,275 INFO EPOCH 122: training on 182922 raw words (78635 effective words) took 0.0s, 3943952 effective words/s
2025-12-14 19:01:58,295 INFO EPOCH 123: training on 182922 raw words (78651 effective words) took 0.0s, 3994752 effective words/s
2025-12-14 19:01:58,315 INFO EPOCH 124: training on 182922 raw words (78535 effective words) took 0.0s, 3980058 effective words/s
2025-12-14 19:01:58,335 INFO EPOCH 125: training on 182922 raw words (78568 effective words) took 0.0s, 3992648 effective words/s
2025-12-14 19:01:58,355 INFO EPOCH 126: training on 182922 raw words (78606 effective words) took 0.0s, 4002486 effective words/s
2025-12-14 19:01:58,375 INFO EPOCH 127: training on 182922 raw words (78560 effective words) took 0.0s, 3940091 effective words/s
2025-12-14 19:01:58,395 INFO EPOCH 128: training on 182922 raw words (78588 effective words) took 0.0s, 3979567 effective words/s
2025-12-14 19:01:58,415 INFO EPOCH 129: training on 182922 raw words (78522 effective words) took 0.0s, 4021047 effective words/s
2025-12-14 19:01:58,435 INFO EPOCH 130: training on 182922 raw words (78607 effective words) took 0.0s, 4020056 effective words/s
2025-12-14 19:01:58,455 INFO EPOCH 131: training on 182922 raw words (78572 effective words) took 0.0s, 4039752 effective words/s
2025-12-14 19:01:58,474 INFO EPOCH 132: training on 182922 raw words (78568 effective words) took 0.0s, 4024527 effective words/s
2025-12-14 19:01:58,494 INFO EPOCH 133: training on 182922 raw words (78643 effective words) took 0.0s, 4024658 effective words/s
2025-12-14 19:01:58,514 INFO EPOCH 134: training on 182922 raw words (78605 effective words) took 0.0s, 4036235 effective words/s
2025-12-14 19:01:58,534 INFO EPOCH 135: training on 182922 raw words (78582 effective words) took 0.0s, 4030268 effective words/s
2025-12-14 19:01:58,553 INFO EPOCH 136: training on 182922 raw words (78722 effective words) took 0.0s, 3995407 effective words/s
2025-12-14 19:01:58,573 INFO EPOCH 137: training on 182922 raw words (78641 effective words) took 0.0s, 4026565 effective words/s
2025-12-14 19:01:58,593 INFO EPOCH 138: training on 182922 raw words (78622 effective words) took 0.0s, 4000908 effective words/s
2025-12-14 19:01:58,613 INFO EPOCH 139: training on 182922 raw words (78620 effective words) took 0.0s, 4023044 effective words/s
2025-12-14 19:01:58,633 INFO EPOCH 140: training on 182922 raw words (78562 effective words) took 0.0s, 3984186 effective words/s
2025-12-14 19:01:58,653 INFO EPOCH 141: training on 182922 raw words (78672 effective words) took 0.0s, 4009505 effective words/s
2025-12-14 19:01:58,673 INFO EPOCH 142: training on 182922 raw words (78608 effective words) took 0.0s, 3950862 effective words/s
2025-12-14 19:01:58,693 INFO EPOCH 143: training on 182922 raw words (78528 effective words) took 0.0s, 4004258 effective words/s
2025-12-14 19:01:58,713 INFO EPOCH 144: training on 182922 raw words (78523 effective words) took 0.0s, 3985391 effective words/s
2025-12-14 19:01:58,733 INFO EPOCH 145: training on 182922 raw words (78626 effective words) took 0.0s, 3967720 effective words/s
2025-12-14 19:01:58,753 INFO EPOCH 146: training on 182922 raw words (78568 effective words) took 0.0s, 3975694 effective words/s
2025-12-14 19:01:58,773 INFO EPOCH 147: training on 182922 raw words (78494 effective words) took 0.0s, 4003417 effective words/s
2025-12-14 19:01:58,792 INFO EPOCH 148: training on 182922 raw words (78528 effective words) took 0.0s, 4006982 effective words/s
2025-12-14 19:01:58,812 INFO EPOCH 149: training on 182922 raw words (78573 effective words) took 0.0s, 4065260 effective words/s
2025-12-14 19:01:58,832 INFO EPOCH 150: training on 182922 raw words (78545 effective words) took 0.0s, 4009222 effective words/s
2025-12-14 19:01:58,852 INFO EPOCH 151: training on 182922 raw words (78583 effective words) took 0.0s, 4016389 effective words/s
2025-12-14 19:01:58,871 INFO EPOCH 152: training on 182922 raw words (78618 effective words) took 0.0s, 4020987 effective words/s
2025-12-14 19:01:58,891 INFO EPOCH 153: training on 182922 raw words (78549 effective words) took 0.0s, 4052399 effective words/s
2025-12-14 19:01:58,911 INFO EPOCH 154: training on 182922 raw words (78563 effective words) took 0.0s, 3921320 effective words/s
2025-12-14 19:01:58,932 INFO EPOCH 155: training on 182922 raw words (78495 effective words) took 0.0s, 3770610 effective words/s
2025-12-14 19:01:58,952 INFO EPOCH 156: training on 182922 raw words (78546 effective words) took 0.0s, 3964684 effective words/s
2025-12-14 19:01:58,972 INFO EPOCH 157: training on 182922 raw words (78581 effective words) took 0.0s, 3980893 effective words/s
2025-12-14 19:01:58,993 INFO EPOCH 158: training on 182922 raw words (78604 effective words) took 0.0s, 3909350 effective words/s
2025-12-14 19:01:59,013 INFO EPOCH 159: training on 182922 raw words (78673 effective words) took 0.0s, 3994195 effective words/s
2025-12-14 19:01:59,033 INFO EPOCH 160: training on 182922 raw words (78580 effective words) took 0.0s, 3908456 effective words/s
2025-12-14 19:01:59,053 INFO EPOCH 161: training on 182922 raw words (78625 effective words) took 0.0s, 3980870 effective words/s
2025-12-14 19:01:59,073 INFO EPOCH 162: training on 182922 raw words (78584 effective words) took 0.0s, 3988943 effective words/s
2025-12-14 19:01:59,093 INFO EPOCH 163: training on 182922 raw words (78509 effective words) took 0.0s, 3987379 effective words/s
2025-12-14 19:01:59,113 INFO EPOCH 164: training on 182922 raw words (78660 effective words) took 0.0s, 3973940 effective words/s
2025-12-14 19:01:59,133 INFO EPOCH 165: training on 182922 raw words (78650 effective words) took 0.0s, 4017812 effective words/s
2025-12-14 19:01:59,153 INFO EPOCH 166: training on 182922 raw words (78595 effective words) took 0.0s, 4025619 effective words/s
2025-12-14 19:01:59,173 INFO EPOCH 167: training on 182922 raw words (78576 effective words) took 0.0s, 3931954 effective words/s
2025-12-14 19:01:59,193 INFO EPOCH 168: training on 182922 raw words (78615 effective words) took 0.0s, 3981573 effective words/s
2025-12-14 19:01:59,213 INFO EPOCH 169: training on 182922 raw words (78518 effective words) took 0.0s, 3986537 effective words/s
2025-12-14 19:01:59,233 INFO EPOCH 170: training on 182922 raw words (78559 effective words) took 0.0s, 3977234 effective words/s
2025-12-14 19:01:59,252 INFO EPOCH 171: training on 182922 raw words (78615 effective words) took 0.0s, 4009605 effective words/s
2025-12-14 19:01:59,272 INFO EPOCH 172: training on 182922 raw words (78465 effective words) took 0.0s, 3983458 effective words/s
2025-12-14 19:01:59,292 INFO EPOCH 173: training on 182922 raw words (78549 effective words) took 0.0s, 4019368 effective words/s
2025-12-14 19:01:59,342 INFO EPOCH 174: training on 182922 raw words (78542 effective words) took 0.0s, 1577397 effective words/s
2025-12-14 19:01:59,362 INFO EPOCH 175: training on 182922 raw words (78628 effective words) took 0.0s, 3996417 effective words/s
2025-12-14 19:01:59,382 INFO EPOCH 176: training on 182922 raw words (78636 effective words) took 0.0s, 4005000 effective words/s
2025-12-14 19:01:59,402 INFO EPOCH 177: training on 182922 raw words (78626 effective words) took 0.0s, 3983517 effective words/s
2025-12-14 19:01:59,422 INFO EPOCH 178: training on 182922 raw words (78643 effective words) took 0.0s, 3977552 effective words/s
2025-12-14 19:01:59,442 INFO EPOCH 179: training on 182922 raw words (78567 effective words) took 0.0s, 3967212 effective words/s
2025-12-14 19:01:59,462 INFO EPOCH 180: training on 182922 raw words (78547 effective words) took 0.0s, 3988001 effective words/s
2025-12-14 19:01:59,482 INFO EPOCH 181: training on 182922 raw words (78675 effective words) took 0.0s, 4004929 effective words/s
2025-12-14 19:01:59,502 INFO EPOCH 182: training on 182922 raw words (78572 effective words) took 0.0s, 4030324 effective words/s
2025-12-14 19:01:59,522 INFO EPOCH 183: training on 182922 raw words (78614 effective words) took 0.0s, 3994690 effective words/s
2025-12-14 19:01:59,545 INFO EPOCH 184: training on 182922 raw words (78534 effective words) took 0.0s, 3354613 effective words/s
2025-12-14 19:01:59,566 INFO EPOCH 185: training on 182922 raw words (78623 effective words) took 0.0s, 3860187 effective words/s
2025-12-14 19:01:59,586 INFO EPOCH 186: training on 182922 raw words (78557 effective words) took 0.0s, 3919228 effective words/s
2025-12-14 19:01:59,606 INFO EPOCH 187: training on 182922 raw words (78533 effective words) took 0.0s, 3980680 effective words/s
2025-12-14 19:01:59,626 INFO EPOCH 188: training on 182922 raw words (78670 effective words) took 0.0s, 4003044 effective words/s
2025-12-14 19:01:59,646 INFO EPOCH 189: training on 182922 raw words (78609 effective words) took 0.0s, 4013052 effective words/s
2025-12-14 19:01:59,666 INFO EPOCH 190: training on 182922 raw words (78613 effective words) took 0.0s, 4013470 effective words/s
2025-12-14 19:01:59,686 INFO EPOCH 191: training on 182922 raw words (78589 effective words) took 0.0s, 4012850 effective words/s
2025-12-14 19:01:59,705 INFO EPOCH 192: training on 182922 raw words (78593 effective words) took 0.0s, 4056648 effective words/s
2025-12-14 19:01:59,725 INFO EPOCH 193: training on 182922 raw words (78644 effective words) took 0.0s, 4009100 effective words/s
2025-12-14 19:01:59,745 INFO EPOCH 194: training on 182922 raw words (78587 effective words) took 0.0s, 4003711 effective words/s
2025-12-14 19:01:59,765 INFO EPOCH 195: training on 182922 raw words (78505 effective words) took 0.0s, 4028221 effective words/s
2025-12-14 19:01:59,784 INFO EPOCH 196: training on 182922 raw words (78441 effective words) took 0.0s, 4004024 effective words/s
2025-12-14 19:01:59,804 INFO EPOCH 197: training on 182922 raw words (78543 effective words) took 0.0s, 4021676 effective words/s
2025-12-14 19:01:59,824 INFO EPOCH 198: training on 182922 raw words (78531 effective words) took 0.0s, 4045713 effective words/s
2025-12-14 19:01:59,844 INFO EPOCH 199: training on 182922 raw words (78596 effective words) took 0.0s, 3997415 effective words/s
2025-12-14 19:01:59,863 INFO EPOCH 200: training on 182922 raw words (78562 effective words) took 0.0s, 4003686 effective words/s
2025-12-14 19:01:59,883 INFO EPOCH 201: training on 182922 raw words (78541 effective words) took 0.0s, 4019173 effective words/s
2025-12-14 19:01:59,903 INFO EPOCH 202: training on 182922 raw words (78612 effective words) took 0.0s, 4019635 effective words/s
2025-12-14 19:01:59,923 INFO EPOCH 203: training on 182922 raw words (78600 effective words) took 0.0s, 4005223 effective words/s
2025-12-14 19:01:59,943 INFO EPOCH 204: training on 182922 raw words (78578 effective words) took 0.0s, 4001901 effective words/s
2025-12-14 19:01:59,962 INFO EPOCH 205: training on 182922 raw words (78534 effective words) took 0.0s, 4041331 effective words/s
2025-12-14 19:01:59,982 INFO EPOCH 206: training on 182922 raw words (78653 effective words) took 0.0s, 4029225 effective words/s
2025-12-14 19:02:00,002 INFO EPOCH 207: training on 182922 raw words (78592 effective words) took 0.0s, 4028560 effective words/s
2025-12-14 19:02:00,026 INFO EPOCH 208: training on 182922 raw words (78475 effective words) took 0.0s, 3319205 effective words/s
2025-12-14 19:02:00,063 INFO EPOCH 209: training on 182922 raw words (78678 effective words) took 0.0s, 2178805 effective words/s
2025-12-14 19:02:00,083 INFO EPOCH 210: training on 182922 raw words (78541 effective words) took 0.0s, 3922645 effective words/s
2025-12-14 19:02:00,103 INFO EPOCH 211: training on 182922 raw words (78575 effective words) took 0.0s, 4002734 effective words/s
2025-12-14 19:02:00,123 INFO EPOCH 212: training on 182922 raw words (78475 effective words) took 0.0s, 4008496 effective words/s
2025-12-14 19:02:00,143 INFO EPOCH 213: training on 182922 raw words (78595 effective words) took 0.0s, 3978856 effective words/s
2025-12-14 19:02:00,163 INFO EPOCH 214: training on 182922 raw words (78644 effective words) took 0.0s, 3951844 effective words/s
2025-12-14 19:02:00,184 INFO EPOCH 215: training on 182922 raw words (78651 effective words) took 0.0s, 3860614 effective words/s
2025-12-14 19:02:00,207 INFO EPOCH 216: training on 182922 raw words (78536 effective words) took 0.0s, 3376223 effective words/s
2025-12-14 19:02:00,228 INFO EPOCH 217: training on 182922 raw words (78516 effective words) took 0.0s, 3870810 effective words/s
2025-12-14 19:02:00,279 INFO EPOCH 218: training on 182922 raw words (78582 effective words) took 0.1s, 1559127 effective words/s
2025-12-14 19:02:00,299 INFO EPOCH 219: training on 182922 raw words (78577 effective words) took 0.0s, 3924901 effective words/s
2025-12-14 19:02:00,319 INFO EPOCH 220: training on 182922 raw words (78509 effective words) took 0.0s, 3931002 effective words/s
2025-12-14 19:02:00,339 INFO EPOCH 221: training on 182922 raw words (78618 effective words) took 0.0s, 4003675 effective words/s
2025-12-14 19:02:00,359 INFO EPOCH 222: training on 182922 raw words (78714 effective words) took 0.0s, 4014186 effective words/s
2025-12-14 19:02:00,379 INFO EPOCH 223: training on 182922 raw words (78631 effective words) took 0.0s, 4003913 effective words/s
2025-12-14 19:02:00,399 INFO EPOCH 224: training on 182922 raw words (78518 effective words) took 0.0s, 4003714 effective words/s
2025-12-14 19:02:00,419 INFO EPOCH 225: training on 182922 raw words (78594 effective words) took 0.0s, 3999084 effective words/s
2025-12-14 19:02:00,438 INFO EPOCH 226: training on 182922 raw words (78616 effective words) took 0.0s, 4013213 effective words/s
2025-12-14 19:02:00,458 INFO EPOCH 227: training on 182922 raw words (78606 effective words) took 0.0s, 3993472 effective words/s
2025-12-14 19:02:00,478 INFO EPOCH 228: training on 182922 raw words (78574 effective words) took 0.0s, 3987760 effective words/s
2025-12-14 19:02:00,498 INFO EPOCH 229: training on 182922 raw words (78557 effective words) took 0.0s, 3986426 effective words/s
2025-12-14 19:02:00,518 INFO EPOCH 230: training on 182922 raw words (78600 effective words) took 0.0s, 4018833 effective words/s
2025-12-14 19:02:00,538 INFO EPOCH 231: training on 182922 raw words (78554 effective words) took 0.0s, 4009426 effective words/s
2025-12-14 19:02:00,558 INFO EPOCH 232: training on 182922 raw words (78656 effective words) took 0.0s, 4021636 effective words/s
2025-12-14 19:02:00,577 INFO EPOCH 233: training on 182922 raw words (78609 effective words) took 0.0s, 4009922 effective words/s
2025-12-14 19:02:00,597 INFO EPOCH 234: training on 182922 raw words (78605 effective words) took 0.0s, 4010169 effective words/s
2025-12-14 19:02:00,617 INFO EPOCH 235: training on 182922 raw words (78630 effective words) took 0.0s, 3999771 effective words/s
2025-12-14 19:02:00,637 INFO EPOCH 236: training on 182922 raw words (78584 effective words) took 0.0s, 3999678 effective words/s
2025-12-14 19:02:00,657 INFO EPOCH 237: training on 182922 raw words (78616 effective words) took 0.0s, 3972846 effective words/s
2025-12-14 19:02:00,677 INFO EPOCH 238: training on 182922 raw words (78565 effective words) took 0.0s, 3996456 effective words/s
2025-12-14 19:02:00,699 INFO EPOCH 239: training on 182922 raw words (78574 effective words) took 0.0s, 3521037 effective words/s
2025-12-14 19:02:00,723 INFO EPOCH 240: training on 182922 raw words (78618 effective words) took 0.0s, 3391606 effective words/s
2025-12-14 19:02:00,744 INFO EPOCH 241: training on 182922 raw words (78568 effective words) took 0.0s, 3727356 effective words/s
2025-12-14 19:02:00,769 INFO EPOCH 242: training on 182922 raw words (78512 effective words) took 0.0s, 3229529 effective words/s
2025-12-14 19:02:00,789 INFO EPOCH 243: training on 182922 raw words (78566 effective words) took 0.0s, 3915046 effective words/s
2025-12-14 19:02:00,810 INFO EPOCH 244: training on 182922 raw words (78583 effective words) took 0.0s, 3933797 effective words/s
2025-12-14 19:02:00,830 INFO EPOCH 245: training on 182922 raw words (78612 effective words) took 0.0s, 3929470 effective words/s
2025-12-14 19:02:00,850 INFO EPOCH 246: training on 182922 raw words (78581 effective words) took 0.0s, 3959031 effective words/s
2025-12-14 19:02:00,870 INFO EPOCH 247: training on 182922 raw words (78589 effective words) took 0.0s, 3979156 effective words/s
2025-12-14 19:02:00,890 INFO EPOCH 248: training on 182922 raw words (78560 effective words) took 0.0s, 3960052 effective words/s
2025-12-14 19:02:00,910 INFO EPOCH 249: training on 182922 raw words (78470 effective words) took 0.0s, 3994985 effective words/s
2025-12-14 19:02:00,930 INFO EPOCH 250: training on 182922 raw words (78628 effective words) took 0.0s, 3962814 effective words/s
2025-12-14 19:02:00,950 INFO EPOCH 251: training on 182922 raw words (78577 effective words) took 0.0s, 3996135 effective words/s
2025-12-14 19:02:00,970 INFO EPOCH 252: training on 182922 raw words (78634 effective words) took 0.0s, 3945988 effective words/s
2025-12-14 19:02:00,990 INFO EPOCH 253: training on 182922 raw words (78586 effective words) took 0.0s, 3998906 effective words/s
2025-12-14 19:02:01,010 INFO EPOCH 254: training on 182922 raw words (78542 effective words) took 0.0s, 3991589 effective words/s
2025-12-14 19:02:01,030 INFO EPOCH 255: training on 182922 raw words (78580 effective words) took 0.0s, 3903287 effective words/s
2025-12-14 19:02:01,051 INFO EPOCH 256: training on 182922 raw words (78545 effective words) took 0.0s, 3922567 effective words/s
2025-12-14 19:02:01,071 INFO EPOCH 257: training on 182922 raw words (78604 effective words) took 0.0s, 3936014 effective words/s
2025-12-14 19:02:01,095 INFO EPOCH 258: training on 182922 raw words (78593 effective words) took 0.0s, 3999364 effective words/s
2025-12-14 19:02:01,115 INFO EPOCH 259: training on 182922 raw words (78654 effective words) took 0.0s, 3972851 effective words/s
2025-12-14 19:02:01,135 INFO EPOCH 260: training on 182922 raw words (78631 effective words) took 0.0s, 3987542 effective words/s
2025-12-14 19:02:01,155 INFO EPOCH 261: training on 182922 raw words (78532 effective words) took 0.0s, 4007382 effective words/s
2025-12-14 19:02:01,175 INFO EPOCH 262: training on 182922 raw words (78648 effective words) took 0.0s, 4002612 effective words/s
2025-12-14 19:02:01,195 INFO EPOCH 263: training on 182922 raw words (78618 effective words) took 0.0s, 3971576 effective words/s
2025-12-14 19:02:01,215 INFO EPOCH 264: training on 182922 raw words (78545 effective words) took 0.0s, 3952629 effective words/s
2025-12-14 19:02:01,235 INFO EPOCH 265: training on 182922 raw words (78585 effective words) took 0.0s, 3955571 effective words/s
2025-12-14 19:02:01,256 INFO EPOCH 266: training on 182922 raw words (78614 effective words) took 0.0s, 3940938 effective words/s
2025-12-14 19:02:01,276 INFO EPOCH 267: training on 182922 raw words (78609 effective words) took 0.0s, 3886572 effective words/s
2025-12-14 19:02:01,297 INFO EPOCH 268: training on 182922 raw words (78671 effective words) took 0.0s, 3848851 effective words/s
2025-12-14 19:02:01,367 INFO EPOCH 269: training on 182922 raw words (78481 effective words) took 0.1s, 1120614 effective words/s
2025-12-14 19:02:01,397 INFO EPOCH 270: training on 182922 raw words (78676 effective words) took 0.0s, 2691515 effective words/s
2025-12-14 19:02:01,417 INFO EPOCH 271: training on 182922 raw words (78632 effective words) took 0.0s, 3952606 effective words/s
2025-12-14 19:02:01,437 INFO EPOCH 272: training on 182922 raw words (78572 effective words) took 0.0s, 3947738 effective words/s
2025-12-14 19:02:01,457 INFO EPOCH 273: training on 182922 raw words (78580 effective words) took 0.0s, 3967935 effective words/s
2025-12-14 19:02:01,477 INFO EPOCH 274: training on 182922 raw words (78643 effective words) took 0.0s, 4000687 effective words/s
2025-12-14 19:02:01,497 INFO EPOCH 275: training on 182922 raw words (78525 effective words) took 0.0s, 4013673 effective words/s
2025-12-14 19:02:01,517 INFO EPOCH 276: training on 182922 raw words (78605 effective words) took 0.0s, 3998008 effective words/s
2025-12-14 19:02:01,537 INFO EPOCH 277: training on 182922 raw words (78605 effective words) took 0.0s, 3972148 effective words/s
2025-12-14 19:02:01,557 INFO EPOCH 278: training on 182922 raw words (78524 effective words) took 0.0s, 3972856 effective words/s
2025-12-14 19:02:01,577 INFO EPOCH 279: training on 182922 raw words (78539 effective words) took 0.0s, 3981084 effective words/s
2025-12-14 19:02:01,597 INFO EPOCH 280: training on 182922 raw words (78625 effective words) took 0.0s, 3968195 effective words/s
2025-12-14 19:02:01,617 INFO EPOCH 281: training on 182922 raw words (78621 effective words) took 0.0s, 3994023 effective words/s
2025-12-14 19:02:01,637 INFO EPOCH 282: training on 182922 raw words (78562 effective words) took 0.0s, 3967410 effective words/s
2025-12-14 19:02:01,657 INFO EPOCH 283: training on 182922 raw words (78661 effective words) took 0.0s, 3952913 effective words/s
2025-12-14 19:02:01,677 INFO EPOCH 284: training on 182922 raw words (78521 effective words) took 0.0s, 3959591 effective words/s
2025-12-14 19:02:01,698 INFO EPOCH 285: training on 182922 raw words (78665 effective words) took 0.0s, 3921640 effective words/s
2025-12-14 19:02:01,718 INFO EPOCH 286: training on 182922 raw words (78520 effective words) took 0.0s, 3945646 effective words/s
2025-12-14 19:02:01,738 INFO EPOCH 287: training on 182922 raw words (78586 effective words) took 0.0s, 3900542 effective words/s
2025-12-14 19:02:01,759 INFO EPOCH 288: training on 182922 raw words (78593 effective words) took 0.0s, 3917286 effective words/s
2025-12-14 19:02:01,779 INFO EPOCH 289: training on 182922 raw words (78589 effective words) took 0.0s, 3846384 effective words/s
2025-12-14 19:02:01,803 INFO EPOCH 290: training on 182922 raw words (78629 effective words) took 0.0s, 3405708 effective words/s
2025-12-14 19:02:01,824 INFO EPOCH 291: training on 182922 raw words (78666 effective words) took 0.0s, 3687728 effective words/s
2025-12-14 19:02:01,845 INFO EPOCH 292: training on 182922 raw words (78683 effective words) took 0.0s, 3942948 effective words/s
2025-12-14 19:02:01,865 INFO EPOCH 293: training on 182922 raw words (78573 effective words) took 0.0s, 3814794 effective words/s
2025-12-14 19:02:01,886 INFO EPOCH 294: training on 182922 raw words (78540 effective words) took 0.0s, 3824084 effective words/s
2025-12-14 19:02:01,907 INFO EPOCH 295: training on 182922 raw words (78550 effective words) took 0.0s, 3900610 effective words/s
2025-12-14 19:02:01,927 INFO EPOCH 296: training on 182922 raw words (78539 effective words) took 0.0s, 3968562 effective words/s
2025-12-14 19:02:01,947 INFO EPOCH 297: training on 182922 raw words (78563 effective words) took 0.0s, 3950478 effective words/s
2025-12-14 19:02:01,967 INFO EPOCH 298: training on 182922 raw words (78609 effective words) took 0.0s, 3946111 effective words/s
2025-12-14 19:02:01,987 INFO EPOCH 299: training on 182922 raw words (78528 effective words) took 0.0s, 3980325 effective words/s
2025-12-14 19:02:01,987 INFO Doc2Vec lifecycle event {'msg': 'training on 54876600 raw words (23575537 effective words) took 6.2s, 3814483 effective words/s', 'datetime': '2025-12-14T19:02:01.987857', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}
2025-12-14 19:02:01,988 INFO Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_model.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-12-14T19:02:01.988068', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'saving'}
2025-12-14 19:02:01,988 INFO not storing attribute cum_table
2025-12-14 19:02:01,990 INFO saved doc2vec_model.model
2025-12-14 19:02:01,992 INFO loading Doc2Vec object from doc2vec_model.model
2025-12-14 19:02:01,993 INFO loading dv recursively from doc2vec_model.model.dv.* with mmap=None
2025-12-14 19:02:01,993 INFO loading wv recursively from doc2vec_model.model.wv.* with mmap=None
2025-12-14 19:02:01,993 INFO setting ignored attribute cum_table to None
2025-12-14 19:02:02,000 INFO Doc2Vec lifecycle event {'fname': 'doc2vec_model.model', 'datetime': '2025-12-14T19:02:02.000226', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}
2025-12-14 19:02:02,000 INFO Loaded Doc2Vec model
2025-12-14 19:02:02,000 INFO Loaded Doc2Vec model
2025-12-14 19:02:02,000 INFO Loaded FAISS index
2025-12-14 19:02:02,000 INFO Loaded FAISS index
2025-12-14 19:02:03,465 INFO Initializing pipeline (device cuda? False)
2025-12-14 19:02:03,465 INFO Initializing pipeline (device cuda? False)
2025-12-14 19:02:04,945 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f6c1c-7fd789550831ca8872777148;70265990-3eca-4eb9-9ad6-f4be4aaa226a)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 243, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f6c1c-7fd789550831ca8872777148;70265990-3eca-4eb9-9ad6-f4be4aaa226a)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 19:02:04,945 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 286, in hf_raise_for_status
    response.raise_for_status()
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 118, in _inner_fn
    return fn(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1457, in hf_hub_download
    http_get(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 451, in http_get
    r = _request_wrapper(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 409, in _request_wrapper
    hf_raise_for_status(response)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py", line 302, in hf_raise_for_status
    raise GatedRepoError(message, response) from e
huggingface_hub.utils._errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-693f6c1c-7fd789550831ca8872777148;70265990-3eca-4eb9-9ad6-f4be4aaa226a)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 243, in generate_report
    pipe = pipeline('text-generation', model=model_id, device=device)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/pipelines/__init__.py", line 815, in pipeline
    config = AutoConfig.from_pretrained(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py", line 1138, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 631, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/configuration_utils.py", line 686, in _get_config_dict
    resolved_config_file = cached_file(
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv310/lib/python3.10/site-packages/transformers/utils/hub.py", line 416, in cached_file
    raise EnvironmentError(
OSError: You are trying to access a gated repo.
Make sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct.
401 Client Error. (Request ID: Root=1-693f6c1c-7fd789550831ca8872777148;70265990-3eca-4eb9-9ad6-f4be4aaa226a)

Cannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct/resolve/main/config.json.
Access to model meta-llama/Llama-3.1-8B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-12-14 19:02:04,963 INFO Processing question 1
2025-12-14 19:02:04,963 INFO Processing question 1
2025-12-14 19:02:04,999 INFO Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-12-14 19:06:16,121 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 19:06:16,123 INFO [33mPress CTRL+C to quit[0m
2025-12-14 19:06:26,600 INFO Received form responses; launching background generation
2025-12-14 19:06:26,600 INFO Background report generation started
2025-12-14 19:06:26,604 INFO 127.0.0.1 - - [14/Dec/2025 19:06:26] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:06:26,608 INFO Starting report generation
2025-12-14 19:06:26,608 INFO Starting report generation
2025-12-14 19:06:28,068 INFO Loading faiss.
2025-12-14 19:06:28,092 INFO Successfully loaded faiss.
2025-12-14 19:06:41,139 INFO Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d20,n5,w5,mc5,s0.001,t3>', 'datetime': '2025-12-14T19:06:41.126425', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'created'}
2025-12-14 19:06:41,140 INFO collecting all words and their counts
2025-12-14 19:06:41,140 INFO PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags
2025-12-14 19:06:41,153 INFO collected 8045 word types and 22 unique tags from a corpus of 22 examples and 182922 words
2025-12-14 19:06:41,153 INFO Creating a fresh vocabulary
2025-12-14 19:06:41,158 INFO Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 2492 unique words (30.98% of original 8045, drops 5553)', 'datetime': '2025-12-14T19:06:41.158457', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 19:06:41,158 INFO Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 174109 word corpus (95.18% of original 182922, drops 8813)', 'datetime': '2025-12-14T19:06:41.158554', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 19:06:41,163 INFO deleting the raw counts dictionary of 8045 items
2025-12-14 19:06:41,164 INFO sample=0.001 downsamples 48 most-common words
2025-12-14 19:06:41,164 INFO Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 117305.50818736776 word corpus (67.4%% of prior 174109)', 'datetime': '2025-12-14T19:06:41.164111', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'prepare_vocab'}
2025-12-14 19:06:41,173 INFO estimated required memory for 2492 words and 20 dimensions: 1650880 bytes
2025-12-14 19:06:41,173 INFO resetting layer weights
2025-12-14 19:06:41,175 INFO Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 2492 vocabulary and 20 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-12-14T19:06:41.175418', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}
2025-12-14 19:06:41,200 INFO EPOCH 0: training on 182922 raw words (78637 effective words) took 0.0s, 3245590 effective words/s
2025-12-14 19:06:41,219 INFO EPOCH 1: training on 182922 raw words (78594 effective words) took 0.0s, 4195195 effective words/s
2025-12-14 19:06:41,239 INFO EPOCH 2: training on 182922 raw words (78603 effective words) took 0.0s, 4196786 effective words/s
2025-12-14 19:06:41,258 INFO EPOCH 3: training on 182922 raw words (78605 effective words) took 0.0s, 4188069 effective words/s
2025-12-14 19:06:41,277 INFO EPOCH 4: training on 182922 raw words (78637 effective words) took 0.0s, 4173523 effective words/s
2025-12-14 19:06:41,297 INFO EPOCH 5: training on 182922 raw words (78628 effective words) took 0.0s, 4018433 effective words/s
2025-12-14 19:06:41,316 INFO EPOCH 6: training on 182922 raw words (78644 effective words) took 0.0s, 4154958 effective words/s
2025-12-14 19:06:41,335 INFO EPOCH 7: training on 182922 raw words (78604 effective words) took 0.0s, 4108536 effective words/s
2025-12-14 19:06:41,354 INFO EPOCH 8: training on 182922 raw words (78609 effective words) took 0.0s, 4174954 effective words/s
2025-12-14 19:06:41,374 INFO EPOCH 9: training on 182922 raw words (78624 effective words) took 0.0s, 4130343 effective words/s
2025-12-14 19:06:41,393 INFO EPOCH 10: training on 182922 raw words (78626 effective words) took 0.0s, 4129526 effective words/s
2025-12-14 19:06:41,413 INFO EPOCH 11: training on 182922 raw words (78618 effective words) took 0.0s, 4088335 effective words/s
2025-12-14 19:06:41,432 INFO EPOCH 12: training on 182922 raw words (78602 effective words) took 0.0s, 4071992 effective words/s
2025-12-14 19:06:41,452 INFO EPOCH 13: training on 182922 raw words (78626 effective words) took 0.0s, 4076121 effective words/s
2025-12-14 19:06:41,471 INFO EPOCH 14: training on 182922 raw words (78577 effective words) took 0.0s, 4103336 effective words/s
2025-12-14 19:06:41,491 INFO EPOCH 15: training on 182922 raw words (78593 effective words) took 0.0s, 4036983 effective words/s
2025-12-14 19:06:41,510 INFO EPOCH 16: training on 182922 raw words (78581 effective words) took 0.0s, 4083482 effective words/s
2025-12-14 19:06:41,530 INFO EPOCH 17: training on 182922 raw words (78567 effective words) took 0.0s, 4015777 effective words/s
2025-12-14 19:06:41,550 INFO EPOCH 18: training on 182922 raw words (78611 effective words) took 0.0s, 4108821 effective words/s
2025-12-14 19:06:41,569 INFO EPOCH 19: training on 182922 raw words (78474 effective words) took 0.0s, 4058056 effective words/s
2025-12-14 19:06:41,589 INFO EPOCH 20: training on 182922 raw words (78563 effective words) took 0.0s, 4093271 effective words/s
2025-12-14 19:06:41,608 INFO EPOCH 21: training on 182922 raw words (78684 effective words) took 0.0s, 4071599 effective words/s
2025-12-14 19:06:41,628 INFO EPOCH 22: training on 182922 raw words (78611 effective words) took 0.0s, 4042329 effective words/s
2025-12-14 19:06:41,648 INFO EPOCH 23: training on 182922 raw words (78521 effective words) took 0.0s, 4052479 effective words/s
2025-12-14 19:06:41,668 INFO EPOCH 24: training on 182922 raw words (78632 effective words) took 0.0s, 4031980 effective words/s
2025-12-14 19:06:41,687 INFO EPOCH 25: training on 182922 raw words (78668 effective words) took 0.0s, 4043960 effective words/s
2025-12-14 19:06:41,707 INFO EPOCH 26: training on 182922 raw words (78614 effective words) took 0.0s, 4055404 effective words/s
2025-12-14 19:06:41,727 INFO EPOCH 27: training on 182922 raw words (78628 effective words) took 0.0s, 3985613 effective words/s
2025-12-14 19:06:41,747 INFO EPOCH 28: training on 182922 raw words (78530 effective words) took 0.0s, 4024943 effective words/s
2025-12-14 19:06:41,767 INFO EPOCH 29: training on 182922 raw words (78525 effective words) took 0.0s, 4028498 effective words/s
2025-12-14 19:06:41,786 INFO EPOCH 30: training on 182922 raw words (78606 effective words) took 0.0s, 4016325 effective words/s
2025-12-14 19:06:41,806 INFO EPOCH 31: training on 182922 raw words (78560 effective words) took 0.0s, 4045496 effective words/s
2025-12-14 19:06:41,826 INFO EPOCH 32: training on 182922 raw words (78640 effective words) took 0.0s, 4063260 effective words/s
2025-12-14 19:06:41,846 INFO EPOCH 33: training on 182922 raw words (78598 effective words) took 0.0s, 3976223 effective words/s
2025-12-14 19:06:41,866 INFO EPOCH 34: training on 182922 raw words (78637 effective words) took 0.0s, 4019192 effective words/s
2025-12-14 19:06:41,885 INFO EPOCH 35: training on 182922 raw words (78604 effective words) took 0.0s, 4026973 effective words/s
2025-12-14 19:06:41,905 INFO EPOCH 36: training on 182922 raw words (78511 effective words) took 0.0s, 4040008 effective words/s
2025-12-14 19:06:41,925 INFO EPOCH 37: training on 182922 raw words (78573 effective words) took 0.0s, 4025067 effective words/s
2025-12-14 19:06:41,945 INFO EPOCH 38: training on 182922 raw words (78542 effective words) took 0.0s, 3953058 effective words/s
2025-12-14 19:06:41,965 INFO EPOCH 39: training on 182922 raw words (78548 effective words) took 0.0s, 4023099 effective words/s
2025-12-14 19:06:41,985 INFO EPOCH 40: training on 182922 raw words (78563 effective words) took 0.0s, 4000085 effective words/s
2025-12-14 19:06:42,004 INFO EPOCH 41: training on 182922 raw words (78622 effective words) took 0.0s, 4019221 effective words/s
2025-12-14 19:06:42,024 INFO EPOCH 42: training on 182922 raw words (78660 effective words) took 0.0s, 4035450 effective words/s
2025-12-14 19:06:42,044 INFO EPOCH 43: training on 182922 raw words (78573 effective words) took 0.0s, 3978229 effective words/s
2025-12-14 19:06:42,064 INFO EPOCH 44: training on 182922 raw words (78568 effective words) took 0.0s, 4029171 effective words/s
2025-12-14 19:06:42,084 INFO EPOCH 45: training on 182922 raw words (78620 effective words) took 0.0s, 3980608 effective words/s
2025-12-14 19:06:42,104 INFO EPOCH 46: training on 182922 raw words (78579 effective words) took 0.0s, 4004493 effective words/s
2025-12-14 19:06:42,124 INFO EPOCH 47: training on 182922 raw words (78562 effective words) took 0.0s, 4033569 effective words/s
2025-12-14 19:06:42,144 INFO EPOCH 48: training on 182922 raw words (78552 effective words) took 0.0s, 3926921 effective words/s
2025-12-14 19:06:42,166 INFO EPOCH 49: training on 182922 raw words (78499 effective words) took 0.0s, 3612478 effective words/s
2025-12-14 19:06:42,187 INFO EPOCH 50: training on 182922 raw words (78593 effective words) took 0.0s, 3885981 effective words/s
2025-12-14 19:06:42,207 INFO EPOCH 51: training on 182922 raw words (78597 effective words) took 0.0s, 3989257 effective words/s
2025-12-14 19:06:42,226 INFO EPOCH 52: training on 182922 raw words (78492 effective words) took 0.0s, 4007974 effective words/s
2025-12-14 19:06:42,246 INFO EPOCH 53: training on 182922 raw words (78650 effective words) took 0.0s, 3995047 effective words/s
2025-12-14 19:06:42,266 INFO EPOCH 54: training on 182922 raw words (78627 effective words) took 0.0s, 3999796 effective words/s
2025-12-14 19:06:42,289 INFO EPOCH 55: training on 182922 raw words (78609 effective words) took 0.0s, 3578206 effective words/s
2025-12-14 19:06:42,308 INFO EPOCH 56: training on 182922 raw words (78603 effective words) took 0.0s, 3997864 effective words/s
2025-12-14 19:06:42,328 INFO EPOCH 57: training on 182922 raw words (78569 effective words) took 0.0s, 3978513 effective words/s
2025-12-14 19:06:42,348 INFO EPOCH 58: training on 182922 raw words (78624 effective words) took 0.0s, 4000636 effective words/s
2025-12-14 19:06:42,368 INFO EPOCH 59: training on 182922 raw words (78515 effective words) took 0.0s, 3967141 effective words/s
2025-12-14 19:06:42,389 INFO EPOCH 60: training on 182922 raw words (78633 effective words) took 0.0s, 3940845 effective words/s
2025-12-14 19:06:42,410 INFO EPOCH 61: training on 182922 raw words (78626 effective words) took 0.0s, 3697589 effective words/s
2025-12-14 19:06:42,430 INFO EPOCH 62: training on 182922 raw words (78606 effective words) took 0.0s, 3953104 effective words/s
2025-12-14 19:06:42,451 INFO EPOCH 63: training on 182922 raw words (78560 effective words) took 0.0s, 3822910 effective words/s
2025-12-14 19:06:42,472 INFO EPOCH 64: training on 182922 raw words (78646 effective words) took 0.0s, 3911034 effective words/s
2025-12-14 19:06:42,492 INFO EPOCH 65: training on 182922 raw words (78548 effective words) took 0.0s, 3933333 effective words/s
2025-12-14 19:06:42,512 INFO EPOCH 66: training on 182922 raw words (78654 effective words) took 0.0s, 3914359 effective words/s
2025-12-14 19:06:42,533 INFO EPOCH 67: training on 182922 raw words (78544 effective words) took 0.0s, 3863746 effective words/s
2025-12-14 19:06:42,553 INFO EPOCH 68: training on 182922 raw words (78595 effective words) took 0.0s, 3900230 effective words/s
2025-12-14 19:06:42,573 INFO EPOCH 69: training on 182922 raw words (78456 effective words) took 0.0s, 3974686 effective words/s
2025-12-14 19:06:42,596 INFO EPOCH 70: training on 182922 raw words (78609 effective words) took 0.0s, 3584515 effective words/s
2025-12-14 19:06:42,616 INFO EPOCH 71: training on 182922 raw words (78522 effective words) took 0.0s, 3952002 effective words/s
2025-12-14 19:06:42,637 INFO EPOCH 72: training on 182922 raw words (78613 effective words) took 0.0s, 3744754 effective words/s
2025-12-14 19:06:42,658 INFO EPOCH 73: training on 182922 raw words (78624 effective words) took 0.0s, 3836791 effective words/s
2025-12-14 19:06:42,679 INFO EPOCH 74: training on 182922 raw words (78695 effective words) took 0.0s, 3846959 effective words/s
2025-12-14 19:06:42,699 INFO EPOCH 75: training on 182922 raw words (78591 effective words) took 0.0s, 3906380 effective words/s
2025-12-14 19:06:42,720 INFO EPOCH 76: training on 182922 raw words (78606 effective words) took 0.0s, 3752860 effective words/s
2025-12-14 19:06:42,741 INFO EPOCH 77: training on 182922 raw words (78599 effective words) took 0.0s, 3886823 effective words/s
2025-12-14 19:06:42,763 INFO EPOCH 78: training on 182922 raw words (78558 effective words) took 0.0s, 3630634 effective words/s
2025-12-14 19:06:42,783 INFO EPOCH 79: training on 182922 raw words (78567 effective words) took 0.0s, 3929234 effective words/s
2025-12-14 19:06:42,803 INFO EPOCH 80: training on 182922 raw words (78619 effective words) took 0.0s, 3931540 effective words/s
2025-12-14 19:06:42,826 INFO EPOCH 81: training on 182922 raw words (78652 effective words) took 0.0s, 3545451 effective words/s
2025-12-14 19:06:42,847 INFO EPOCH 82: training on 182922 raw words (78595 effective words) took 0.0s, 3855988 effective words/s
2025-12-14 19:06:42,867 INFO EPOCH 83: training on 182922 raw words (78606 effective words) took 0.0s, 3884951 effective words/s
2025-12-14 19:06:42,888 INFO EPOCH 84: training on 182922 raw words (78640 effective words) took 0.0s, 3909447 effective words/s
2025-12-14 19:06:42,908 INFO EPOCH 85: training on 182922 raw words (78559 effective words) took 0.0s, 3928932 effective words/s
2025-12-14 19:06:42,928 INFO EPOCH 86: training on 182922 raw words (78668 effective words) took 0.0s, 3909325 effective words/s
2025-12-14 19:06:42,950 INFO EPOCH 87: training on 182922 raw words (78549 effective words) took 0.0s, 3628877 effective words/s
2025-12-14 19:06:42,971 INFO EPOCH 88: training on 182922 raw words (78593 effective words) took 0.0s, 3923781 effective words/s
2025-12-14 19:06:42,991 INFO EPOCH 89: training on 182922 raw words (78607 effective words) took 0.0s, 3952815 effective words/s
2025-12-14 19:06:43,011 INFO EPOCH 90: training on 182922 raw words (78590 effective words) took 0.0s, 3912822 effective words/s
2025-12-14 19:06:43,031 INFO EPOCH 91: training on 182922 raw words (78674 effective words) took 0.0s, 3954212 effective words/s
2025-12-14 19:06:43,052 INFO EPOCH 92: training on 182922 raw words (78499 effective words) took 0.0s, 3883342 effective words/s
2025-12-14 19:06:43,072 INFO EPOCH 93: training on 182922 raw words (78581 effective words) took 0.0s, 3928592 effective words/s
2025-12-14 19:06:43,093 INFO EPOCH 94: training on 182922 raw words (78679 effective words) took 0.0s, 3878273 effective words/s
2025-12-14 19:06:43,113 INFO EPOCH 95: training on 182922 raw words (78589 effective words) took 0.0s, 3908871 effective words/s
2025-12-14 19:06:43,133 INFO EPOCH 96: training on 182922 raw words (78559 effective words) took 0.0s, 3926486 effective words/s
2025-12-14 19:06:43,155 INFO EPOCH 97: training on 182922 raw words (78525 effective words) took 0.0s, 3742144 effective words/s
2025-12-14 19:06:43,175 INFO EPOCH 98: training on 182922 raw words (78605 effective words) took 0.0s, 3910283 effective words/s
2025-12-14 19:06:43,196 INFO EPOCH 99: training on 182922 raw words (78583 effective words) took 0.0s, 3783759 effective words/s
2025-12-14 19:06:43,220 INFO EPOCH 100: training on 182922 raw words (78478 effective words) took 0.0s, 3336035 effective words/s
2025-12-14 19:06:43,241 INFO EPOCH 101: training on 182922 raw words (78550 effective words) took 0.0s, 3951067 effective words/s
2025-12-14 19:06:43,262 INFO EPOCH 102: training on 182922 raw words (78654 effective words) took 0.0s, 3756923 effective words/s
2025-12-14 19:06:43,282 INFO EPOCH 103: training on 182922 raw words (78568 effective words) took 0.0s, 3864103 effective words/s
2025-12-14 19:06:43,303 INFO EPOCH 104: training on 182922 raw words (78585 effective words) took 0.0s, 3893640 effective words/s
2025-12-14 19:06:43,323 INFO EPOCH 105: training on 182922 raw words (78531 effective words) took 0.0s, 3945199 effective words/s
2025-12-14 19:06:43,343 INFO EPOCH 106: training on 182922 raw words (78570 effective words) took 0.0s, 3918060 effective words/s
2025-12-14 19:06:43,364 INFO EPOCH 107: training on 182922 raw words (78600 effective words) took 0.0s, 3890214 effective words/s
2025-12-14 19:06:43,384 INFO EPOCH 108: training on 182922 raw words (78622 effective words) took 0.0s, 3896832 effective words/s
2025-12-14 19:06:43,405 INFO EPOCH 109: training on 182922 raw words (78610 effective words) took 0.0s, 3903259 effective words/s
2025-12-14 19:06:43,425 INFO EPOCH 110: training on 182922 raw words (78722 effective words) took 0.0s, 3917549 effective words/s
2025-12-14 19:06:43,446 INFO EPOCH 111: training on 182922 raw words (78632 effective words) took 0.0s, 3894143 effective words/s
2025-12-14 19:06:43,466 INFO EPOCH 112: training on 182922 raw words (78577 effective words) took 0.0s, 3875043 effective words/s
2025-12-14 19:06:43,487 INFO EPOCH 113: training on 182922 raw words (78521 effective words) took 0.0s, 3911106 effective words/s
2025-12-14 19:06:43,507 INFO EPOCH 114: training on 182922 raw words (78536 effective words) took 0.0s, 3918212 effective words/s
2025-12-14 19:06:43,527 INFO EPOCH 115: training on 182922 raw words (78689 effective words) took 0.0s, 3907327 effective words/s
2025-12-14 19:06:43,547 INFO EPOCH 116: training on 182922 raw words (78553 effective words) took 0.0s, 3958452 effective words/s
2025-12-14 19:06:43,577 INFO EPOCH 117: training on 182922 raw words (78540 effective words) took 0.0s, 2705038 effective words/s
2025-12-14 19:06:43,643 INFO EPOCH 118: training on 182922 raw words (78634 effective words) took 0.1s, 1187900 effective words/s
2025-12-14 19:06:43,664 INFO EPOCH 119: training on 182922 raw words (78589 effective words) took 0.0s, 3888435 effective words/s
2025-12-14 19:06:43,684 INFO EPOCH 120: training on 182922 raw words (78585 effective words) took 0.0s, 3927245 effective words/s
2025-12-14 19:06:43,704 INFO EPOCH 121: training on 182922 raw words (78554 effective words) took 0.0s, 3912977 effective words/s
2025-12-14 19:06:43,725 INFO EPOCH 122: training on 182922 raw words (78603 effective words) took 0.0s, 3971403 effective words/s
2025-12-14 19:06:43,747 INFO EPOCH 123: training on 182922 raw words (78645 effective words) took 0.0s, 3696353 effective words/s
2025-12-14 19:06:43,769 INFO EPOCH 124: training on 182922 raw words (78465 effective words) took 0.0s, 3550379 effective words/s
2025-12-14 19:06:43,796 INFO EPOCH 125: training on 182922 raw words (78574 effective words) took 0.0s, 2958363 effective words/s
2025-12-14 19:06:43,817 INFO EPOCH 126: training on 182922 raw words (78615 effective words) took 0.0s, 3774237 effective words/s
2025-12-14 19:06:43,845 INFO EPOCH 127: training on 182922 raw words (78646 effective words) took 0.0s, 2870838 effective words/s
2025-12-14 19:06:43,871 INFO EPOCH 128: training on 182922 raw words (78642 effective words) took 0.0s, 3166888 effective words/s
2025-12-14 19:06:43,891 INFO EPOCH 129: training on 182922 raw words (78671 effective words) took 0.0s, 3904510 effective words/s
2025-12-14 19:06:43,912 INFO EPOCH 130: training on 182922 raw words (78658 effective words) took 0.0s, 3939721 effective words/s
2025-12-14 19:06:43,932 INFO EPOCH 131: training on 182922 raw words (78670 effective words) took 0.0s, 3963141 effective words/s
2025-12-14 19:06:43,953 INFO EPOCH 132: training on 182922 raw words (78562 effective words) took 0.0s, 3635215 effective words/s
2025-12-14 19:06:43,975 INFO EPOCH 133: training on 182922 raw words (78580 effective words) took 0.0s, 3699616 effective words/s
2025-12-14 19:06:43,997 INFO EPOCH 134: training on 182922 raw words (78576 effective words) took 0.0s, 3600818 effective words/s
2025-12-14 19:06:44,018 INFO EPOCH 135: training on 182922 raw words (78560 effective words) took 0.0s, 3942349 effective words/s
2025-12-14 19:06:44,038 INFO EPOCH 136: training on 182922 raw words (78474 effective words) took 0.0s, 3854851 effective words/s
2025-12-14 19:06:44,059 INFO EPOCH 137: training on 182922 raw words (78616 effective words) took 0.0s, 3926162 effective words/s
2025-12-14 19:06:44,081 INFO EPOCH 138: training on 182922 raw words (78575 effective words) took 0.0s, 3554177 effective words/s
2025-12-14 19:06:44,120 INFO EPOCH 139: training on 182922 raw words (78535 effective words) took 0.0s, 2056377 effective words/s
2025-12-14 19:06:44,150 INFO EPOCH 140: training on 182922 raw words (78753 effective words) took 0.0s, 2636297 effective words/s
2025-12-14 19:06:44,180 INFO EPOCH 141: training on 182922 raw words (78584 effective words) took 0.0s, 2650585 effective words/s
2025-12-14 19:06:44,207 INFO EPOCH 142: training on 182922 raw words (78657 effective words) took 0.0s, 3003628 effective words/s
2025-12-14 19:06:44,229 INFO EPOCH 143: training on 182922 raw words (78609 effective words) took 0.0s, 3560963 effective words/s
2025-12-14 19:06:44,252 INFO EPOCH 144: training on 182922 raw words (78626 effective words) took 0.0s, 3489242 effective words/s
2025-12-14 19:06:44,284 INFO EPOCH 145: training on 182922 raw words (78556 effective words) took 0.0s, 2531567 effective words/s
2025-12-14 19:06:44,309 INFO EPOCH 146: training on 182922 raw words (78529 effective words) took 0.0s, 3184356 effective words/s
2025-12-14 19:06:44,331 INFO EPOCH 147: training on 182922 raw words (78525 effective words) took 0.0s, 3554199 effective words/s
2025-12-14 19:06:44,354 INFO EPOCH 148: training on 182922 raw words (78590 effective words) took 0.0s, 3477049 effective words/s
2025-12-14 19:06:44,379 INFO EPOCH 149: training on 182922 raw words (78596 effective words) took 0.0s, 3225780 effective words/s
2025-12-14 19:06:44,409 INFO EPOCH 150: training on 182922 raw words (78567 effective words) took 0.0s, 2621671 effective words/s
2025-12-14 19:06:44,432 INFO EPOCH 151: training on 182922 raw words (78530 effective words) took 0.0s, 4768715 effective words/s
2025-12-14 19:06:44,452 INFO EPOCH 152: training on 182922 raw words (78627 effective words) took 0.0s, 3913657 effective words/s
2025-12-14 19:06:44,472 INFO EPOCH 153: training on 182922 raw words (78579 effective words) took 0.0s, 3981691 effective words/s
2025-12-14 19:06:44,492 INFO EPOCH 154: training on 182922 raw words (78667 effective words) took 0.0s, 3969038 effective words/s
2025-12-14 19:06:44,512 INFO EPOCH 155: training on 182922 raw words (78610 effective words) took 0.0s, 3890437 effective words/s
2025-12-14 19:06:44,532 INFO EPOCH 156: training on 182922 raw words (78672 effective words) took 0.0s, 3970776 effective words/s
2025-12-14 19:06:44,553 INFO EPOCH 157: training on 182922 raw words (78647 effective words) took 0.0s, 3975911 effective words/s
2025-12-14 19:06:44,572 INFO EPOCH 158: training on 182922 raw words (78526 effective words) took 0.0s, 3981064 effective words/s
2025-12-14 19:06:44,592 INFO EPOCH 159: training on 182922 raw words (78531 effective words) took 0.0s, 4002370 effective words/s
2025-12-14 19:06:44,612 INFO EPOCH 160: training on 182922 raw words (78540 effective words) took 0.0s, 3993272 effective words/s
2025-12-14 19:06:44,632 INFO EPOCH 161: training on 182922 raw words (78540 effective words) took 0.0s, 3985175 effective words/s
2025-12-14 19:06:44,652 INFO EPOCH 162: training on 182922 raw words (78583 effective words) took 0.0s, 4010880 effective words/s
2025-12-14 19:06:44,672 INFO EPOCH 163: training on 182922 raw words (78633 effective words) took 0.0s, 3994387 effective words/s
2025-12-14 19:06:44,692 INFO EPOCH 164: training on 182922 raw words (78621 effective words) took 0.0s, 4000356 effective words/s
2025-12-14 19:06:44,712 INFO EPOCH 165: training on 182922 raw words (78560 effective words) took 0.0s, 3999983 effective words/s
2025-12-14 19:06:44,731 INFO EPOCH 166: training on 182922 raw words (78634 effective words) took 0.0s, 4004405 effective words/s
2025-12-14 19:06:44,751 INFO EPOCH 167: training on 182922 raw words (78553 effective words) took 0.0s, 4005439 effective words/s
2025-12-14 19:06:44,771 INFO EPOCH 168: training on 182922 raw words (78640 effective words) took 0.0s, 3980487 effective words/s
2025-12-14 19:06:44,791 INFO EPOCH 169: training on 182922 raw words (78633 effective words) took 0.0s, 3989439 effective words/s
2025-12-14 19:06:44,811 INFO EPOCH 170: training on 182922 raw words (78530 effective words) took 0.0s, 3987197 effective words/s
2025-12-14 19:06:44,831 INFO EPOCH 171: training on 182922 raw words (78586 effective words) took 0.0s, 3887397 effective words/s
2025-12-14 19:06:44,853 INFO EPOCH 172: training on 182922 raw words (78555 effective words) took 0.0s, 3619170 effective words/s
2025-12-14 19:06:44,876 INFO EPOCH 173: training on 182922 raw words (78572 effective words) took 0.0s, 3569805 effective words/s
2025-12-14 19:06:44,897 INFO EPOCH 174: training on 182922 raw words (78550 effective words) took 0.0s, 3861271 effective words/s
2025-12-14 19:06:44,917 INFO EPOCH 175: training on 182922 raw words (78538 effective words) took 0.0s, 3950355 effective words/s
2025-12-14 19:06:44,937 INFO EPOCH 176: training on 182922 raw words (78648 effective words) took 0.0s, 3956004 effective words/s
2025-12-14 19:06:44,957 INFO EPOCH 177: training on 182922 raw words (78591 effective words) took 0.0s, 3929206 effective words/s
2025-12-14 19:06:44,977 INFO EPOCH 178: training on 182922 raw words (78589 effective words) took 0.0s, 3998855 effective words/s
2025-12-14 19:06:44,997 INFO EPOCH 179: training on 182922 raw words (78527 effective words) took 0.0s, 3950646 effective words/s
2025-12-14 19:06:45,017 INFO EPOCH 180: training on 182922 raw words (78556 effective words) took 0.0s, 4012173 effective words/s
2025-12-14 19:06:45,037 INFO EPOCH 181: training on 182922 raw words (78552 effective words) took 0.0s, 3999796 effective words/s
2025-12-14 19:06:45,057 INFO EPOCH 182: training on 182922 raw words (78604 effective words) took 0.0s, 3948115 effective words/s
2025-12-14 19:06:45,077 INFO EPOCH 183: training on 182922 raw words (78580 effective words) took 0.0s, 3967994 effective words/s
2025-12-14 19:06:45,097 INFO EPOCH 184: training on 182922 raw words (78453 effective words) took 0.0s, 4000739 effective words/s
2025-12-14 19:06:45,117 INFO EPOCH 185: training on 182922 raw words (78667 effective words) took 0.0s, 3975373 effective words/s
2025-12-14 19:06:45,137 INFO EPOCH 186: training on 182922 raw words (78534 effective words) took 0.0s, 4025355 effective words/s
2025-12-14 19:06:45,157 INFO EPOCH 187: training on 182922 raw words (78601 effective words) took 0.0s, 3946304 effective words/s
2025-12-14 19:06:45,177 INFO EPOCH 188: training on 182922 raw words (78677 effective words) took 0.0s, 3975694 effective words/s
2025-12-14 19:06:45,197 INFO EPOCH 189: training on 182922 raw words (78645 effective words) took 0.0s, 3979926 effective words/s
2025-12-14 19:06:45,220 INFO EPOCH 190: training on 182922 raw words (78589 effective words) took 0.0s, 3372629 effective words/s
2025-12-14 19:06:45,309 INFO EPOCH 191: training on 182922 raw words (78599 effective words) took 0.1s, 1177797 effective words/s
2025-12-14 19:06:45,331 INFO EPOCH 192: training on 182922 raw words (78526 effective words) took 0.0s, 3752833 effective words/s
2025-12-14 19:06:45,352 INFO EPOCH 193: training on 182922 raw words (78702 effective words) took 0.0s, 3750602 effective words/s
2025-12-14 19:06:45,373 INFO EPOCH 194: training on 182922 raw words (78552 effective words) took 0.0s, 3830505 effective words/s
2025-12-14 19:06:45,401 INFO EPOCH 195: training on 182922 raw words (78690 effective words) took 0.0s, 2831501 effective words/s
2025-12-14 19:06:45,423 INFO EPOCH 196: training on 182922 raw words (78563 effective words) took 0.0s, 3645375 effective words/s
2025-12-14 19:06:45,444 INFO EPOCH 197: training on 182922 raw words (78647 effective words) took 0.0s, 3767784 effective words/s
2025-12-14 19:06:45,465 INFO EPOCH 198: training on 182922 raw words (78468 effective words) took 0.0s, 3835542 effective words/s
2025-12-14 19:06:45,486 INFO EPOCH 199: training on 182922 raw words (78642 effective words) took 0.0s, 3781767 effective words/s
2025-12-14 19:06:45,507 INFO EPOCH 200: training on 182922 raw words (78601 effective words) took 0.0s, 3814618 effective words/s
2025-12-14 19:06:45,530 INFO EPOCH 201: training on 182922 raw words (78621 effective words) took 0.0s, 3446299 effective words/s
2025-12-14 19:06:45,552 INFO EPOCH 202: training on 182922 raw words (78536 effective words) took 0.0s, 3733106 effective words/s
2025-12-14 19:06:45,573 INFO EPOCH 203: training on 182922 raw words (78569 effective words) took 0.0s, 3833063 effective words/s
2025-12-14 19:06:45,593 INFO EPOCH 204: training on 182922 raw words (78618 effective words) took 0.0s, 3838231 effective words/s
2025-12-14 19:06:45,614 INFO EPOCH 205: training on 182922 raw words (78685 effective words) took 0.0s, 3770726 effective words/s
2025-12-14 19:06:45,636 INFO EPOCH 206: training on 182922 raw words (78532 effective words) took 0.0s, 3702302 effective words/s
2025-12-14 19:06:45,657 INFO EPOCH 207: training on 182922 raw words (78608 effective words) took 0.0s, 3856240 effective words/s
2025-12-14 19:06:45,678 INFO EPOCH 208: training on 182922 raw words (78572 effective words) took 0.0s, 3754448 effective words/s
2025-12-14 19:06:45,699 INFO EPOCH 209: training on 182922 raw words (78565 effective words) took 0.0s, 3843360 effective words/s
2025-12-14 19:06:45,720 INFO EPOCH 210: training on 182922 raw words (78639 effective words) took 0.0s, 3735524 effective words/s
2025-12-14 19:06:45,742 INFO EPOCH 211: training on 182922 raw words (78611 effective words) took 0.0s, 3629554 effective words/s
2025-12-14 19:06:45,765 INFO EPOCH 212: training on 182922 raw words (78626 effective words) took 0.0s, 3470096 effective words/s
2025-12-14 19:06:45,794 INFO EPOCH 213: training on 182922 raw words (78636 effective words) took 0.0s, 2760684 effective words/s
2025-12-14 19:06:45,814 INFO EPOCH 214: training on 182922 raw words (78615 effective words) took 0.0s, 3882430 effective words/s
2025-12-14 19:06:45,837 INFO EPOCH 215: training on 182922 raw words (78579 effective words) took 0.0s, 3590172 effective words/s
2025-12-14 19:06:45,857 INFO EPOCH 216: training on 182922 raw words (78588 effective words) took 0.0s, 3847018 effective words/s
2025-12-14 19:06:45,884 INFO EPOCH 217: training on 182922 raw words (78543 effective words) took 0.0s, 2940767 effective words/s
2025-12-14 19:06:45,906 INFO EPOCH 218: training on 182922 raw words (78501 effective words) took 0.0s, 3718789 effective words/s
2025-12-14 19:06:45,926 INFO EPOCH 219: training on 182922 raw words (78598 effective words) took 0.0s, 3862270 effective words/s
2025-12-14 19:06:45,948 INFO EPOCH 220: training on 182922 raw words (78529 effective words) took 0.0s, 3748983 effective words/s
2025-12-14 19:06:45,969 INFO EPOCH 221: training on 182922 raw words (78591 effective words) took 0.0s, 3656685 effective words/s
2025-12-14 19:06:46,000 INFO EPOCH 222: training on 182922 raw words (78596 effective words) took 0.0s, 2573336 effective words/s
2025-12-14 19:06:46,022 INFO EPOCH 223: training on 182922 raw words (78635 effective words) took 0.0s, 3611915 effective words/s
2025-12-14 19:06:46,043 INFO EPOCH 224: training on 182922 raw words (78596 effective words) took 0.0s, 3916183 effective words/s
2025-12-14 19:06:46,063 INFO EPOCH 225: training on 182922 raw words (78644 effective words) took 0.0s, 3922231 effective words/s
2025-12-14 19:06:46,083 INFO EPOCH 226: training on 182922 raw words (78559 effective words) took 0.0s, 3919026 effective words/s
2025-12-14 19:06:46,104 INFO EPOCH 227: training on 182922 raw words (78705 effective words) took 0.0s, 3911010 effective words/s
2025-12-14 19:06:46,124 INFO EPOCH 228: training on 182922 raw words (78625 effective words) took 0.0s, 3941160 effective words/s
2025-12-14 19:06:46,144 INFO EPOCH 229: training on 182922 raw words (78554 effective words) took 0.0s, 3942592 effective words/s
2025-12-14 19:06:46,164 INFO EPOCH 230: training on 182922 raw words (78585 effective words) took 0.0s, 3942433 effective words/s
2025-12-14 19:06:46,185 INFO EPOCH 231: training on 182922 raw words (78562 effective words) took 0.0s, 3941138 effective words/s
2025-12-14 19:06:46,205 INFO EPOCH 232: training on 182922 raw words (78562 effective words) took 0.0s, 3967711 effective words/s
2025-12-14 19:06:46,225 INFO EPOCH 233: training on 182922 raw words (78537 effective words) took 0.0s, 3956964 effective words/s
2025-12-14 19:06:46,245 INFO EPOCH 234: training on 182922 raw words (78685 effective words) took 0.0s, 3892960 effective words/s
2025-12-14 19:06:46,265 INFO EPOCH 235: training on 182922 raw words (78581 effective words) took 0.0s, 3982524 effective words/s
2025-12-14 19:06:46,285 INFO EPOCH 236: training on 182922 raw words (78588 effective words) took 0.0s, 3975759 effective words/s
2025-12-14 19:06:46,305 INFO EPOCH 237: training on 182922 raw words (78569 effective words) took 0.0s, 3960006 effective words/s
2025-12-14 19:06:46,325 INFO EPOCH 238: training on 182922 raw words (78530 effective words) took 0.0s, 3955349 effective words/s
2025-12-14 19:06:46,346 INFO EPOCH 239: training on 182922 raw words (78548 effective words) took 0.0s, 3911242 effective words/s
2025-12-14 19:06:46,366 INFO EPOCH 240: training on 182922 raw words (78618 effective words) took 0.0s, 3919175 effective words/s
2025-12-14 19:06:46,386 INFO EPOCH 241: training on 182922 raw words (78590 effective words) took 0.0s, 3933532 effective words/s
2025-12-14 19:06:46,406 INFO EPOCH 242: training on 182922 raw words (78476 effective words) took 0.0s, 3961875 effective words/s
2025-12-14 19:06:46,427 INFO EPOCH 243: training on 182922 raw words (78568 effective words) took 0.0s, 3901141 effective words/s
2025-12-14 19:06:46,447 INFO EPOCH 244: training on 182922 raw words (78539 effective words) took 0.0s, 3923819 effective words/s
2025-12-14 19:06:46,467 INFO EPOCH 245: training on 182922 raw words (78619 effective words) took 0.0s, 3932679 effective words/s
2025-12-14 19:06:46,488 INFO EPOCH 246: training on 182922 raw words (78637 effective words) took 0.0s, 3912670 effective words/s
2025-12-14 19:06:46,508 INFO EPOCH 247: training on 182922 raw words (78593 effective words) took 0.0s, 3856166 effective words/s
2025-12-14 19:06:46,531 INFO EPOCH 248: training on 182922 raw words (78552 effective words) took 0.0s, 3587607 effective words/s
2025-12-14 19:06:46,552 INFO EPOCH 249: training on 182922 raw words (78544 effective words) took 0.0s, 3883342 effective words/s
2025-12-14 19:06:46,573 INFO EPOCH 250: training on 182922 raw words (78582 effective words) took 0.0s, 3797317 effective words/s
2025-12-14 19:06:46,593 INFO EPOCH 251: training on 182922 raw words (78588 effective words) took 0.0s, 3884758 effective words/s
2025-12-14 19:06:46,613 INFO EPOCH 252: training on 182922 raw words (78638 effective words) took 0.0s, 3930664 effective words/s
2025-12-14 19:06:46,634 INFO EPOCH 253: training on 182922 raw words (78540 effective words) took 0.0s, 3903288 effective words/s
2025-12-14 19:06:46,654 INFO EPOCH 254: training on 182922 raw words (78608 effective words) took 0.0s, 3895599 effective words/s
2025-12-14 19:06:46,674 INFO EPOCH 255: training on 182922 raw words (78492 effective words) took 0.0s, 3957821 effective words/s
2025-12-14 19:06:46,695 INFO EPOCH 256: training on 182922 raw words (78562 effective words) took 0.0s, 3936703 effective words/s
2025-12-14 19:06:46,715 INFO EPOCH 257: training on 182922 raw words (78530 effective words) took 0.0s, 3923639 effective words/s
2025-12-14 19:06:46,735 INFO EPOCH 258: training on 182922 raw words (78537 effective words) took 0.0s, 3940972 effective words/s
2025-12-14 19:06:46,755 INFO EPOCH 259: training on 182922 raw words (78625 effective words) took 0.0s, 3949748 effective words/s
2025-12-14 19:06:46,775 INFO EPOCH 260: training on 182922 raw words (78560 effective words) took 0.0s, 3955814 effective words/s
2025-12-14 19:06:46,796 INFO EPOCH 261: training on 182922 raw words (78559 effective words) took 0.0s, 3899427 effective words/s
2025-12-14 19:06:46,816 INFO EPOCH 262: training on 182922 raw words (78570 effective words) took 0.0s, 3922738 effective words/s
2025-12-14 19:06:46,836 INFO EPOCH 263: training on 182922 raw words (78693 effective words) took 0.0s, 3928340 effective words/s
2025-12-14 19:06:46,856 INFO EPOCH 264: training on 182922 raw words (78556 effective words) took 0.0s, 3950921 effective words/s
2025-12-14 19:06:46,877 INFO EPOCH 265: training on 182922 raw words (78695 effective words) took 0.0s, 3943426 effective words/s
2025-12-14 19:06:46,897 INFO EPOCH 266: training on 182922 raw words (78561 effective words) took 0.0s, 3961075 effective words/s
2025-12-14 19:06:46,917 INFO EPOCH 267: training on 182922 raw words (78594 effective words) took 0.0s, 3930461 effective words/s
2025-12-14 19:06:46,937 INFO EPOCH 268: training on 182922 raw words (78564 effective words) took 0.0s, 3947675 effective words/s
2025-12-14 19:06:46,957 INFO EPOCH 269: training on 182922 raw words (78609 effective words) took 0.0s, 3934196 effective words/s
2025-12-14 19:06:46,977 INFO EPOCH 270: training on 182922 raw words (78600 effective words) took 0.0s, 3952298 effective words/s
2025-12-14 19:06:46,997 INFO EPOCH 271: training on 182922 raw words (78592 effective words) took 0.0s, 3976506 effective words/s
2025-12-14 19:06:47,019 INFO EPOCH 272: training on 182922 raw words (78629 effective words) took 0.0s, 3657638 effective words/s
2025-12-14 19:06:47,039 INFO EPOCH 273: training on 182922 raw words (78547 effective words) took 0.0s, 3948731 effective words/s
2025-12-14 19:06:47,060 INFO EPOCH 274: training on 182922 raw words (78606 effective words) took 0.0s, 3840606 effective words/s
2025-12-14 19:06:47,080 INFO EPOCH 275: training on 182922 raw words (78570 effective words) took 0.0s, 3918638 effective words/s
2025-12-14 19:06:47,101 INFO EPOCH 276: training on 182922 raw words (78606 effective words) took 0.0s, 3945053 effective words/s
2025-12-14 19:06:47,121 INFO EPOCH 277: training on 182922 raw words (78506 effective words) took 0.0s, 3921819 effective words/s
2025-12-14 19:06:47,141 INFO EPOCH 278: training on 182922 raw words (78585 effective words) took 0.0s, 3936450 effective words/s
2025-12-14 19:06:47,163 INFO EPOCH 279: training on 182922 raw words (78485 effective words) took 0.0s, 3596586 effective words/s
2025-12-14 19:06:47,185 INFO EPOCH 280: training on 182922 raw words (78623 effective words) took 0.0s, 3678699 effective words/s
2025-12-14 19:06:47,206 INFO EPOCH 281: training on 182922 raw words (78632 effective words) took 0.0s, 3845822 effective words/s
2025-12-14 19:06:47,227 INFO EPOCH 282: training on 182922 raw words (78569 effective words) took 0.0s, 3788938 effective words/s
2025-12-14 19:06:47,248 INFO EPOCH 283: training on 182922 raw words (78522 effective words) took 0.0s, 3787075 effective words/s
2025-12-14 19:06:47,268 INFO EPOCH 284: training on 182922 raw words (78711 effective words) took 0.0s, 3882306 effective words/s
2025-12-14 19:06:47,289 INFO EPOCH 285: training on 182922 raw words (78596 effective words) took 0.0s, 3852359 effective words/s
2025-12-14 19:06:47,310 INFO EPOCH 286: training on 182922 raw words (78645 effective words) took 0.0s, 3869349 effective words/s
2025-12-14 19:06:47,330 INFO EPOCH 287: training on 182922 raw words (78614 effective words) took 0.0s, 3919774 effective words/s
2025-12-14 19:06:47,350 INFO EPOCH 288: training on 182922 raw words (78627 effective words) took 0.0s, 3941598 effective words/s
2025-12-14 19:06:47,371 INFO EPOCH 289: training on 182922 raw words (78650 effective words) took 0.0s, 3890603 effective words/s
2025-12-14 19:06:47,391 INFO EPOCH 290: training on 182922 raw words (78565 effective words) took 0.0s, 3934562 effective words/s
2025-12-14 19:06:47,411 INFO EPOCH 291: training on 182922 raw words (78626 effective words) took 0.0s, 3949831 effective words/s
2025-12-14 19:06:47,432 INFO EPOCH 292: training on 182922 raw words (78596 effective words) took 0.0s, 3886106 effective words/s
2025-12-14 19:06:47,452 INFO EPOCH 293: training on 182922 raw words (78590 effective words) took 0.0s, 3922701 effective words/s
2025-12-14 19:06:47,472 INFO EPOCH 294: training on 182922 raw words (78589 effective words) took 0.0s, 3972502 effective words/s
2025-12-14 19:06:47,492 INFO EPOCH 295: training on 182922 raw words (78555 effective words) took 0.0s, 3934159 effective words/s
2025-12-14 19:06:47,513 INFO EPOCH 296: training on 182922 raw words (78615 effective words) took 0.0s, 3937460 effective words/s
2025-12-14 19:06:47,533 INFO EPOCH 297: training on 182922 raw words (78573 effective words) took 0.0s, 3938258 effective words/s
2025-12-14 19:06:47,553 INFO EPOCH 298: training on 182922 raw words (78694 effective words) took 0.0s, 3959770 effective words/s
2025-12-14 19:06:47,573 INFO EPOCH 299: training on 182922 raw words (78555 effective words) took 0.0s, 3960865 effective words/s
2025-12-14 19:06:47,573 INFO Doc2Vec lifecycle event {'msg': 'training on 54876600 raw words (23577270 effective words) took 6.4s, 3685067 effective words/s', 'datetime': '2025-12-14T19:06:47.573600', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'train'}
2025-12-14 19:06:47,573 INFO Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_model.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-12-14T19:06:47.573813', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'saving'}
2025-12-14 19:06:47,574 INFO not storing attribute cum_table
2025-12-14 19:06:47,581 INFO saved doc2vec_model.model
2025-12-14 19:06:47,585 INFO loading Doc2Vec object from doc2vec_model.model
2025-12-14 19:06:47,586 INFO loading dv recursively from doc2vec_model.model.dv.* with mmap=None
2025-12-14 19:06:47,586 INFO loading wv recursively from doc2vec_model.model.wv.* with mmap=None
2025-12-14 19:06:47,586 INFO setting ignored attribute cum_table to None
2025-12-14 19:06:47,593 INFO Doc2Vec lifecycle event {'fname': 'doc2vec_model.model', 'datetime': '2025-12-14T19:06:47.593278', 'gensim': '4.3.3', 'python': '3.10.19 (main, Dec 14 2025, 17:25:52) [Clang 17.0.0 (clang-1700.0.13.5)]', 'platform': 'macOS-15.5-arm64-arm-64bit', 'event': 'loaded'}
2025-12-14 19:06:47,593 INFO Loaded Doc2Vec model
2025-12-14 19:06:47,593 INFO Loaded Doc2Vec model
2025-12-14 19:06:47,593 INFO Loaded FAISS index
2025-12-14 19:06:47,593 INFO Loaded FAISS index
2025-12-14 19:06:47,625 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:06:47,625 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:06:47,625 INFO Processing question 1
2025-12-14 19:06:47,625 INFO Processing question 1
2025-12-14 19:06:48,967 INFO Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-12-14 19:15:31,436 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 19:15:31,436 INFO [33mPress CTRL+C to quit[0m
2025-12-14 19:15:45,399 INFO 127.0.0.1 - - [14/Dec/2025 19:15:45] "GET / HTTP/1.1" 200 -
2025-12-14 19:15:45,541 INFO 127.0.0.1 - - [14/Dec/2025 19:15:45] "[36mGET /static/css/form.css HTTP/1.1[0m" 304 -
2025-12-14 19:15:45,575 INFO 127.0.0.1 - - [14/Dec/2025 19:15:45] "[36mGET /static/js/form.js HTTP/1.1[0m" 304 -
2025-12-14 19:18:23,151 INFO Received form responses; launching background generation
2025-12-14 19:18:23,153 INFO Background report generation started
2025-12-14 19:18:23,165 INFO 127.0.0.1 - - [14/Dec/2025 19:18:23] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:18:23,167 INFO Starting report generation
2025-12-14 19:18:23,167 INFO Starting report generation
2025-12-14 19:18:23,169 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:18:23,169 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:18:23,169 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 193, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:18:23,169 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 193, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:18:23,172 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:18:23,172 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:18:23,173 INFO Processing question 1
2025-12-14 19:18:23,173 INFO Processing question 1
2025-12-14 19:18:23,174 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,174 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,175 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,175 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,176 INFO Processing question 2
2025-12-14 19:18:23,176 INFO Processing question 2
2025-12-14 19:18:23,176 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,176 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,176 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,176 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,176 INFO Processing question 3
2025-12-14 19:18:23,176 INFO Processing question 3
2025-12-14 19:18:23,177 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,177 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,177 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,177 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,177 INFO Processing question 4
2025-12-14 19:18:23,177 INFO Processing question 4
2025-12-14 19:18:23,178 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,178 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,178 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,178 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,178 INFO Processing question 5
2025-12-14 19:18:23,178 INFO Processing question 5
2025-12-14 19:18:23,179 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,179 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,180 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,180 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,180 INFO Processing question 6
2025-12-14 19:18:23,180 INFO Processing question 6
2025-12-14 19:18:23,181 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,181 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,181 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,181 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,181 INFO Processing question 7
2025-12-14 19:18:23,181 INFO Processing question 7
2025-12-14 19:18:23,181 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,181 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,181 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,181 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,181 INFO Processing question 8
2025-12-14 19:18:23,181 INFO Processing question 8
2025-12-14 19:18:23,181 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,181 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,181 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,181 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,181 INFO Processing question 9
2025-12-14 19:18:23,181 INFO Processing question 9
2025-12-14 19:18:23,181 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,181 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,181 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,181 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,181 INFO Processing question 10
2025-12-14 19:18:23,181 INFO Processing question 10
2025-12-14 19:18:23,181 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,181 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,182 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,182 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,182 INFO Processing question 11
2025-12-14 19:18:23,182 INFO Processing question 11
2025-12-14 19:18:23,182 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,182 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,182 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,182 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,182 INFO Processing question 12
2025-12-14 19:18:23,182 INFO Processing question 12
2025-12-14 19:18:23,183 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,183 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,183 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,183 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,183 INFO Processing question 13
2025-12-14 19:18:23,183 INFO Processing question 13
2025-12-14 19:18:23,183 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,183 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,183 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,183 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,183 INFO Processing question 14
2025-12-14 19:18:23,183 INFO Processing question 14
2025-12-14 19:18:23,184 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,184 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,184 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,184 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,184 INFO Processing question 15
2025-12-14 19:18:23,184 INFO Processing question 15
2025-12-14 19:18:23,184 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,184 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:18:23,184 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,184 INFO No LLM provider available; returning placeholder
2025-12-14 19:18:23,185 INFO Wrote analysis to ./llm_analyses/Study on AI-assisted Ethical Feedback Tools_-llm-analysis.txt
2025-12-14 19:18:23,185 INFO Wrote analysis to ./llm_analyses/Study on AI-assisted Ethical Feedback Tools_-llm-analysis.txt
2025-12-14 19:18:23,185 INFO Report generation finished: ./llm_analyses/Study on AI-assisted Ethical Feedback Tools_-llm-analysis.txt
2025-12-14 19:18:23,204 INFO 127.0.0.1 - - [14/Dec/2025 19:18:23] "[36mGET /static/css/submit_success.css HTTP/1.1[0m" 304 -
2025-12-14 19:18:23,237 INFO 127.0.0.1 - - [14/Dec/2025 19:18:23] "GET /reports/status HTTP/1.1" 200 -
2025-12-14 19:18:25,740 INFO 127.0.0.1 - - [14/Dec/2025 19:18:25] "GET /reports/latest HTTP/1.1" 200 -
2025-12-14 19:23:17,303 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 19:23:17,303 INFO [33mPress CTRL+C to quit[0m
2025-12-14 19:23:31,303 INFO 127.0.0.1 - - [14/Dec/2025 19:23:31] "[36mGET /reports/latest HTTP/1.1[0m" 304 -
2025-12-14 19:23:37,015 INFO 127.0.0.1 - - [14/Dec/2025 19:23:37] "[36mGET /reports/latest HTTP/1.1[0m" 304 -
2025-12-14 19:23:41,244 INFO 127.0.0.1 - - [14/Dec/2025 19:23:41] "GET / HTTP/1.1" 200 -
2025-12-14 19:23:41,286 INFO 127.0.0.1 - - [14/Dec/2025 19:23:41] "[36mGET /static/css/form.css HTTP/1.1[0m" 304 -
2025-12-14 19:23:41,288 INFO 127.0.0.1 - - [14/Dec/2025 19:23:41] "[36mGET /static/js/form.js HTTP/1.1[0m" 304 -
2025-12-14 19:24:37,895 INFO Received form responses; launching background generation
2025-12-14 19:24:37,896 INFO Background report generation started
2025-12-14 19:24:37,914 INFO 127.0.0.1 - - [14/Dec/2025 19:24:37] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:24:37,926 INFO Starting report generation
2025-12-14 19:24:37,926 INFO Starting report generation
2025-12-14 19:24:37,927 WARNING Temporary hardcoded ANTHROPIC_API_KEY is set from llama_rag.py — remove after testing
2025-12-14 19:24:37,927 WARNING Temporary hardcoded ANTHROPIC_API_KEY is set from llama_rag.py — remove after testing
2025-12-14 19:24:37,928 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:24:37,928 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:24:37,928 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:24:37,928 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:24:37,930 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:24:37,930 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:24:37,930 INFO Processing question 1
2025-12-14 19:24:37,930 INFO Processing question 1
2025-12-14 19:24:37,930 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,930 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,931 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,931 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,932 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,932 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,932 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,932 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,932 INFO Processing question 2
2025-12-14 19:24:37,932 INFO Processing question 2
2025-12-14 19:24:37,932 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,932 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,933 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,933 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,933 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,933 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,934 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,934 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,934 INFO Processing question 3
2025-12-14 19:24:37,934 INFO Processing question 3
2025-12-14 19:24:37,934 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,934 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,934 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,934 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,936 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,936 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,938 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,938 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,938 INFO Processing question 4
2025-12-14 19:24:37,938 INFO Processing question 4
2025-12-14 19:24:37,940 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,940 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,940 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,940 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,941 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,941 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,945 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,945 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,945 INFO Processing question 5
2025-12-14 19:24:37,945 INFO Processing question 5
2025-12-14 19:24:37,948 INFO 127.0.0.1 - - [14/Dec/2025 19:24:37] "[36mGET /static/css/submit_success.css HTTP/1.1[0m" 304 -
2025-12-14 19:24:37,953 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,953 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,955 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,955 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,956 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,956 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,956 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,956 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,956 INFO Processing question 6
2025-12-14 19:24:37,956 INFO Processing question 6
2025-12-14 19:24:37,956 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,956 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,957 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,957 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,957 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,957 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,957 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,957 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,957 INFO Processing question 7
2025-12-14 19:24:37,957 INFO Processing question 7
2025-12-14 19:24:37,958 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,958 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,958 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,958 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,958 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,958 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,958 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,958 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,959 INFO Processing question 8
2025-12-14 19:24:37,959 INFO Processing question 8
2025-12-14 19:24:37,959 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,959 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,959 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,959 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,959 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,959 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,960 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,960 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,960 INFO Processing question 9
2025-12-14 19:24:37,960 INFO Processing question 9
2025-12-14 19:24:37,960 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,960 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,960 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,960 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,961 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,961 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,961 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,961 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,961 INFO Processing question 10
2025-12-14 19:24:37,961 INFO Processing question 10
2025-12-14 19:24:37,961 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,961 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,962 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,962 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,962 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,962 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,962 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,962 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,962 INFO Processing question 11
2025-12-14 19:24:37,962 INFO Processing question 11
2025-12-14 19:24:37,963 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,963 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,963 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,963 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,965 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,965 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,967 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,967 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,967 INFO Processing question 12
2025-12-14 19:24:37,967 INFO Processing question 12
2025-12-14 19:24:37,968 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,968 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,968 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,968 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,968 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,968 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,969 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,969 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,969 INFO Processing question 13
2025-12-14 19:24:37,969 INFO Processing question 13
2025-12-14 19:24:37,969 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,969 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,969 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,969 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,969 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,969 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,969 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,969 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,970 INFO Processing question 14
2025-12-14 19:24:37,970 INFO Processing question 14
2025-12-14 19:24:37,970 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,970 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,970 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,970 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,970 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,970 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,970 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,970 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,970 INFO Processing question 15
2025-12-14 19:24:37,970 INFO Processing question 15
2025-12-14 19:24:37,970 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,970 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:24:37,971 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,971 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-12-14 19:24:37,971 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,971 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 146, in _call_llm
    import anthropic
ModuleNotFoundError: No module named 'anthropic'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 159, in _call_llm
    import requests
ModuleNotFoundError: No module named 'requests'
2025-12-14 19:24:37,971 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,971 INFO No LLM provider available; returning placeholder
2025-12-14 19:24:37,971 INFO Wrote analysis to ./llm_analyses/Study on AI-assisted Ethical Feedback Tools-llm-analysis.txt
2025-12-14 19:24:37,971 INFO Wrote analysis to ./llm_analyses/Study on AI-assisted Ethical Feedback Tools-llm-analysis.txt
2025-12-14 19:24:37,971 INFO Report generation finished: ./llm_analyses/Study on AI-assisted Ethical Feedback Tools-llm-analysis.txt
2025-12-14 19:24:37,999 INFO 127.0.0.1 - - [14/Dec/2025 19:24:37] "GET /reports/status HTTP/1.1" 200 -
2025-12-14 19:24:40,628 INFO 127.0.0.1 - - [14/Dec/2025 19:24:40] "GET /reports/latest HTTP/1.1" 200 -
2025-12-14 19:28:06,211 INFO Received form responses; launching background generation
2025-12-14 19:28:06,212 INFO Background report generation started
2025-12-14 19:28:06,212 INFO 127.0.0.1 - - [14/Dec/2025 19:28:06] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:28:06,212 INFO Starting report generation
2025-12-14 19:28:06,212 INFO Starting report generation
2025-12-14 19:28:06,213 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:28:06,213 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:28:06,213 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:28:06,213 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:28:06,214 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:28:06,214 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:28:06,214 INFO Processing question 1
2025-12-14 19:28:06,214 INFO Processing question 1
2025-12-14 19:28:06,214 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:06,214 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:07,615 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:07,615 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbipbRuWfx6mFBnoVQ'}
2025-12-14 19:28:07,615 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbipbRuWfx6mFBnoVQ'}
2025-12-14 19:28:08,260 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbipbRuWfx6mFBnoVQ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:08,260 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbipbRuWfx6mFBnoVQ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:08,263 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:08,263 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:08,264 INFO Processing question 2
2025-12-14 19:28:08,264 INFO Processing question 2
2025-12-14 19:28:08,265 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:08,265 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:08,540 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:08,543 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbnrBcBFD6NLUG33zX'}
2025-12-14 19:28:08,543 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbnrBcBFD6NLUG33zX'}
2025-12-14 19:28:08,835 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbnrBcBFD6NLUG33zX'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:08,835 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbnrBcBFD6NLUG33zX'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:08,839 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:08,839 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:08,841 INFO Processing question 3
2025-12-14 19:28:08,841 INFO Processing question 3
2025-12-14 19:28:08,842 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:08,842 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:09,106 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:09,107 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbqJH8ZWN5jLJFtvZt'}
2025-12-14 19:28:09,107 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbqJH8ZWN5jLJFtvZt'}
2025-12-14 19:28:09,364 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbqJH8ZWN5jLJFtvZt'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:09,364 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbqJH8ZWN5jLJFtvZt'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:09,365 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:09,365 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:09,366 INFO Processing question 4
2025-12-14 19:28:09,366 INFO Processing question 4
2025-12-14 19:28:09,366 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:09,366 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:09,857 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:09,857 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbtSnFn6BUUdEv7ydk'}
2025-12-14 19:28:09,857 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbtSnFn6BUUdEv7ydk'}
2025-12-14 19:28:10,092 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbtSnFn6BUUdEv7ydk'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:10,092 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbtSnFn6BUUdEv7ydk'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:10,095 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:10,095 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:10,097 INFO Processing question 5
2025-12-14 19:28:10,097 INFO Processing question 5
2025-12-14 19:28:10,097 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:10,097 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:10,364 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:10,365 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbvfjDMQUFdqooSrHQ'}
2025-12-14 19:28:10,365 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbvfjDMQUFdqooSrHQ'}
2025-12-14 19:28:10,675 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbvfjDMQUFdqooSrHQ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:10,675 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbvfjDMQUFdqooSrHQ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:10,679 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:10,679 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:10,681 INFO Processing question 6
2025-12-14 19:28:10,681 INFO Processing question 6
2025-12-14 19:28:10,681 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:10,681 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:10,979 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:10,980 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbyFm3H8shoG7uZ4Vw'}
2025-12-14 19:28:10,980 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbyFm3H8shoG7uZ4Vw'}
2025-12-14 19:28:11,258 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbyFm3H8shoG7uZ4Vw'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:11,258 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gbyFm3H8shoG7uZ4Vw'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:11,270 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:11,270 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:11,272 INFO Processing question 7
2025-12-14 19:28:11,272 INFO Processing question 7
2025-12-14 19:28:11,273 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:11,273 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:11,631 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:11,633 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc1tG1Da9JGSc3V2Bg'}
2025-12-14 19:28:11,633 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc1tG1Da9JGSc3V2Bg'}
2025-12-14 19:28:11,953 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc1tG1Da9JGSc3V2Bg'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:11,953 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc1tG1Da9JGSc3V2Bg'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:11,954 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:11,954 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:11,955 INFO Processing question 8
2025-12-14 19:28:11,955 INFO Processing question 8
2025-12-14 19:28:11,955 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:11,955 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:12,218 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:12,219 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc4bUqBiQwyWnV5F6U'}
2025-12-14 19:28:12,219 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc4bUqBiQwyWnV5F6U'}
2025-12-14 19:28:12,527 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc4bUqBiQwyWnV5F6U'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:12,527 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc4bUqBiQwyWnV5F6U'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:12,529 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:12,529 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:12,531 INFO Processing question 9
2025-12-14 19:28:12,531 INFO Processing question 9
2025-12-14 19:28:12,531 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:12,531 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:12,802 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:12,802 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc763ZvJ2VaPsfzZ37'}
2025-12-14 19:28:12,802 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc763ZvJ2VaPsfzZ37'}
2025-12-14 19:28:13,106 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc763ZvJ2VaPsfzZ37'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:13,106 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc763ZvJ2VaPsfzZ37'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:13,109 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:13,109 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:13,110 INFO Processing question 10
2025-12-14 19:28:13,110 INFO Processing question 10
2025-12-14 19:28:13,111 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:13,111 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:13,356 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:13,356 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc9XeJZzwMZ3zuFkXw'}
2025-12-14 19:28:13,356 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc9XeJZzwMZ3zuFkXw'}
2025-12-14 19:28:13,616 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc9XeJZzwMZ3zuFkXw'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:13,616 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gc9XeJZzwMZ3zuFkXw'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:13,617 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:13,617 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:13,618 INFO Processing question 11
2025-12-14 19:28:13,618 INFO Processing question 11
2025-12-14 19:28:13,618 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:13,618 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:13,886 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:13,886 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcBjbUHbC7abYNMNnE'}
2025-12-14 19:28:13,886 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcBjbUHbC7abYNMNnE'}
2025-12-14 19:28:14,252 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcBjbUHbC7abYNMNnE'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:14,252 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcBjbUHbC7abYNMNnE'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:14,253 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:14,253 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:14,254 INFO Processing question 12
2025-12-14 19:28:14,254 INFO Processing question 12
2025-12-14 19:28:14,254 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:14,254 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:14,559 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:14,560 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcEN6sW2WxC6iZRBWG'}
2025-12-14 19:28:14,560 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcEN6sW2WxC6iZRBWG'}
2025-12-14 19:28:14,845 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcEN6sW2WxC6iZRBWG'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:14,845 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcEN6sW2WxC6iZRBWG'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:14,847 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:14,847 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:14,848 INFO Processing question 13
2025-12-14 19:28:14,848 INFO Processing question 13
2025-12-14 19:28:14,849 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:14,849 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:15,110 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:15,111 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcGzMiFAdbTX6wM3jK'}
2025-12-14 19:28:15,111 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcGzMiFAdbTX6wM3jK'}
2025-12-14 19:28:15,386 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcGzMiFAdbTX6wM3jK'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:15,386 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcGzMiFAdbTX6wM3jK'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:15,389 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:15,389 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:15,390 INFO Processing question 14
2025-12-14 19:28:15,390 INFO Processing question 14
2025-12-14 19:28:15,391 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:15,391 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:15,739 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:15,741 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcKTSHAJD1DaXKFyTL'}
2025-12-14 19:28:15,741 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcKTSHAJD1DaXKFyTL'}
2025-12-14 19:28:16,059 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcKTSHAJD1DaXKFyTL'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:16,059 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcKTSHAJD1DaXKFyTL'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:16,060 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:16,060 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:16,061 INFO Processing question 15
2025-12-14 19:28:16,061 INFO Processing question 15
2025-12-14 19:28:16,061 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:16,061 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:28:16,327 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:28:16,327 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcN5wTBnsb1HyLU4Hb'}
2025-12-14 19:28:16,327 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcN5wTBnsb1HyLU4Hb'}
2025-12-14 19:28:16,594 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcN5wTBnsb1HyLU4Hb'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:16,594 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gcN5wTBnsb1HyLU4Hb'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:28:16,597 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:16,597 INFO No LLM provider available; returning placeholder
2025-12-14 19:28:16,600 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:28:16,600 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:28:16,600 INFO Report generation finished: ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:29:39,076 INFO Received form responses; launching background generation
2025-12-14 19:29:39,078 INFO Background report generation started
2025-12-14 19:29:39,081 INFO 127.0.0.1 - - [14/Dec/2025 19:29:39] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:29:39,081 INFO Starting report generation
2025-12-14 19:29:39,081 INFO Starting report generation
2025-12-14 19:29:39,082 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:29:39,082 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:29:39,083 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    return 'LLM unavailable or failed; no analysis generated.'
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:29:39,083 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    return 'LLM unavailable or failed; no analysis generated.'
    ^^^^^^^^^^^^
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:29:39,083 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:29:39,083 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:29:39,084 INFO Processing question 1
2025-12-14 19:29:39,084 INFO Processing question 1
2025-12-14 19:29:39,084 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:39,084 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:39,424 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:39,425 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giVAWDFYKMDbowPR5a'}
2025-12-14 19:29:39,425 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giVAWDFYKMDbowPR5a'}
2025-12-14 19:29:39,743 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giVAWDFYKMDbowPR5a'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:39,743 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giVAWDFYKMDbowPR5a'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:39,748 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:39,748 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:39,750 INFO Processing question 2
2025-12-14 19:29:39,750 INFO Processing question 2
2025-12-14 19:29:39,751 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:39,751 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:40,015 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:40,015 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giY29sveQkT3ddPzn8'}
2025-12-14 19:29:40,015 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giY29sveQkT3ddPzn8'}
2025-12-14 19:29:40,307 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giY29sveQkT3ddPzn8'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:40,307 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giY29sveQkT3ddPzn8'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:40,312 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:40,312 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:40,314 INFO Processing question 3
2025-12-14 19:29:40,314 INFO Processing question 3
2025-12-14 19:29:40,315 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:40,315 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:40,791 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:40,792 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gib9v67vQySnbqUC6S'}
2025-12-14 19:29:40,792 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gib9v67vQySnbqUC6S'}
2025-12-14 19:29:41,098 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gib9v67vQySnbqUC6S'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:41,098 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gib9v67vQySnbqUC6S'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:41,103 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:41,103 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:41,105 INFO Processing question 4
2025-12-14 19:29:41,105 INFO Processing question 4
2025-12-14 19:29:41,106 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:41,106 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:41,399 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:41,400 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gidqQ5Qc9rms14B5YE'}
2025-12-14 19:29:41,400 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gidqQ5Qc9rms14B5YE'}
2025-12-14 19:29:41,885 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gidqQ5Qc9rms14B5YE'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:41,885 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gidqQ5Qc9rms14B5YE'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:41,890 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:41,890 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:41,893 INFO Processing question 5
2025-12-14 19:29:41,893 INFO Processing question 5
2025-12-14 19:29:41,894 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:41,894 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:42,210 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:42,211 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gihEJ4xCvjyyaVgbwL'}
2025-12-14 19:29:42,211 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gihEJ4xCvjyyaVgbwL'}
2025-12-14 19:29:42,633 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gihEJ4xCvjyyaVgbwL'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:42,633 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gihEJ4xCvjyyaVgbwL'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:42,635 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:42,635 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:42,636 INFO Processing question 6
2025-12-14 19:29:42,636 INFO Processing question 6
2025-12-14 19:29:42,636 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:42,636 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:43,237 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:43,238 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gimeCaGEzjvT5JiiN9'}
2025-12-14 19:29:43,238 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gimeCaGEzjvT5JiiN9'}
2025-12-14 19:29:43,989 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gimeCaGEzjvT5JiiN9'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:43,989 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gimeCaGEzjvT5JiiN9'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:44,014 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:44,014 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:44,015 INFO Processing question 7
2025-12-14 19:29:44,015 INFO Processing question 7
2025-12-14 19:29:44,016 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:44,016 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:44,296 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:44,297 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7girGG5UDVbh3Aj8KZC'}
2025-12-14 19:29:44,297 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7girGG5UDVbh3Aj8KZC'}
2025-12-14 19:29:44,566 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7girGG5UDVbh3Aj8KZC'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:44,566 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7girGG5UDVbh3Aj8KZC'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:44,571 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:44,571 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:44,573 INFO Processing question 8
2025-12-14 19:29:44,573 INFO Processing question 8
2025-12-14 19:29:44,574 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:44,574 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:44,929 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:44,930 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gituWkumMcfDi5WXNR'}
2025-12-14 19:29:44,930 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gituWkumMcfDi5WXNR'}
2025-12-14 19:29:45,254 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gituWkumMcfDi5WXNR'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:45,254 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gituWkumMcfDi5WXNR'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:45,256 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:45,256 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:45,258 INFO Processing question 9
2025-12-14 19:29:45,258 INFO Processing question 9
2025-12-14 19:29:45,259 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:45,259 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:45,629 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:45,630 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giwmQTAVCPy46hiiEe'}
2025-12-14 19:29:45,630 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giwmQTAVCPy46hiiEe'}
2025-12-14 19:29:45,969 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giwmQTAVCPy46hiiEe'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:45,969 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7giwmQTAVCPy46hiiEe'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:45,973 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:45,973 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:45,975 INFO Processing question 10
2025-12-14 19:29:45,975 INFO Processing question 10
2025-12-14 19:29:45,976 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:45,976 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:46,272 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:46,273 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gizcopYzYNQNsKzkjc'}
2025-12-14 19:29:46,273 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gizcopYzYNQNsKzkjc'}
2025-12-14 19:29:46,591 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gizcopYzYNQNsKzkjc'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:46,591 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gizcopYzYNQNsKzkjc'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:46,595 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:46,595 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:46,597 INFO Processing question 11
2025-12-14 19:29:46,597 INFO Processing question 11
2025-12-14 19:29:46,598 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:46,598 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:46,968 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:46,990 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj3SxkgYHsznD6n25h'}
2025-12-14 19:29:46,990 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj3SxkgYHsznD6n25h'}
2025-12-14 19:29:47,299 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj3SxkgYHsznD6n25h'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:47,299 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj3SxkgYHsznD6n25h'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:47,304 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:47,304 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:47,307 INFO Processing question 12
2025-12-14 19:29:47,307 INFO Processing question 12
2025-12-14 19:29:47,307 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:47,307 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:47,590 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:47,592 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj6MLmQCs2ptnUjbtr'}
2025-12-14 19:29:47,592 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj6MLmQCs2ptnUjbtr'}
2025-12-14 19:29:47,905 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj6MLmQCs2ptnUjbtr'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:47,905 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj6MLmQCs2ptnUjbtr'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:47,908 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:47,908 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:47,912 INFO Processing question 13
2025-12-14 19:29:47,912 INFO Processing question 13
2025-12-14 19:29:47,913 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:47,913 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:48,193 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:48,195 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj8tPPGYatVutx8rae'}
2025-12-14 19:29:48,195 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj8tPPGYatVutx8rae'}
2025-12-14 19:29:48,454 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj8tPPGYatVutx8rae'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:48,454 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gj8tPPGYatVutx8rae'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:48,459 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:48,459 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:48,461 INFO Processing question 14
2025-12-14 19:29:48,461 INFO Processing question 14
2025-12-14 19:29:48,462 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:48,462 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:48,767 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:48,768 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gjBKz25HP8gtyViC1A'}
2025-12-14 19:29:48,768 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gjBKz25HP8gtyViC1A'}
2025-12-14 19:29:49,039 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gjBKz25HP8gtyViC1A'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:49,039 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gjBKz25HP8gtyViC1A'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:49,043 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:49,043 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:49,045 INFO Processing question 15
2025-12-14 19:29:49,045 INFO Processing question 15
2025-12-14 19:29:49,046 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:49,046 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:29:49,331 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:29:49,332 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gjDmpftSWudDwdzDhW'}
2025-12-14 19:29:49,332 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gjDmpftSWudDwdzDhW'}
2025-12-14 19:29:49,646 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gjDmpftSWudDwdzDhW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:49,646 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gjDmpftSWudDwdzDhW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    return text
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:29:49,650 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:49,650 INFO No LLM provider available; returning placeholder
2025-12-14 19:29:49,653 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:29:49,653 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:29:49,653 INFO Report generation finished: ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:30:09,157 INFO Received form responses; launching background generation
2025-12-14 19:30:09,158 INFO Background report generation started
2025-12-14 19:30:09,158 INFO 127.0.0.1 - - [14/Dec/2025 19:30:09] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:30:09,158 INFO Starting report generation
2025-12-14 19:30:09,158 INFO Starting report generation
2025-12-14 19:30:09,159 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:30:09,159 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:30:09,159 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    return text
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:30:09,159 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    return text
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:30:09,160 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:30:09,160 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:30:09,160 INFO Processing question 1
2025-12-14 19:30:09,160 INFO Processing question 1
2025-12-14 19:30:09,160 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:09,160 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:09,620 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:09,622 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkiU1VMKHN5b7jTAQi'}
2025-12-14 19:30:09,622 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkiU1VMKHN5b7jTAQi'}
2025-12-14 19:30:10,158 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkiU1VMKHN5b7jTAQi'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:10,158 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkiU1VMKHN5b7jTAQi'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:10,160 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:10,160 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:10,161 INFO Processing question 2
2025-12-14 19:30:10,161 INFO Processing question 2
2025-12-14 19:30:10,162 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:10,162 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:10,401 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:10,402 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkmuPPzwUGjKtcp7k5'}
2025-12-14 19:30:10,402 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkmuPPzwUGjKtcp7k5'}
2025-12-14 19:30:10,705 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkmuPPzwUGjKtcp7k5'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:10,705 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkmuPPzwUGjKtcp7k5'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:10,709 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:10,709 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:10,712 INFO Processing question 3
2025-12-14 19:30:10,712 INFO Processing question 3
2025-12-14 19:30:10,712 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:10,712 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:10,980 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:10,981 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkpPx5x3ER3D2mjbae'}
2025-12-14 19:30:10,981 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkpPx5x3ER3D2mjbae'}
2025-12-14 19:30:11,268 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkpPx5x3ER3D2mjbae'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:11,268 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkpPx5x3ER3D2mjbae'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:11,271 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:11,271 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:11,274 INFO Processing question 4
2025-12-14 19:30:11,274 INFO Processing question 4
2025-12-14 19:30:11,274 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:11,274 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:11,589 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:11,590 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkrvkbZ8AqYa6Fq6sg'}
2025-12-14 19:30:11,590 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkrvkbZ8AqYa6Fq6sg'}
2025-12-14 19:30:11,867 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkrvkbZ8AqYa6Fq6sg'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:11,867 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkrvkbZ8AqYa6Fq6sg'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:11,870 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:11,870 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:11,872 INFO Processing question 5
2025-12-14 19:30:11,872 INFO Processing question 5
2025-12-14 19:30:11,872 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:11,872 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:12,159 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:12,160 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkuMrP24c8dNYAcYYH'}
2025-12-14 19:30:12,160 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkuMrP24c8dNYAcYYH'}
2025-12-14 19:30:12,471 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkuMrP24c8dNYAcYYH'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:12,471 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkuMrP24c8dNYAcYYH'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:12,475 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:12,475 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:12,477 INFO Processing question 6
2025-12-14 19:30:12,477 INFO Processing question 6
2025-12-14 19:30:12,477 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:12,477 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:13,112 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:13,114 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkyTuoripDwRxDUunK'}
2025-12-14 19:30:13,114 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkyTuoripDwRxDUunK'}
2025-12-14 19:30:13,420 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkyTuoripDwRxDUunK'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:13,420 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gkyTuoripDwRxDUunK'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:13,424 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:13,424 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:13,426 INFO Processing question 7
2025-12-14 19:30:13,426 INFO Processing question 7
2025-12-14 19:30:13,426 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:13,426 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:13,747 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:13,748 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm1yDdoBPtbKkmwNLn'}
2025-12-14 19:30:13,748 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm1yDdoBPtbKkmwNLn'}
2025-12-14 19:30:14,455 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm1yDdoBPtbKkmwNLn'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:14,455 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm1yDdoBPtbKkmwNLn'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:14,461 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:14,461 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:14,463 INFO Processing question 8
2025-12-14 19:30:14,463 INFO Processing question 8
2025-12-14 19:30:14,464 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:14,464 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:14,752 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:14,753 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm6R7WydgkCuASkxFa'}
2025-12-14 19:30:14,753 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm6R7WydgkCuASkxFa'}
2025-12-14 19:30:15,053 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm6R7WydgkCuASkxFa'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:15,053 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm6R7WydgkCuASkxFa'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:15,058 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:15,058 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:15,060 INFO Processing question 9
2025-12-14 19:30:15,060 INFO Processing question 9
2025-12-14 19:30:15,060 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:15,060 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:15,352 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:15,353 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm947frWMYvFG3ndyx'}
2025-12-14 19:30:15,353 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm947frWMYvFG3ndyx'}
2025-12-14 19:30:15,665 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm947frWMYvFG3ndyx'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:15,665 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gm947frWMYvFG3ndyx'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:15,702 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:15,702 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:15,703 INFO Processing question 10
2025-12-14 19:30:15,703 INFO Processing question 10
2025-12-14 19:30:15,703 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:15,703 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:15,915 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:15,917 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmBWTHdAajRbyr3Rki'}
2025-12-14 19:30:15,917 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmBWTHdAajRbyr3Rki'}
2025-12-14 19:30:16,193 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmBWTHdAajRbyr3Rki'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:16,193 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmBWTHdAajRbyr3Rki'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:16,198 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:16,198 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:16,199 INFO Processing question 11
2025-12-14 19:30:16,199 INFO Processing question 11
2025-12-14 19:30:16,200 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:16,200 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:16,491 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:16,492 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmDs5w7bec28P8i3am'}
2025-12-14 19:30:16,492 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmDs5w7bec28P8i3am'}
2025-12-14 19:30:16,790 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmDs5w7bec28P8i3am'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:16,790 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmDs5w7bec28P8i3am'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:16,795 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:16,795 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:16,797 INFO Processing question 12
2025-12-14 19:30:16,797 INFO Processing question 12
2025-12-14 19:30:16,798 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:16,798 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:17,070 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:17,071 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmGKgESmJRuVjDtALf'}
2025-12-14 19:30:17,071 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmGKgESmJRuVjDtALf'}
2025-12-14 19:30:17,333 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmGKgESmJRuVjDtALf'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:17,333 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmGKgESmJRuVjDtALf'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:17,337 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:17,337 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:17,339 INFO Processing question 13
2025-12-14 19:30:17,339 INFO Processing question 13
2025-12-14 19:30:17,340 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:17,340 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:17,602 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:17,603 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmJfp2RsWXDKY5ANv4'}
2025-12-14 19:30:17,603 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmJfp2RsWXDKY5ANv4'}
2025-12-14 19:30:18,355 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmJfp2RsWXDKY5ANv4'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:18,355 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmJfp2RsWXDKY5ANv4'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:18,358 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:18,358 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:18,361 INFO Processing question 14
2025-12-14 19:30:18,361 INFO Processing question 14
2025-12-14 19:30:18,361 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:18,361 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:19,134 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:19,137 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmP1zreLCzyFud1gkC'}
2025-12-14 19:30:19,137 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmP1zreLCzyFud1gkC'}
2025-12-14 19:30:19,395 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmP1zreLCzyFud1gkC'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:19,395 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmP1zreLCzyFud1gkC'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:19,399 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:19,399 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:19,401 INFO Processing question 15
2025-12-14 19:30:19,401 INFO Processing question 15
2025-12-14 19:30:19,402 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:19,402 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:19,659 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:19,660 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmTUtcsoMFrefp5hxn'}
2025-12-14 19:30:19,660 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmTUtcsoMFrefp5hxn'}
2025-12-14 19:30:19,944 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmTUtcsoMFrefp5hxn'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:19,944 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gmTUtcsoMFrefp5hxn'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:19,949 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:19,949 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:19,951 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:30:19,951 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:30:19,951 INFO Report generation finished: ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:30:33,097 INFO Received form responses; launching background generation
2025-12-14 19:30:33,097 INFO Background report generation started
2025-12-14 19:30:33,100 INFO 127.0.0.1 - - [14/Dec/2025 19:30:33] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:30:33,100 INFO Starting report generation
2025-12-14 19:30:33,100 INFO Starting report generation
2025-12-14 19:30:33,101 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:30:33,101 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:30:33,101 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    import openai
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:30:33,101 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    import openai
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:30:33,102 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:30:33,102 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:30:33,102 INFO Processing question 1
2025-12-14 19:30:33,102 INFO Processing question 1
2025-12-14 19:30:33,102 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:33,102 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:33,372 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:33,373 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnU4PgrJD9VzsuvLZD'}
2025-12-14 19:30:33,373 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnU4PgrJD9VzsuvLZD'}
2025-12-14 19:30:33,693 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnU4PgrJD9VzsuvLZD'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:33,693 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnU4PgrJD9VzsuvLZD'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:33,698 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:33,698 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:33,700 INFO Processing question 2
2025-12-14 19:30:33,700 INFO Processing question 2
2025-12-14 19:30:33,701 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:33,701 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:33,991 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:33,992 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnWeAdwJ42PgHLChCM'}
2025-12-14 19:30:33,992 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnWeAdwJ42PgHLChCM'}
2025-12-14 19:30:34,302 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnWeAdwJ42PgHLChCM'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:34,302 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnWeAdwJ42PgHLChCM'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:34,307 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:34,307 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:34,309 INFO Processing question 3
2025-12-14 19:30:34,309 INFO Processing question 3
2025-12-14 19:30:34,309 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:34,309 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:34,617 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:34,618 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnZFSC3YgF3MuEvxyL'}
2025-12-14 19:30:34,618 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnZFSC3YgF3MuEvxyL'}
2025-12-14 19:30:34,870 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnZFSC3YgF3MuEvxyL'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:34,870 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnZFSC3YgF3MuEvxyL'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:34,874 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:34,874 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:34,877 INFO Processing question 4
2025-12-14 19:30:34,877 INFO Processing question 4
2025-12-14 19:30:34,878 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:34,878 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:35,473 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:35,474 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnbd4Utb52Ychdryxr'}
2025-12-14 19:30:35,474 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnbd4Utb52Ychdryxr'}
2025-12-14 19:30:35,729 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnbd4Utb52Ychdryxr'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:35,729 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnbd4Utb52Ychdryxr'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:35,734 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:35,734 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:35,737 INFO Processing question 5
2025-12-14 19:30:35,737 INFO Processing question 5
2025-12-14 19:30:35,738 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:35,738 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:36,014 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:36,015 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnfHaQTkmSkLthVZ7v'}
2025-12-14 19:30:36,015 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnfHaQTkmSkLthVZ7v'}
2025-12-14 19:30:36,277 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnfHaQTkmSkLthVZ7v'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:36,277 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnfHaQTkmSkLthVZ7v'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:36,279 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:36,279 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:36,281 INFO Processing question 6
2025-12-14 19:30:36,281 INFO Processing question 6
2025-12-14 19:30:36,281 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:36,281 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:36,592 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:36,593 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnhtb3jYorxKnPCmPZ'}
2025-12-14 19:30:36,593 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnhtb3jYorxKnPCmPZ'}
2025-12-14 19:30:37,274 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnhtb3jYorxKnPCmPZ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:37,274 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnhtb3jYorxKnPCmPZ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:37,279 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:37,279 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:37,282 INFO Processing question 7
2025-12-14 19:30:37,282 INFO Processing question 7
2025-12-14 19:30:37,282 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:37,282 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:37,567 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:37,567 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnn1dwhJQZXHuf8qFy'}
2025-12-14 19:30:37,567 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnn1dwhJQZXHuf8qFy'}
2025-12-14 19:30:37,852 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnn1dwhJQZXHuf8qFy'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:37,852 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnn1dwhJQZXHuf8qFy'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:37,856 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:37,856 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:37,859 INFO Processing question 8
2025-12-14 19:30:37,859 INFO Processing question 8
2025-12-14 19:30:37,860 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:37,860 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:38,174 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:38,175 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnpZgUo4WpTq4rhq8s'}
2025-12-14 19:30:38,175 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnpZgUo4WpTq4rhq8s'}
2025-12-14 19:30:38,481 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnpZgUo4WpTq4rhq8s'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:38,481 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnpZgUo4WpTq4rhq8s'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:38,485 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:38,485 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:38,487 INFO Processing question 9
2025-12-14 19:30:38,487 INFO Processing question 9
2025-12-14 19:30:38,487 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:38,487 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:38,777 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:38,778 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gns9x1qsb1U31P3viW'}
2025-12-14 19:30:38,778 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gns9x1qsb1U31P3viW'}
2025-12-14 19:30:39,554 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gns9x1qsb1U31P3viW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:39,554 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gns9x1qsb1U31P3viW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:39,558 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:39,558 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:39,560 INFO Processing question 10
2025-12-14 19:30:39,560 INFO Processing question 10
2025-12-14 19:30:39,561 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:39,561 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:39,863 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:39,864 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnwm28FgnXdP33MEJv'}
2025-12-14 19:30:39,864 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnwm28FgnXdP33MEJv'}
2025-12-14 19:30:40,144 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnwm28FgnXdP33MEJv'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:40,144 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnwm28FgnXdP33MEJv'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:40,148 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:40,148 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:40,150 INFO Processing question 11
2025-12-14 19:30:40,150 INFO Processing question 11
2025-12-14 19:30:40,151 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:40,151 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:40,414 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:40,415 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnzCrvrzpjjvHPcZ3z'}
2025-12-14 19:30:40,415 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnzCrvrzpjjvHPcZ3z'}
2025-12-14 19:30:40,670 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnzCrvrzpjjvHPcZ3z'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:40,670 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gnzCrvrzpjjvHPcZ3z'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:40,675 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:40,675 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:40,677 INFO Processing question 12
2025-12-14 19:30:40,677 INFO Processing question 12
2025-12-14 19:30:40,678 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:40,678 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:40,935 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:40,936 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go2QpDPWEY35d7JeMx'}
2025-12-14 19:30:40,936 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go2QpDPWEY35d7JeMx'}
2025-12-14 19:30:41,205 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go2QpDPWEY35d7JeMx'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:41,205 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go2QpDPWEY35d7JeMx'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:41,210 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:41,210 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:41,212 INFO Processing question 13
2025-12-14 19:30:41,212 INFO Processing question 13
2025-12-14 19:30:41,213 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:41,213 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:41,460 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:41,461 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go4hEug9BbhLUqY4ta'}
2025-12-14 19:30:41,461 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go4hEug9BbhLUqY4ta'}
2025-12-14 19:30:41,767 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go4hEug9BbhLUqY4ta'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:41,767 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go4hEug9BbhLUqY4ta'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:41,771 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:41,771 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:41,774 INFO Processing question 14
2025-12-14 19:30:41,774 INFO Processing question 14
2025-12-14 19:30:41,774 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:41,774 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:42,043 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:42,045 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go79pXAnQBEwbxoYWi'}
2025-12-14 19:30:42,045 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go79pXAnQBEwbxoYWi'}
2025-12-14 19:30:42,361 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go79pXAnQBEwbxoYWi'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:42,361 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go79pXAnQBEwbxoYWi'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:42,366 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:42,366 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:42,368 INFO Processing question 15
2025-12-14 19:30:42,368 INFO Processing question 15
2025-12-14 19:30:42,368 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:42,368 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:30:42,679 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:30:42,680 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go9nKtBcQqApzjZvyu'}
2025-12-14 19:30:42,680 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go9nKtBcQqApzjZvyu'}
2025-12-14 19:30:42,936 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go9nKtBcQqApzjZvyu'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:42,936 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7go9nKtBcQqApzjZvyu'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:30:42,940 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:42,940 INFO No LLM provider available; returning placeholder
2025-12-14 19:30:42,943 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:30:42,943 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:30:42,944 INFO Report generation finished: ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:31:01,497 INFO Received form responses; launching background generation
2025-12-14 19:31:01,497 INFO Background report generation started
2025-12-14 19:31:01,498 INFO 127.0.0.1 - - [14/Dec/2025 19:31:01] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:31:01,498 INFO Starting report generation
2025-12-14 19:31:01,498 INFO Starting report generation
2025-12-14 19:31:01,499 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:31:01,499 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:31:01,499 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    _save_cache(cache)
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:31:01,499 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    _save_cache(cache)
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:31:01,500 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:31:01,500 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:31:01,500 INFO Processing question 1
2025-12-14 19:31:01,500 INFO Processing question 1
2025-12-14 19:31:01,500 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:01,500 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:01,811 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:01,812 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpZeJSBRuP3wyeJ5vX'}
2025-12-14 19:31:01,812 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpZeJSBRuP3wyeJ5vX'}
2025-12-14 19:31:02,205 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpZeJSBRuP3wyeJ5vX'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:02,205 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpZeJSBRuP3wyeJ5vX'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:02,209 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:02,209 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:02,211 INFO Processing question 2
2025-12-14 19:31:02,211 INFO Processing question 2
2025-12-14 19:31:02,211 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:02,211 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:02,447 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:02,447 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpcQzH4LN91wBe9ZXf'}
2025-12-14 19:31:02,447 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpcQzH4LN91wBe9ZXf'}
2025-12-14 19:31:02,736 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpcQzH4LN91wBe9ZXf'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:02,736 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpcQzH4LN91wBe9ZXf'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:02,741 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:02,741 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:02,742 INFO Processing question 3
2025-12-14 19:31:02,742 INFO Processing question 3
2025-12-14 19:31:02,743 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:02,743 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:03,110 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:03,111 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gperqNi7CS9M1ZC6oa'}
2025-12-14 19:31:03,111 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gperqNi7CS9M1ZC6oa'}
2025-12-14 19:31:03,404 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gperqNi7CS9M1ZC6oa'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:03,404 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gperqNi7CS9M1ZC6oa'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:03,408 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:03,408 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:03,410 INFO Processing question 4
2025-12-14 19:31:03,410 INFO Processing question 4
2025-12-14 19:31:03,410 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:03,410 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:03,710 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:03,712 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gphgVomMWMPfJkLTa6'}
2025-12-14 19:31:03,712 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gphgVomMWMPfJkLTa6'}
2025-12-14 19:31:04,006 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gphgVomMWMPfJkLTa6'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:04,006 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gphgVomMWMPfJkLTa6'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:04,010 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:04,010 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:04,012 INFO Processing question 5
2025-12-14 19:31:04,012 INFO Processing question 5
2025-12-14 19:31:04,013 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:04,013 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:04,327 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:04,328 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpkG2Sg5QcQ437dJzZ'}
2025-12-14 19:31:04,328 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpkG2Sg5QcQ437dJzZ'}
2025-12-14 19:31:04,606 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpkG2Sg5QcQ437dJzZ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:04,606 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpkG2Sg5QcQ437dJzZ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:04,607 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:04,607 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:04,608 INFO Processing question 6
2025-12-14 19:31:04,608 INFO Processing question 6
2025-12-14 19:31:04,608 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:04,608 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:05,773 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:05,776 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpqnQY4tmBZ4L2eaCQ'}
2025-12-14 19:31:05,776 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpqnQY4tmBZ4L2eaCQ'}
2025-12-14 19:31:06,081 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpqnQY4tmBZ4L2eaCQ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:06,081 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpqnQY4tmBZ4L2eaCQ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:06,087 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:06,087 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:06,089 INFO Processing question 7
2025-12-14 19:31:06,089 INFO Processing question 7
2025-12-14 19:31:06,090 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:06,090 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:06,381 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:06,382 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpuCYCqXmw4htp3FsD'}
2025-12-14 19:31:06,382 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpuCYCqXmw4htp3FsD'}
2025-12-14 19:31:06,662 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpuCYCqXmw4htp3FsD'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:06,662 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpuCYCqXmw4htp3FsD'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:06,666 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:06,666 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:06,669 INFO Processing question 8
2025-12-14 19:31:06,669 INFO Processing question 8
2025-12-14 19:31:06,670 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:06,670 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:06,935 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:06,936 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpwYgPtR5yc7RYsthd'}
2025-12-14 19:31:06,936 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpwYgPtR5yc7RYsthd'}
2025-12-14 19:31:07,221 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpwYgPtR5yc7RYsthd'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:07,221 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpwYgPtR5yc7RYsthd'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:07,226 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:07,226 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:07,228 INFO Processing question 9
2025-12-14 19:31:07,228 INFO Processing question 9
2025-12-14 19:31:07,229 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:07,229 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:07,496 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:07,496 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpyxXrGadmwbj6qnxz'}
2025-12-14 19:31:07,496 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpyxXrGadmwbj6qnxz'}
2025-12-14 19:31:07,775 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpyxXrGadmwbj6qnxz'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:07,775 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gpyxXrGadmwbj6qnxz'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:07,780 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:07,780 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:07,783 INFO Processing question 10
2025-12-14 19:31:07,783 INFO Processing question 10
2025-12-14 19:31:07,783 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:07,783 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:08,050 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:08,051 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq2MtqNQ5MWjgxr9EF'}
2025-12-14 19:31:08,051 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq2MtqNQ5MWjgxr9EF'}
2025-12-14 19:31:08,327 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq2MtqNQ5MWjgxr9EF'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:08,327 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq2MtqNQ5MWjgxr9EF'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:08,331 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:08,331 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:08,334 INFO Processing question 11
2025-12-14 19:31:08,334 INFO Processing question 11
2025-12-14 19:31:08,334 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:08,334 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:08,626 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:08,628 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq4m1ZmWY6gGjzNfMZ'}
2025-12-14 19:31:08,628 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq4m1ZmWY6gGjzNfMZ'}
2025-12-14 19:31:08,939 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq4m1ZmWY6gGjzNfMZ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:08,939 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq4m1ZmWY6gGjzNfMZ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:08,944 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:08,944 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:08,947 INFO Processing question 12
2025-12-14 19:31:08,947 INFO Processing question 12
2025-12-14 19:31:08,947 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:08,947 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:09,273 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:09,274 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq7Rzta9m6EgZQxTAq'}
2025-12-14 19:31:09,274 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq7Rzta9m6EgZQxTAq'}
2025-12-14 19:31:09,554 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq7Rzta9m6EgZQxTAq'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:09,554 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq7Rzta9m6EgZQxTAq'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:09,557 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:09,557 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:09,559 INFO Processing question 13
2025-12-14 19:31:09,559 INFO Processing question 13
2025-12-14 19:31:09,560 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:09,560 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:09,830 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:09,831 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq9zY3Xs8j51LUCifT'}
2025-12-14 19:31:09,831 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq9zY3Xs8j51LUCifT'}
2025-12-14 19:31:10,081 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq9zY3Xs8j51LUCifT'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:10,081 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gq9zY3Xs8j51LUCifT'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:10,086 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:10,086 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:10,088 INFO Processing question 14
2025-12-14 19:31:10,088 INFO Processing question 14
2025-12-14 19:31:10,089 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:10,089 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:10,379 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:10,380 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gqCLRWCrDVVe1Q34Yd'}
2025-12-14 19:31:10,380 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gqCLRWCrDVVe1Q34Yd'}
2025-12-14 19:31:10,627 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gqCLRWCrDVVe1Q34Yd'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:10,627 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gqCLRWCrDVVe1Q34Yd'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:10,632 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:10,632 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:10,633 INFO Processing question 15
2025-12-14 19:31:10,633 INFO Processing question 15
2025-12-14 19:31:10,634 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:10,634 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:31:10,885 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:31:10,886 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gqETvDLiuG5863f6Xp'}
2025-12-14 19:31:10,886 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gqETvDLiuG5863f6Xp'}
2025-12-14 19:31:11,160 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gqETvDLiuG5863f6Xp'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:11,160 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gqETvDLiuG5863f6Xp'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:31:11,165 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:11,165 INFO No LLM provider available; returning placeholder
2025-12-14 19:31:11,167 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:31:11,167 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:31:11,168 INFO Report generation finished: ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:32:21,985 INFO Received form responses; launching background generation
2025-12-14 19:32:21,986 INFO Background report generation started
2025-12-14 19:32:21,987 INFO 127.0.0.1 - - [14/Dec/2025 19:32:21] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:32:21,987 INFO Starting report generation
2025-12-14 19:32:21,987 INFO Starting report generation
2025-12-14 19:32:21,989 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:32:21,989 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:32:21,989 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    cache[key] = {'response': text, 'ts': time.time(), 'provider': 'anthropic-http'}
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:32:21,989 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 210, in generate_report
    cache[key] = {'response': text, 'ts': time.time(), 'provider': 'anthropic-http'}
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:32:21,990 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:32:21,990 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:32:21,990 INFO Processing question 1
2025-12-14 19:32:21,990 INFO Processing question 1
2025-12-14 19:32:21,990 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:21,990 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:22,302 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:22,303 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvVmZJDua5eush9Vzi'}
2025-12-14 19:32:22,303 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvVmZJDua5eush9Vzi'}
2025-12-14 19:32:22,578 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvVmZJDua5eush9Vzi'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:22,578 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvVmZJDua5eush9Vzi'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:22,583 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:22,583 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:22,585 INFO Processing question 2
2025-12-14 19:32:22,585 INFO Processing question 2
2025-12-14 19:32:22,586 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:22,586 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:22,888 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:22,889 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvYCQWyXwAiotuQouS'}
2025-12-14 19:32:22,889 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvYCQWyXwAiotuQouS'}
2025-12-14 19:32:23,156 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvYCQWyXwAiotuQouS'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:23,156 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvYCQWyXwAiotuQouS'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:23,158 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:23,158 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:23,160 INFO Processing question 3
2025-12-14 19:32:23,160 INFO Processing question 3
2025-12-14 19:32:23,161 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:23,161 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:23,608 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:23,658 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvaquAvhPewjBtUFdL'}
2025-12-14 19:32:23,658 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvaquAvhPewjBtUFdL'}
2025-12-14 19:32:23,940 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvaquAvhPewjBtUFdL'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:23,940 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvaquAvhPewjBtUFdL'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:23,945 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:23,945 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:23,947 INFO Processing question 4
2025-12-14 19:32:23,947 INFO Processing question 4
2025-12-14 19:32:23,948 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:23,948 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:24,222 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:24,223 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gve1Q74QF5qQYBgwBG'}
2025-12-14 19:32:24,223 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gve1Q74QF5qQYBgwBG'}
2025-12-14 19:32:24,477 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gve1Q74QF5qQYBgwBG'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:24,477 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gve1Q74QF5qQYBgwBG'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:24,508 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:24,508 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:24,509 INFO Processing question 5
2025-12-14 19:32:24,509 INFO Processing question 5
2025-12-14 19:32:24,509 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:24,509 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:25,080 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:25,080 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvgUycAPJmowPwcLQu'}
2025-12-14 19:32:25,080 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvgUycAPJmowPwcLQu'}
2025-12-14 19:32:25,719 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvgUycAPJmowPwcLQu'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:25,719 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvgUycAPJmowPwcLQu'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:25,724 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:25,724 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:25,726 INFO Processing question 6
2025-12-14 19:32:25,726 INFO Processing question 6
2025-12-14 19:32:25,726 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:25,726 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:27,367 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:27,370 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvqNmd4U5F4QRZTVxG'}
2025-12-14 19:32:27,370 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvqNmd4U5F4QRZTVxG'}
2025-12-14 19:32:27,640 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvqNmd4U5F4QRZTVxG'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:27,640 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvqNmd4U5F4QRZTVxG'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:27,645 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:27,645 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:27,647 INFO Processing question 7
2025-12-14 19:32:27,647 INFO Processing question 7
2025-12-14 19:32:27,648 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:27,648 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:28,034 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:28,034 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvuxbZBSAYFZGPDYGY'}
2025-12-14 19:32:28,034 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvuxbZBSAYFZGPDYGY'}
2025-12-14 19:32:28,264 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvuxbZBSAYFZGPDYGY'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:28,264 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvuxbZBSAYFZGPDYGY'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:28,268 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:28,268 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:28,270 INFO Processing question 8
2025-12-14 19:32:28,270 INFO Processing question 8
2025-12-14 19:32:28,271 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:28,271 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:28,564 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:28,565 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvxaMtKCxwqomDEmiQ'}
2025-12-14 19:32:28,565 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvxaMtKCxwqomDEmiQ'}
2025-12-14 19:32:28,912 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvxaMtKCxwqomDEmiQ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:28,912 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gvxaMtKCxwqomDEmiQ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:28,916 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:28,916 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:28,918 INFO Processing question 9
2025-12-14 19:32:28,918 INFO Processing question 9
2025-12-14 19:32:28,919 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:28,919 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:29,204 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:29,205 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gw1M3hbBEG49fZj5wX'}
2025-12-14 19:32:29,205 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gw1M3hbBEG49fZj5wX'}
2025-12-14 19:32:29,515 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gw1M3hbBEG49fZj5wX'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:29,515 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gw1M3hbBEG49fZj5wX'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:29,520 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:29,520 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:29,523 INFO Processing question 10
2025-12-14 19:32:29,523 INFO Processing question 10
2025-12-14 19:32:29,523 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:29,523 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:30,541 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:30,543 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gw54HawqhL5Zer1yRU'}
2025-12-14 19:32:30,543 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gw54HawqhL5Zer1yRU'}
2025-12-14 19:32:31,807 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gw54HawqhL5Zer1yRU'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:31,807 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gw54HawqhL5Zer1yRU'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:31,813 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:31,813 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:31,815 INFO Processing question 11
2025-12-14 19:32:31,815 INFO Processing question 11
2025-12-14 19:32:31,816 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:31,816 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:32,172 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:32,173 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwE1o9W9BddDZeYfoy'}
2025-12-14 19:32:32,173 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwE1o9W9BddDZeYfoy'}
2025-12-14 19:32:32,507 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwE1o9W9BddDZeYfoy'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:32,507 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwE1o9W9BddDZeYfoy'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:32,508 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:32,508 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:32,509 INFO Processing question 12
2025-12-14 19:32:32,509 INFO Processing question 12
2025-12-14 19:32:32,510 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:32,510 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:32,952 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:32,953 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwGi1ykXgANDJamrEB'}
2025-12-14 19:32:32,953 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwGi1ykXgANDJamrEB'}
2025-12-14 19:32:33,259 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwGi1ykXgANDJamrEB'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:33,259 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwGi1ykXgANDJamrEB'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:33,260 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:33,260 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:33,261 INFO Processing question 13
2025-12-14 19:32:33,261 INFO Processing question 13
2025-12-14 19:32:33,262 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:33,262 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:33,504 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:33,505 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwKkaZdfAy9eXAXBcv'}
2025-12-14 19:32:33,505 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwKkaZdfAy9eXAXBcv'}
2025-12-14 19:32:33,772 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwKkaZdfAy9eXAXBcv'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:33,772 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwKkaZdfAy9eXAXBcv'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:33,777 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:33,777 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:33,780 INFO Processing question 14
2025-12-14 19:32:33,780 INFO Processing question 14
2025-12-14 19:32:33,780 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:33,780 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:34,156 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:34,165 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwN6DoF5QZQNrdK4VS'}
2025-12-14 19:32:34,165 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwN6DoF5QZQNrdK4VS'}
2025-12-14 19:32:34,426 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwN6DoF5QZQNrdK4VS'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:34,426 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwN6DoF5QZQNrdK4VS'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:34,429 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:34,429 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:34,431 INFO Processing question 15
2025-12-14 19:32:34,431 INFO Processing question 15
2025-12-14 19:32:34,431 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:34,431 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:32:34,775 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 400 Bad Request"
2025-12-14 19:32:34,776 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwQoBwtouV9N5KuqtP'}
2025-12-14 19:32:34,776 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwQoBwtouV9N5KuqtP'}
2025-12-14 19:32:35,214 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwQoBwtouV9N5KuqtP'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:35,214 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 149, in _call_llm
    # incoming `prompt` is a plain string, wrap it in the
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    # required format: (optional system) + "\n\nHuman: ...\n\nAssistant:"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    anth_prompt = prompt
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.BadRequestError: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'prompt must start with "\n\nHuman:" turn after an optional system prompt'}, 'request_id': 'req_011CW7gwQoBwtouV9N5KuqtP'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 168, in _call_llm
    logger.exception('Failed to format prompt for Anthropic; using original prompt')
    ^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:32:35,215 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:35,215 INFO No LLM provider available; returning placeholder
2025-12-14 19:32:35,216 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:32:35,216 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:32:35,216 INFO Report generation finished: ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:35:55,151 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 19:35:55,152 INFO [33mPress CTRL+C to quit[0m
2025-12-14 19:37:53,133 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 19:37:53,133 INFO [33mPress CTRL+C to quit[0m
2025-12-14 19:37:53,753 INFO Received form responses; launching background generation
2025-12-14 19:37:53,753 INFO Background report generation started
2025-12-14 19:37:53,756 INFO 127.0.0.1 - - [14/Dec/2025 19:37:53] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:37:53,763 INFO Starting report generation
2025-12-14 19:37:53,763 INFO Starting report generation
2025-12-14 19:37:53,763 WARNING Temporary hardcoded ANTHROPIC_API_KEY is set from llama_rag.py — remove after testing
2025-12-14 19:37:53,763 WARNING Temporary hardcoded ANTHROPIC_API_KEY is set from llama_rag.py — remove after testing
2025-12-14 19:37:53,764 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:37:53,764 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:37:53,765 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 251, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:37:53,765 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 251, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:37:53,765 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:37:53,765 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:37:53,766 INFO Processing question 1
2025-12-14 19:37:53,766 INFO Processing question 1
2025-12-14 19:37:53,766 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:53,766 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:54,034 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:54,034 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:54,373 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:37:54,374 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hLyZZJm9s97bYPzWr5'}
2025-12-14 19:37:54,374 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hLyZZJm9s97bYPzWr5'}
2025-12-14 19:37:54,419 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:54,419 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:54,677 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hLyZZJm9s97bYPzWr5'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:54,677 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hLyZZJm9s97bYPzWr5'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:54,682 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:54,682 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:54,684 INFO Processing question 2
2025-12-14 19:37:54,684 INFO Processing question 2
2025-12-14 19:37:54,685 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:54,685 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:54,714 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:54,714 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:54,991 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:37:54,994 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM22PubVHjxqQJP2kJ'}
2025-12-14 19:37:54,994 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM22PubVHjxqQJP2kJ'}
2025-12-14 19:37:54,995 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 2\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:54,995 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 2\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:55,312 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM22PubVHjxqQJP2kJ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:55,312 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM22PubVHjxqQJP2kJ'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:55,315 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:55,315 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:55,318 INFO Processing question 3
2025-12-14 19:37:55,318 INFO Processing question 3
2025-12-14 19:37:55,318 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:55,318 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:55,347 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:55,347 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:55,606 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:37:55,607 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM4kr8fhJnZXGsBBvB'}
2025-12-14 19:37:55,607 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM4kr8fhJnZXGsBBvB'}
2025-12-14 19:37:55,610 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 3\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:55,610 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 3\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:55,915 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM4kr8fhJnZXGsBBvB'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:55,915 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM4kr8fhJnZXGsBBvB'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:55,917 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:55,917 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:55,918 INFO Processing question 4
2025-12-14 19:37:55,918 INFO Processing question 4
2025-12-14 19:37:55,918 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:55,918 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:55,938 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:55,938 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:56,212 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:37:56,212 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM7TKVwLu3SEA2psYW'}
2025-12-14 19:37:56,212 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM7TKVwLu3SEA2psYW'}
2025-12-14 19:37:56,214 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 4\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:56,214 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 4\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:56,655 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM7TKVwLu3SEA2psYW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:56,655 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hM7TKVwLu3SEA2psYW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:56,660 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:56,660 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:56,663 INFO Processing question 5
2025-12-14 19:37:56,663 INFO Processing question 5
2025-12-14 19:37:56,664 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:56,664 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:56,691 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:56,691 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:57,630 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:37:57,632 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMDJ47j52oiLYhXBk5'}
2025-12-14 19:37:57,632 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMDJ47j52oiLYhXBk5'}
2025-12-14 19:37:57,635 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:57,635 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:58,005 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMDJ47j52oiLYhXBk5'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:58,005 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMDJ47j52oiLYhXBk5'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:58,010 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:58,010 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:58,013 INFO Processing question 6
2025-12-14 19:37:58,013 INFO Processing question 6
2025-12-14 19:37:58,013 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:58,013 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:58,067 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:58,067 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:58,342 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:37:58,343 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMGZkrb6bJauD47mTq'}
2025-12-14 19:37:58,343 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMGZkrb6bJauD47mTq'}
2025-12-14 19:37:58,346 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 6\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:58,346 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 6\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:58,625 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMGZkrb6bJauD47mTq'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:58,625 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMGZkrb6bJauD47mTq'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:58,627 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:58,627 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:58,629 INFO Processing question 7
2025-12-14 19:37:58,629 INFO Processing question 7
2025-12-14 19:37:58,629 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:58,629 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:58,649 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:58,649 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:58,901 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:37:58,902 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMJqvp15P2Zw9Hkjmd'}
2025-12-14 19:37:58,902 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMJqvp15P2Zw9Hkjmd'}
2025-12-14 19:37:58,905 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 7\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:58,905 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 7\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:59,171 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMJqvp15P2Zw9Hkjmd'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:59,171 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMJqvp15P2Zw9Hkjmd'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:59,175 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:59,175 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:59,177 INFO Processing question 8
2025-12-14 19:37:59,177 INFO Processing question 8
2025-12-14 19:37:59,178 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:59,178 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:59,209 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:59,209 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:59,455 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:37:59,456 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMMFnQeQAkSvEwr6QW'}
2025-12-14 19:37:59,456 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMMFnQeQAkSvEwr6QW'}
2025-12-14 19:37:59,459 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:59,459 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:59,712 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMMFnQeQAkSvEwr6QW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:59,712 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMMFnQeQAkSvEwr6QW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:37:59,716 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:59,716 INFO No LLM provider available; returning placeholder
2025-12-14 19:37:59,718 INFO Processing question 9
2025-12-14 19:37:59,718 INFO Processing question 9
2025-12-14 19:37:59,718 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:59,718 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:37:59,741 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:59,741 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:37:59,975 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:37:59,976 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMPVyKSRNhdrn3uZHM'}
2025-12-14 19:37:59,976 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMPVyKSRNhdrn3uZHM'}
2025-12-14 19:37:59,978 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 9\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:37:59,978 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 9\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:00,249 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMPVyKSRNhdrn3uZHM'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:00,249 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMPVyKSRNhdrn3uZHM'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:00,297 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:00,297 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:00,298 INFO Processing question 10
2025-12-14 19:38:00,298 INFO Processing question 10
2025-12-14 19:38:00,298 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:00,298 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:00,314 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:00,314 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:00,633 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:38:00,642 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMSAhvB6KyDqzDWrdd'}
2025-12-14 19:38:00,642 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMSAhvB6KyDqzDWrdd'}
2025-12-14 19:38:00,646 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 10\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:00,646 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 10\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:00,930 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMSAhvB6KyDqzDWrdd'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:00,930 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMSAhvB6KyDqzDWrdd'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:00,933 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:00,933 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:00,935 INFO Processing question 11
2025-12-14 19:38:00,935 INFO Processing question 11
2025-12-14 19:38:00,935 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:00,935 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:00,958 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:00,958 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:01,246 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:38:01,248 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMUven7Z7TevPYxPdq'}
2025-12-14 19:38:01,248 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMUven7Z7TevPYxPdq'}
2025-12-14 19:38:01,251 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 11\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:01,251 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 11\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:02,188 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMUven7Z7TevPYxPdq'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:02,188 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMUven7Z7TevPYxPdq'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:02,190 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:02,190 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:02,191 INFO Processing question 12
2025-12-14 19:38:02,191 INFO Processing question 12
2025-12-14 19:38:02,191 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:02,191 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:02,216 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:02,216 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:02,509 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:38:02,510 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMaMLCT1G7owVNA83r'}
2025-12-14 19:38:02,510 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMaMLCT1G7owVNA83r'}
2025-12-14 19:38:02,511 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 12\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:02,511 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 12\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:02,769 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMaMLCT1G7owVNA83r'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:02,769 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMaMLCT1G7owVNA83r'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:02,770 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:02,770 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:02,771 INFO Processing question 13
2025-12-14 19:38:02,771 INFO Processing question 13
2025-12-14 19:38:02,772 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:02,772 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:02,787 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:02,787 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:03,024 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:38:03,024 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMcZHm1gmaC5g2i2Mh'}
2025-12-14 19:38:03,024 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMcZHm1gmaC5g2i2Mh'}
2025-12-14 19:38:03,025 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:03,025 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:03,320 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMcZHm1gmaC5g2i2Mh'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:03,320 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMcZHm1gmaC5g2i2Mh'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:03,321 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:03,321 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:03,322 INFO Processing question 14
2025-12-14 19:38:03,322 INFO Processing question 14
2025-12-14 19:38:03,322 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:03,322 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:03,336 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:03,336 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:03,566 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:38:03,567 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMeuB9qsiC46GUAJNG'}
2025-12-14 19:38:03,567 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMeuB9qsiC46GUAJNG'}
2025-12-14 19:38:03,569 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:03,569 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:03,857 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMeuB9qsiC46GUAJNG'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:03,857 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMeuB9qsiC46GUAJNG'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:03,862 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:03,862 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:03,864 INFO Processing question 15
2025-12-14 19:38:03,864 INFO Processing question 15
2025-12-14 19:38:03,865 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:03,865 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:38:03,895 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:03,895 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:38:04,162 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:38:04,164 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMhNG5Sc5HMgL1UwuF'}
2025-12-14 19:38:04,164 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMhNG5Sc5HMgL1UwuF'}
2025-12-14 19:38:04,167 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:04,167 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:38:04,445 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMhNG5Sc5HMgL1UwuF'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:04,445 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-instant-v1'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-v1'}, 'request_id': 'req_011CW7hMhNG5Sc5HMgL1UwuF'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:38:04,448 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:04,448 INFO No LLM provider available; returning placeholder
2025-12-14 19:38:04,451 INFO Wrote analysis to ./llm_analyses/Sample-llm-analysis.txt
2025-12-14 19:38:04,451 INFO Wrote analysis to ./llm_analyses/Sample-llm-analysis.txt
2025-12-14 19:38:04,452 INFO Report generation finished: ./llm_analyses/Sample-llm-analysis.txt
2025-12-14 19:39:08,777 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 19:39:08,777 INFO [33mPress CTRL+C to quit[0m
2025-12-14 19:39:09,570 INFO Received form responses; launching background generation
2025-12-14 19:39:09,570 INFO Background report generation started
2025-12-14 19:39:09,572 INFO 127.0.0.1 - - [14/Dec/2025 19:39:09] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:39:09,577 INFO Starting report generation
2025-12-14 19:39:09,577 INFO Starting report generation
2025-12-14 19:39:09,577 WARNING Temporary hardcoded ANTHROPIC_API_KEY is set from llama_rag.py — remove after testing
2025-12-14 19:39:09,577 WARNING Temporary hardcoded ANTHROPIC_API_KEY is set from llama_rag.py — remove after testing
2025-12-14 19:39:09,578 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:39:09,578 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:39:09,578 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 251, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:39:09,578 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 251, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:39:09,579 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:39:09,579 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:39:09,579 INFO Processing question 1
2025-12-14 19:39:09,579 INFO Processing question 1
2025-12-14 19:39:09,579 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:09,579 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:09,932 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:09,932 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:11,396 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:11,398 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSedCSqpVfy3NX73R2'}
2025-12-14 19:39:11,398 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSedCSqpVfy3NX73R2'}
2025-12-14 19:39:11,461 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:11,461 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:11,743 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSedCSqpVfy3NX73R2'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:11,743 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSedCSqpVfy3NX73R2'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:11,747 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:11,747 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:11,748 INFO Processing question 2
2025-12-14 19:39:11,748 INFO Processing question 2
2025-12-14 19:39:11,748 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:11,748 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:11,763 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:11,763 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:12,032 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:12,033 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hShcHPCGmiUGJtW29m'}
2025-12-14 19:39:12,033 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hShcHPCGmiUGJtW29m'}
2025-12-14 19:39:12,034 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 2\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:12,034 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 2\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:12,383 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hShcHPCGmiUGJtW29m'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:12,383 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hShcHPCGmiUGJtW29m'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:12,389 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:12,389 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:12,391 INFO Processing question 3
2025-12-14 19:39:12,391 INFO Processing question 3
2025-12-14 19:39:12,392 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:12,392 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:12,423 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:12,423 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:12,703 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:12,705 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSkPTvSMm7Y6dR5tYp'}
2025-12-14 19:39:12,705 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSkPTvSMm7Y6dR5tYp'}
2025-12-14 19:39:12,708 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 3\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:12,708 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 3\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:12,977 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSkPTvSMm7Y6dR5tYp'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:12,977 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSkPTvSMm7Y6dR5tYp'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:12,981 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:12,981 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:12,984 INFO Processing question 4
2025-12-14 19:39:12,984 INFO Processing question 4
2025-12-14 19:39:12,985 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:12,985 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:13,018 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:13,018 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:13,243 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:13,245 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSnoKsyqfQzyiM2xG6'}
2025-12-14 19:39:13,245 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSnoKsyqfQzyiM2xG6'}
2025-12-14 19:39:13,247 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 4\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:13,247 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 4\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:13,606 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSnoKsyqfQzyiM2xG6'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:13,606 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSnoKsyqfQzyiM2xG6'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:13,611 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:13,611 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:13,613 INFO Processing question 5
2025-12-14 19:39:13,613 INFO Processing question 5
2025-12-14 19:39:13,614 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:13,614 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:13,646 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:13,646 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:13,904 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:13,924 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSqUZD5ky2ZWdpKxez'}
2025-12-14 19:39:13,924 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSqUZD5ky2ZWdpKxez'}
2025-12-14 19:39:13,926 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:13,926 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:14,267 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSqUZD5ky2ZWdpKxez'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:14,267 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSqUZD5ky2ZWdpKxez'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:14,271 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:14,271 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:14,273 INFO Processing question 6
2025-12-14 19:39:14,273 INFO Processing question 6
2025-12-14 19:39:14,274 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:14,274 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:14,300 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:14,300 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:14,596 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:14,598 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hStRuYvxzRbiZwpzjB'}
2025-12-14 19:39:14,598 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hStRuYvxzRbiZwpzjB'}
2025-12-14 19:39:14,601 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 6\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:14,601 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 6\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:14,915 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hStRuYvxzRbiZwpzjB'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:14,915 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hStRuYvxzRbiZwpzjB'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:14,919 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:14,919 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:14,922 INFO Processing question 7
2025-12-14 19:39:14,922 INFO Processing question 7
2025-12-14 19:39:14,922 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:14,922 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:14,951 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:14,951 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:15,231 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:15,232 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSwC6Z6Vdjf9Z4hT82'}
2025-12-14 19:39:15,232 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSwC6Z6Vdjf9Z4hT82'}
2025-12-14 19:39:15,234 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 7\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:15,234 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 7\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:15,492 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSwC6Z6Vdjf9Z4hT82'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:15,492 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSwC6Z6Vdjf9Z4hT82'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:15,497 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:15,497 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:15,499 INFO Processing question 8
2025-12-14 19:39:15,499 INFO Processing question 8
2025-12-14 19:39:15,499 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:15,499 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:15,528 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:15,528 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:15,767 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:15,768 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSyWzvJBy54cMPsHFT'}
2025-12-14 19:39:15,768 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSyWzvJBy54cMPsHFT'}
2025-12-14 19:39:15,771 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:15,771 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:16,049 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSyWzvJBy54cMPsHFT'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:16,049 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hSyWzvJBy54cMPsHFT'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:16,054 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:16,054 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:16,057 INFO Processing question 9
2025-12-14 19:39:16,057 INFO Processing question 9
2025-12-14 19:39:16,057 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:16,057 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:16,088 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:16,088 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:16,318 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:16,318 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT1td88SqGPfkRZWmg'}
2025-12-14 19:39:16,318 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT1td88SqGPfkRZWmg'}
2025-12-14 19:39:16,320 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 9\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:16,320 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 9\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:16,634 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT1td88SqGPfkRZWmg'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:16,634 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT1td88SqGPfkRZWmg'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:16,652 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:16,652 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:16,654 INFO Processing question 10
2025-12-14 19:39:16,654 INFO Processing question 10
2025-12-14 19:39:16,654 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:16,654 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:16,675 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:16,675 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:16,938 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:16,939 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT4ZrRCvDhp2oJncZG'}
2025-12-14 19:39:16,939 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT4ZrRCvDhp2oJncZG'}
2025-12-14 19:39:16,941 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 10\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:16,941 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 10\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:17,228 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT4ZrRCvDhp2oJncZG'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:17,228 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT4ZrRCvDhp2oJncZG'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:17,233 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:17,233 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:17,235 INFO Processing question 11
2025-12-14 19:39:17,235 INFO Processing question 11
2025-12-14 19:39:17,235 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:17,235 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:17,266 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:17,266 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:18,108 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:18,109 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT7FLgxrCqC2Den1ot'}
2025-12-14 19:39:18,109 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT7FLgxrCqC2Den1ot'}
2025-12-14 19:39:18,112 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 11\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:18,112 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 11\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:18,412 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT7FLgxrCqC2Den1ot'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:18,412 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hT7FLgxrCqC2Den1ot'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:18,414 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:18,414 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:18,415 INFO Processing question 12
2025-12-14 19:39:18,415 INFO Processing question 12
2025-12-14 19:39:18,415 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:18,415 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:18,434 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:18,434 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:18,874 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:18,875 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTCqSFtGGMNqhJfKUc'}
2025-12-14 19:39:18,875 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTCqSFtGGMNqhJfKUc'}
2025-12-14 19:39:18,877 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 12\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:18,877 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 12\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:20,024 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTCqSFtGGMNqhJfKUc'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:20,024 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTCqSFtGGMNqhJfKUc'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:20,027 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:20,027 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:20,031 INFO Processing question 13
2025-12-14 19:39:20,031 INFO Processing question 13
2025-12-14 19:39:20,032 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:20,032 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:20,059 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:20,059 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:20,798 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:20,798 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTM2ZcUz1r1c63coK9'}
2025-12-14 19:39:20,798 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTM2ZcUz1r1c63coK9'}
2025-12-14 19:39:20,800 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:20,800 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:21,094 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTM2ZcUz1r1c63coK9'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:21,094 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTM2ZcUz1r1c63coK9'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:21,098 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:21,098 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:21,101 INFO Processing question 14
2025-12-14 19:39:21,101 INFO Processing question 14
2025-12-14 19:39:21,101 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:21,101 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:21,131 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:21,131 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:21,381 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:21,382 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTPXsjjQj5CGrqmYKy'}
2025-12-14 19:39:21,382 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTPXsjjQj5CGrqmYKy'}
2025-12-14 19:39:21,386 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:21,386 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:21,810 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTPXsjjQj5CGrqmYKy'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:21,810 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTPXsjjQj5CGrqmYKy'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:21,813 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:21,813 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:21,816 INFO Processing question 15
2025-12-14 19:39:21,816 INFO Processing question 15
2025-12-14 19:39:21,817 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:21,817 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:21,849 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:21,849 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:22,080 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:22,081 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTSavmzJJUqujHUjSM'}
2025-12-14 19:39:22,081 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTSavmzJJUqujHUjSM'}
2025-12-14 19:39:22,084 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:22,084 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:22,385 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTSavmzJJUqujHUjSM'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:22,385 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hTSavmzJJUqujHUjSM'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:22,390 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:22,390 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:22,393 INFO Wrote analysis to ./llm_analyses/Sample-llm-analysis.txt
2025-12-14 19:39:22,393 INFO Wrote analysis to ./llm_analyses/Sample-llm-analysis.txt
2025-12-14 19:39:22,393 INFO Report generation finished: ./llm_analyses/Sample-llm-analysis.txt
2025-12-14 19:39:32,379 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 19:39:32,380 INFO [33mPress CTRL+C to quit[0m
2025-12-14 19:39:33,035 INFO Received form responses; launching background generation
2025-12-14 19:39:33,035 INFO Background report generation started
2025-12-14 19:39:33,037 INFO 127.0.0.1 - - [14/Dec/2025 19:39:33] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:39:33,038 INFO Starting report generation
2025-12-14 19:39:33,038 INFO Starting report generation
2025-12-14 19:39:33,038 WARNING Temporary hardcoded ANTHROPIC_API_KEY is set from llama_rag.py — remove after testing
2025-12-14 19:39:33,038 WARNING Temporary hardcoded ANTHROPIC_API_KEY is set from llama_rag.py — remove after testing
2025-12-14 19:39:33,038 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:39:33,038 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:39:33,038 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 251, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:39:33,038 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 251, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:39:33,039 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:39:33,039 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:39:33,039 INFO Processing question 1
2025-12-14 19:39:33,039 INFO Processing question 1
2025-12-14 19:39:33,039 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:33,039 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:33,282 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:33,282 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:33,699 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:33,700 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUJ1Ge578FYBraKq2u'}
2025-12-14 19:39:33,700 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUJ1Ge578FYBraKq2u'}
2025-12-14 19:39:33,737 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:33,737 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:34,028 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUJ1Ge578FYBraKq2u'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:34,028 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUJ1Ge578FYBraKq2u'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:34,033 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:34,033 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:34,035 INFO Processing question 2
2025-12-14 19:39:34,035 INFO Processing question 2
2025-12-14 19:39:34,036 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:34,036 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:34,062 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:34,062 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:34,359 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:34,361 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hULzbxv52ZTSDXW3cx'}
2025-12-14 19:39:34,361 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hULzbxv52ZTSDXW3cx'}
2025-12-14 19:39:34,364 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 2\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:34,364 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 2\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:34,638 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hULzbxv52ZTSDXW3cx'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:34,638 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hULzbxv52ZTSDXW3cx'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:34,642 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:34,642 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:34,645 INFO Processing question 3
2025-12-14 19:39:34,645 INFO Processing question 3
2025-12-14 19:39:34,646 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:34,646 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:34,667 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:34,667 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:35,359 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:35,360 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hURLns1Wocdp2vsehw'}
2025-12-14 19:39:35,360 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hURLns1Wocdp2vsehw'}
2025-12-14 19:39:35,361 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 3\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:35,361 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 3\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:35,631 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hURLns1Wocdp2vsehw'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:35,631 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hURLns1Wocdp2vsehw'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:35,633 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:35,633 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:35,636 INFO Processing question 4
2025-12-14 19:39:35,636 INFO Processing question 4
2025-12-14 19:39:35,636 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:35,636 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:35,665 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:35,665 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:36,468 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:36,471 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUTehdhxehZHMqdYB8'}
2025-12-14 19:39:36,471 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUTehdhxehZHMqdYB8'}
2025-12-14 19:39:36,473 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 4\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:36,473 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 4\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:36,745 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUTehdhxehZHMqdYB8'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:36,745 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUTehdhxehZHMqdYB8'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:36,748 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:36,748 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:36,750 INFO Processing question 5
2025-12-14 19:39:36,750 INFO Processing question 5
2025-12-14 19:39:36,751 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:36,751 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:36,781 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:36,781 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:37,026 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:37,027 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUYTRdcZstRdxKRFzr'}
2025-12-14 19:39:37,027 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUYTRdcZstRdxKRFzr'}
2025-12-14 19:39:37,029 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:37,029 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:37,316 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUYTRdcZstRdxKRFzr'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:37,316 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUYTRdcZstRdxKRFzr'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:37,320 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:37,320 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:37,323 INFO Processing question 6
2025-12-14 19:39:37,323 INFO Processing question 6
2025-12-14 19:39:37,323 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:37,323 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:37,352 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:37,352 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:37,612 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:37,615 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUayEH5r2VTrSmXgHW'}
2025-12-14 19:39:37,615 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUayEH5r2VTrSmXgHW'}
2025-12-14 19:39:37,619 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 6\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:37,619 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 6\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:37,868 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUayEH5r2VTrSmXgHW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:37,868 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUayEH5r2VTrSmXgHW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:37,870 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:37,870 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:37,871 INFO Processing question 7
2025-12-14 19:39:37,871 INFO Processing question 7
2025-12-14 19:39:37,871 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:37,871 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:37,888 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:37,888 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:38,109 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:38,111 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUd9xAwVwaK2jfcyUu'}
2025-12-14 19:39:38,111 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUd9xAwVwaK2jfcyUu'}
2025-12-14 19:39:38,114 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 7\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:38,114 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 7\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:38,406 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUd9xAwVwaK2jfcyUu'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:38,406 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUd9xAwVwaK2jfcyUu'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:38,408 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:38,408 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:38,410 INFO Processing question 8
2025-12-14 19:39:38,410 INFO Processing question 8
2025-12-14 19:39:38,410 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:38,410 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:38,431 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:38,431 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:38,787 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:38,787 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUffGEDiQEZiTJQ73J'}
2025-12-14 19:39:38,787 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUffGEDiQEZiTJQ73J'}
2025-12-14 19:39:38,788 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:38,788 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:39,165 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUffGEDiQEZiTJQ73J'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:39,165 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUffGEDiQEZiTJQ73J'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:39,169 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:39,169 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:39,171 INFO Processing question 9
2025-12-14 19:39:39,171 INFO Processing question 9
2025-12-14 19:39:39,171 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:39,171 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:39,201 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:39,201 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:39,494 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:39,496 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUivUAD8SYf13nxCxp'}
2025-12-14 19:39:39,496 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUivUAD8SYf13nxCxp'}
2025-12-14 19:39:39,499 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 9\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:39,499 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 9\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:39,791 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUivUAD8SYf13nxCxp'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:39,791 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUivUAD8SYf13nxCxp'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:39,800 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:39,800 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:39,801 INFO Processing question 10
2025-12-14 19:39:39,801 INFO Processing question 10
2025-12-14 19:39:39,801 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:39,801 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:39,820 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:39,820 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:40,059 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:40,060 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUmQ3WrEXR66heQpGx'}
2025-12-14 19:39:40,060 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUmQ3WrEXR66heQpGx'}
2025-12-14 19:39:40,064 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 10\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:40,064 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 10\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:40,352 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUmQ3WrEXR66heQpGx'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:40,352 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUmQ3WrEXR66heQpGx'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:40,356 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:40,356 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:40,359 INFO Processing question 11
2025-12-14 19:39:40,359 INFO Processing question 11
2025-12-14 19:39:40,359 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:40,359 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:40,388 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:40,388 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:40,627 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:40,628 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUosdD43KXdGVuH31P'}
2025-12-14 19:39:40,628 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUosdD43KXdGVuH31P'}
2025-12-14 19:39:40,629 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 11\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:40,629 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 11\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:42,636 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUosdD43KXdGVuH31P'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:42,636 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUosdD43KXdGVuH31P'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:42,642 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:42,642 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:42,643 INFO Processing question 12
2025-12-14 19:39:42,643 INFO Processing question 12
2025-12-14 19:39:42,644 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:42,644 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:42,665 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:42,665 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:42,929 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:42,930 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUydWCXriKesdp15yo'}
2025-12-14 19:39:42,930 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUydWCXriKesdp15yo'}
2025-12-14 19:39:42,932 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 12\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:42,932 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 12\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:43,212 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUydWCXriKesdp15yo'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:43,212 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hUydWCXriKesdp15yo'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:43,216 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:43,216 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:43,218 INFO Processing question 13
2025-12-14 19:39:43,218 INFO Processing question 13
2025-12-14 19:39:43,218 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:43,218 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:43,243 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:43,243 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:43,497 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:43,498 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV25b3v6ESKV5jBG9s'}
2025-12-14 19:39:43,498 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV25b3v6ESKV5jBG9s'}
2025-12-14 19:39:43,501 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:43,501 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:43,770 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV25b3v6ESKV5jBG9s'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:43,770 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV25b3v6ESKV5jBG9s'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:43,771 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:43,771 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:43,772 INFO Processing question 14
2025-12-14 19:39:43,772 INFO Processing question 14
2025-12-14 19:39:43,772 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:43,772 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:43,787 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:43,787 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:44,013 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:44,013 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV4KXiTGWGsHyiCRub'}
2025-12-14 19:39:44,013 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV4KXiTGWGsHyiCRub'}
2025-12-14 19:39:44,016 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:44,016 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:44,415 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV4KXiTGWGsHyiCRub'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:44,415 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV4KXiTGWGsHyiCRub'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:44,419 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:44,419 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:44,422 INFO Processing question 15
2025-12-14 19:39:44,422 INFO Processing question 15
2025-12-14 19:39:44,423 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:44,423 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:39:44,452 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:44,452 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:39:44,931 INFO HTTP Request: POST https://api.anthropic.com/v1/complete "HTTP/1.1 404 Not Found"
2025-12-14 19:39:44,932 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV8Bwsan5HHrsMrvra'}
2025-12-14 19:39:44,932 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV8Bwsan5HHrsMrvra'}
2025-12-14 19:39:44,936 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:44,936 INFO Anthropic HTTP body preview: {"model": "claude-2", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample\n\nAssistant:"}
2025-12-14 19:39:45,874 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV8Bwsan5HHrsMrvra'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:45,874 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 181, in _call_llm
    resp = client.completions.create(model=os.getenv('ANTHROPIC_MODEL', 'claude-2'),
                                     prompt=anth_prompt,
                                     max_tokens_to_sample=max_tokens)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/completions.py", line 393, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/complete",
        ^^^^^^^^^^^^^^^
    ...<21 lines>...
        stream_cls=Stream[Completion],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-2'}, 'request_id': 'req_011CW7hV8Bwsan5HHrsMrvra'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 209, in _call_llm
    r.raise_for_status()
    ~~~~~~~~~~~~~~~~~~^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/complete
2025-12-14 19:39:45,876 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:45,876 INFO No LLM provider available; returning placeholder
2025-12-14 19:39:45,879 INFO Wrote analysis to ./llm_analyses/Sample-llm-analysis.txt
2025-12-14 19:39:45,879 INFO Wrote analysis to ./llm_analyses/Sample-llm-analysis.txt
2025-12-14 19:39:45,879 INFO Report generation finished: ./llm_analyses/Sample-llm-analysis.txt
2025-12-14 19:50:34,995 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 19:50:34,995 INFO [33mPress CTRL+C to quit[0m
2025-12-14 19:50:36,825 INFO Received form responses; launching background generation
2025-12-14 19:50:36,825 INFO Background report generation started
2025-12-14 19:50:36,827 INFO 127.0.0.1 - - [14/Dec/2025 19:50:36] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:50:36,829 INFO Starting report generation
2025-12-14 19:50:36,829 INFO Starting report generation
2025-12-14 19:50:36,830 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:50:36,830 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:50:36,830 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 327, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:50:36,830 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 327, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:50:36,832 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:50:36,832 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:50:36,832 INFO Processing question 1
2025-12-14 19:50:36,832 INFO Processing question 1
2025-12-14 19:50:36,832 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:50:36,832 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:50:37,088 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:50:37,088 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:50:37,088 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:50:37,088 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:50:44,259 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:50:44,279 INFO LLM (API) provided response for question 1
2025-12-14 19:50:44,279 INFO LLM (API) provided response for question 1
2025-12-14 19:50:44,280 INFO Processing question 2
2025-12-14 19:50:44,280 INFO Processing question 2
2025-12-14 19:50:44,280 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:50:44,280 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:50:44,302 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:50:44,302 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:50:44,302 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:50:44,302 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:50:49,262 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:50:49,266 INFO LLM (API) provided response for question 2
2025-12-14 19:50:49,266 INFO LLM (API) provided response for question 2
2025-12-14 19:50:49,267 INFO Processing question 3
2025-12-14 19:50:49,267 INFO Processing question 3
2025-12-14 19:50:49,267 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:50:49,267 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:50:49,297 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:50:49,297 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:50:49,298 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:50:49,298 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:50:53,997 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:50:54,011 INFO LLM (API) provided response for question 3
2025-12-14 19:50:54,011 INFO LLM (API) provided response for question 3
2025-12-14 19:50:54,012 INFO Processing question 4
2025-12-14 19:50:54,012 INFO Processing question 4
2025-12-14 19:50:54,012 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:50:54,012 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:50:54,036 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:50:54,036 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:50:54,036 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:50:54,036 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:50:58,680 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:50:58,682 INFO LLM (API) provided response for question 4
2025-12-14 19:50:58,682 INFO LLM (API) provided response for question 4
2025-12-14 19:50:58,683 INFO Processing question 5
2025-12-14 19:50:58,683 INFO Processing question 5
2025-12-14 19:50:58,683 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:50:58,683 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:50:58,714 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:50:58,714 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:50:58,714 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:50:58,714 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:03,045 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:51:03,051 INFO LLM (API) provided response for question 5
2025-12-14 19:51:03,051 INFO LLM (API) provided response for question 5
2025-12-14 19:51:03,051 INFO Processing question 6
2025-12-14 19:51:03,051 INFO Processing question 6
2025-12-14 19:51:03,052 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:03,052 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:03,079 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:03,079 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:03,079 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:03,079 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:09,098 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:51:09,104 INFO LLM (API) provided response for question 6
2025-12-14 19:51:09,104 INFO LLM (API) provided response for question 6
2025-12-14 19:51:09,104 INFO Processing question 7
2025-12-14 19:51:09,104 INFO Processing question 7
2025-12-14 19:51:09,105 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:09,105 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:09,136 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:09,136 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:09,136 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:09,136 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:15,067 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:51:15,077 INFO LLM (API) provided response for question 7
2025-12-14 19:51:15,077 INFO LLM (API) provided response for question 7
2025-12-14 19:51:15,077 INFO Processing question 8
2025-12-14 19:51:15,077 INFO Processing question 8
2025-12-14 19:51:15,078 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:15,078 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:15,107 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:15,107 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:15,107 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:15,107 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:19,370 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:51:19,372 INFO LLM (API) provided response for question 8
2025-12-14 19:51:19,372 INFO LLM (API) provided response for question 8
2025-12-14 19:51:19,373 INFO Processing question 9
2025-12-14 19:51:19,373 INFO Processing question 9
2025-12-14 19:51:19,373 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:19,373 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:19,403 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:19,403 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:19,403 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:19,403 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:19,693 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:51:19,693 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:51:30,162 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:51:30,168 INFO LLM (API) provided response for question 9
2025-12-14 19:51:30,168 INFO LLM (API) provided response for question 9
2025-12-14 19:51:30,168 INFO Processing question 10
2025-12-14 19:51:30,168 INFO Processing question 10
2025-12-14 19:51:30,169 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:30,169 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:30,182 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:30,182 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:30,182 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:30,182 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:30,437 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:51:30,437 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 19:51:43,402 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:51:43,408 INFO LLM (API) provided response for question 10
2025-12-14 19:51:43,408 INFO LLM (API) provided response for question 10
2025-12-14 19:51:43,408 INFO Processing question 11
2025-12-14 19:51:43,408 INFO Processing question 11
2025-12-14 19:51:43,409 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:43,409 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:43,439 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:43,439 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:43,439 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:43,439 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:43,969 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:51:43,978 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:51:56,538 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:51:56,544 INFO LLM (API) provided response for question 11
2025-12-14 19:51:56,544 INFO LLM (API) provided response for question 11
2025-12-14 19:51:56,544 INFO Processing question 12
2025-12-14 19:51:56,544 INFO Processing question 12
2025-12-14 19:51:56,545 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:56,545 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:51:56,571 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:56,571 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:51:56,571 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:56,571 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:51:56,908 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:51:56,911 INFO Retrying request to /v1/messages in 5.000000 seconds
2025-12-14 19:52:02,463 INFO Received form responses; launching background generation
2025-12-14 19:52:02,463 INFO Background report generation started
2025-12-14 19:52:02,464 INFO 127.0.0.1 - - [14/Dec/2025 19:52:02] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:52:02,464 INFO Starting report generation
2025-12-14 19:52:02,464 INFO Starting report generation
2025-12-14 19:52:02,465 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:52:02,465 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:52:02,465 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 327, in generate_report
    last_exc = e
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:52:02,465 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 327, in generate_report
    last_exc = e
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:52:02,466 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:52:02,466 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:52:02,466 INFO Processing question 1
2025-12-14 19:52:02,466 INFO Processing question 1
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 1
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 1
2025-12-14 19:52:02,466 INFO Processing question 2
2025-12-14 19:52:02,466 INFO Processing question 2
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 2
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 2
2025-12-14 19:52:02,466 INFO Processing question 3
2025-12-14 19:52:02,466 INFO Processing question 3
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 3
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 3
2025-12-14 19:52:02,466 INFO Processing question 4
2025-12-14 19:52:02,466 INFO Processing question 4
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 4
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 4
2025-12-14 19:52:02,466 INFO Processing question 5
2025-12-14 19:52:02,466 INFO Processing question 5
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 5
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 5
2025-12-14 19:52:02,466 INFO Processing question 6
2025-12-14 19:52:02,466 INFO Processing question 6
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM cache hit
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 6
2025-12-14 19:52:02,466 INFO LLM (API) provided response for question 6
2025-12-14 19:52:02,466 INFO Processing question 7
2025-12-14 19:52:02,466 INFO Processing question 7
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO LLM cache hit
2025-12-14 19:52:02,467 INFO LLM cache hit
2025-12-14 19:52:02,467 INFO LLM (API) provided response for question 7
2025-12-14 19:52:02,467 INFO LLM (API) provided response for question 7
2025-12-14 19:52:02,467 INFO Processing question 8
2025-12-14 19:52:02,467 INFO Processing question 8
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO LLM cache hit
2025-12-14 19:52:02,467 INFO LLM cache hit
2025-12-14 19:52:02,467 INFO LLM (API) provided response for question 8
2025-12-14 19:52:02,467 INFO LLM (API) provided response for question 8
2025-12-14 19:52:02,467 INFO Processing question 9
2025-12-14 19:52:02,467 INFO Processing question 9
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO LLM cache hit
2025-12-14 19:52:02,467 INFO LLM cache hit
2025-12-14 19:52:02,467 INFO LLM (API) provided response for question 9
2025-12-14 19:52:02,467 INFO LLM (API) provided response for question 9
2025-12-14 19:52:02,467 INFO Processing question 10
2025-12-14 19:52:02,467 INFO Processing question 10
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO LLM cache hit
2025-12-14 19:52:02,467 INFO LLM cache hit
2025-12-14 19:52:02,467 INFO LLM (API) provided response for question 10
2025-12-14 19:52:02,467 INFO LLM (API) provided response for question 10
2025-12-14 19:52:02,467 INFO Processing question 11
2025-12-14 19:52:02,467 INFO Processing question 11
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO LLM cache hit
2025-12-14 19:52:02,467 INFO LLM cache hit
2025-12-14 19:52:02,467 INFO LLM (API) provided response for question 11
2025-12-14 19:52:02,467 INFO LLM (API) provided response for question 11
2025-12-14 19:52:02,467 INFO Processing question 12
2025-12-14 19:52:02,467 INFO Processing question 12
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,467 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:02,480 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:02,480 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:02,480 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:02,480 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:03,401 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:03,402 INFO Retrying request to /v1/messages in 11.000000 seconds
2025-12-14 19:52:06,946 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:52:06,952 INFO LLM (API) provided response for question 12
2025-12-14 19:52:06,952 INFO LLM (API) provided response for question 12
2025-12-14 19:52:06,953 INFO Processing question 13
2025-12-14 19:52:06,953 INFO Processing question 13
2025-12-14 19:52:06,953 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:06,953 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:06,978 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:06,978 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:06,978 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:06,978 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:07,827 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:07,828 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:52:14,779 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:14,782 INFO Retrying request to /v1/messages in 11.000000 seconds
2025-12-14 19:52:22,021 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:52:22,028 INFO LLM (API) provided response for question 13
2025-12-14 19:52:22,028 INFO LLM (API) provided response for question 13
2025-12-14 19:52:22,028 INFO Processing question 14
2025-12-14 19:52:22,028 INFO Processing question 14
2025-12-14 19:52:22,029 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:22,029 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:22,060 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:22,060 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:22,061 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:22,061 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:22,415 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:22,416 INFO Retrying request to /v1/messages in 4.000000 seconds
2025-12-14 19:52:26,657 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:26,679 INFO Retrying request to /v1/messages in 12.000000 seconds
2025-12-14 19:52:30,841 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:52:30,845 INFO LLM (API) provided response for question 12
2025-12-14 19:52:30,845 INFO LLM (API) provided response for question 12
2025-12-14 19:52:30,845 INFO Processing question 13
2025-12-14 19:52:30,845 INFO Processing question 13
2025-12-14 19:52:30,846 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:30,846 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:30,877 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:30,877 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:30,877 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:30,877 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:31,164 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:31,165 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:52:38,531 INFO Received form responses; launching background generation
2025-12-14 19:52:38,531 INFO Background report generation started
2025-12-14 19:52:38,531 INFO 127.0.0.1 - - [14/Dec/2025 19:52:38] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:52:38,532 INFO Starting report generation
2025-12-14 19:52:38,532 INFO Starting report generation
2025-12-14 19:52:38,533 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:52:38,533 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:52:38,533 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 327, in generate_report
    last_exc = e
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:52:38,533 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 327, in generate_report
    last_exc = e
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:52:38,533 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:52:38,533 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:52:38,533 INFO Processing question 1
2025-12-14 19:52:38,533 INFO Processing question 1
2025-12-14 19:52:38,533 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:38,533 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:38,547 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:38,547 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:38,547 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:38,547 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:38,909 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:38,911 INFO Retrying request to /v1/messages in 11.000000 seconds
2025-12-14 19:52:39,050 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:39,052 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:52:39,052 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:52:39,052 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:52:39,052 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:52:39,209 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:52:39,210 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:52:39,210 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:52:39,211 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:52:39,211 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:52:39,388 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:52:39,390 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:52:39,390 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:52:39,390 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:52:39,390 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:52:39,745 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:52:39,745 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:52:39,745 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:52:39,745 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:52:39,745 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:52:39,955 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:52:39,956 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:52:39,956 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:52:39,957 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iUFQ7wTQUZQwAFbBLL'}
2025-12-14 19:52:39,957 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iUFQ7wTQUZQwAFbBLL'}
2025-12-14 19:52:40,011 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:40,011 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:40,011 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:40,011 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:40,417 INFO Anthropic HTTP response status: 400
2025-12-14 19:52:40,417 INFO Anthropic HTTP response status: 400
2025-12-14 19:52:40,417 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iUHT9QdkbTnwmxPtwC"}
2025-12-14 19:52:40,417 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iUHT9QdkbTnwmxPtwC"}
2025-12-14 19:52:40,418 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:52:40,418 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:52:40,418 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:40,418 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:40,722 INFO Anthropic HTTP response status: 400
2025-12-14 19:52:40,722 INFO Anthropic HTTP response status: 400
2025-12-14 19:52:40,723 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iUJqVMFZGennihvZgD"}
2025-12-14 19:52:40,723 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iUJqVMFZGennihvZgD"}
2025-12-14 19:52:40,723 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:52:40,723 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:52:40,727 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:40,727 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:41,064 INFO Anthropic HTTP response status: 400
2025-12-14 19:52:41,064 INFO Anthropic HTTP response status: 400
2025-12-14 19:52:41,065 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iULK3azdosPg7s8t5P"}
2025-12-14 19:52:41,065 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iULK3azdosPg7s8t5P"}
2025-12-14 19:52:41,065 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:52:41,065 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:52:41,068 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:41,068 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:41,387 INFO Anthropic HTTP response status: 400
2025-12-14 19:52:41,387 INFO Anthropic HTTP response status: 400
2025-12-14 19:52:41,387 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iUMjd13QvJ4PDKA5F6"}
2025-12-14 19:52:41,387 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iUMjd13QvJ4PDKA5F6"}
2025-12-14 19:52:41,387 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:52:41,387 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:52:41,390 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:41,390 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 14\n\nAnswer: Sample response 14\n\nAssistant:"}
2025-12-14 19:52:41,699 INFO Anthropic HTTP response status: 400
2025-12-14 19:52:41,699 INFO Anthropic HTTP response status: 400
2025-12-14 19:52:41,700 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iUP3zTHYFLwTQ78Raq"}
2025-12-14 19:52:41,700 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iUP3zTHYFLwTQ78Raq"}
2025-12-14 19:52:41,700 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:52:41,700 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:52:41,703 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iUFQ7wTQUZQwAFbBLL'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    for m in candidates:
        ^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    headers = {'x-api-key': os.getenv('ANTHROPIC_API_KEY'), 'Content-Type': 'application/json'}
            ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:52:41,703 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iUFQ7wTQUZQwAFbBLL'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    for m in candidates:
        ^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    headers = {'x-api-key': os.getenv('ANTHROPIC_API_KEY'), 'Content-Type': 'application/json'}
            ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:52:41,709 INFO No LLM provider available; returning placeholder
2025-12-14 19:52:41,709 INFO No LLM provider available; returning placeholder
2025-12-14 19:52:41,709 INFO Processing question 15
2025-12-14 19:52:41,709 INFO Processing question 15
2025-12-14 19:52:41,710 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:41,710 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:41,738 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:41,738 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:41,738 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:41,738 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:42,081 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:42,082 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 19:52:43,529 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:52:43,533 INFO LLM (API) provided response for question 13
2025-12-14 19:52:43,533 INFO LLM (API) provided response for question 13
2025-12-14 19:52:43,534 INFO Processing question 14
2025-12-14 19:52:43,534 INFO Processing question 14
2025-12-14 19:52:43,534 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:43,534 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:43,566 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:43,566 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:43,566 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:43,566 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:43,814 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:43,815 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:52:50,283 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:50,285 INFO Retrying request to /v1/messages in 12.000000 seconds
2025-12-14 19:52:50,460 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:50,461 INFO Retrying request to /v1/messages in 12.000000 seconds
2025-12-14 19:52:54,905 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:52:54,911 INFO LLM (API) provided response for question 14
2025-12-14 19:52:54,911 INFO LLM (API) provided response for question 14
2025-12-14 19:52:54,911 INFO Processing question 15
2025-12-14 19:52:54,911 INFO Processing question 15
2025-12-14 19:52:54,912 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:54,912 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:52:54,936 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:54,936 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:52:54,936 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:54,936 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:52:55,205 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:52:55,206 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:53:02,610 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:53:02,618 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:53:02,618 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:53:02,618 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:53:02,618 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:53:02,829 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:53:02,830 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:02,830 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:02,830 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:53:02,830 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:53:02,845 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:53:02,846 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:53:02,846 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:53:02,846 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:53:02,846 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:53:03,082 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:53:03,083 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:53:03,085 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,085 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,086 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,086 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:53:03,086 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,086 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:53:03,086 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:53:03,086 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:53:03,251 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:53:03,252 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:53:03,253 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,253 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,253 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,253 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,254 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:53:03,254 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:53:03,254 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:53:03,254 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:53:03,427 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:53:03,429 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,429 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,429 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:53:03,429 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:53:03,449 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:53:03,451 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,451 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,451 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iVyw1FkpdaRZr41XvE'}
2025-12-14 19:53:03,451 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iVyw1FkpdaRZr41XvE'}
2025-12-14 19:53:03,460 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:03,460 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:03,460 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:03,460 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:03,587 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:53:03,589 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,589 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:53:03,589 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iVzdvPw3ErhcBjcNAT'}
2025-12-14 19:53:03,589 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iVzdvPw3ErhcBjcNAT'}
2025-12-14 19:53:03,592 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:03,592 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:03,592 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:03,592 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:03,733 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:03,733 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:03,734 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW1FNmYHTwsQ1P8xmo"}
2025-12-14 19:53:03,734 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW1FNmYHTwsQ1P8xmo"}
2025-12-14 19:53:03,734 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:03,734 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:03,734 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:03,734 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:03,880 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:03,880 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:03,880 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW1u4pKDmhX3kYNL33"}
2025-12-14 19:53:03,880 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW1u4pKDmhX3kYNL33"}
2025-12-14 19:53:03,880 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:03,880 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:03,880 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:03,880 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:04,103 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,103 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,103 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW2o9R9ebrxuuSpPRW"}
2025-12-14 19:53:04,103 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW2o9R9ebrxuuSpPRW"}
2025-12-14 19:53:04,104 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,104 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,107 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:04,107 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:04,180 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,180 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,181 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW3CCpW5SgeN1MN1z3"}
2025-12-14 19:53:04,181 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW3CCpW5SgeN1MN1z3"}
2025-12-14 19:53:04,181 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,181 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,182 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:04,182 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:04,412 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,412 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,412 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW3yakfs3WPa1pAGWP"}
2025-12-14 19:53:04,412 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW3yakfs3WPa1pAGWP"}
2025-12-14 19:53:04,413 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,413 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,416 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:04,416 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:04,483 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,483 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,483 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW4Kfq5qGFrdSPcBZi"}
2025-12-14 19:53:04,483 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW4Kfq5qGFrdSPcBZi"}
2025-12-14 19:53:04,483 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,483 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,485 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:04,485 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:04,714 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,714 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,715 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW5NvRmxLZfvo8aejz"}
2025-12-14 19:53:04,715 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW5NvRmxLZfvo8aejz"}
2025-12-14 19:53:04,715 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,715 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,718 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:04,718 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 1\n\nAnswer: Sample response 1\n\nAssistant:"}
2025-12-14 19:53:04,861 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,861 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:04,861 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW5kVjXwxQLzbt3AK2"}
2025-12-14 19:53:04,861 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW5kVjXwxQLzbt3AK2"}
2025-12-14 19:53:04,862 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,862 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:04,864 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:04,864 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 15\n\nAnswer: Sample response 15\n\nAssistant:"}
2025-12-14 19:53:05,009 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:05,009 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:05,010 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW6fKFGH7gYTKEkP4h"}
2025-12-14 19:53:05,010 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW6fKFGH7gYTKEkP4h"}
2025-12-14 19:53:05,010 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:05,010 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:05,014 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iVyw1FkpdaRZr41XvE'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    for m in candidates:
        ^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    headers = {'x-api-key': os.getenv('ANTHROPIC_API_KEY'), 'Content-Type': 'application/json'}
            ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:53:05,014 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iVyw1FkpdaRZr41XvE'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    for m in candidates:
        ^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    headers = {'x-api-key': os.getenv('ANTHROPIC_API_KEY'), 'Content-Type': 'application/json'}
            ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:53:05,017 INFO No LLM provider available; returning placeholder
2025-12-14 19:53:05,017 INFO No LLM provider available; returning placeholder
2025-12-14 19:53:05,017 INFO Processing question 2
2025-12-14 19:53:05,017 INFO Processing question 2
2025-12-14 19:53:05,017 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:53:05,017 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:53:05,043 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:53:05,043 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:53:05,043 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:53:05,043 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:53:05,176 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:05,176 INFO Anthropic HTTP response status: 400
2025-12-14 19:53:05,176 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW7NizSnaEAKidQEfn"}
2025-12-14 19:53:05,176 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7iW7NizSnaEAKidQEfn"}
2025-12-14 19:53:05,176 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:05,176 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:53:05,178 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iVzdvPw3ErhcBjcNAT'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    for m in candidates:
        ^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    headers = {'x-api-key': os.getenv('ANTHROPIC_API_KEY'), 'Content-Type': 'application/json'}
            ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:53:05,178 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7iVzdvPw3ErhcBjcNAT'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    for m in candidates:
        ^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    headers = {'x-api-key': os.getenv('ANTHROPIC_API_KEY'), 'Content-Type': 'application/json'}
            ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:53:05,180 INFO No LLM provider available; returning placeholder
2025-12-14 19:53:05,180 INFO No LLM provider available; returning placeholder
2025-12-14 19:53:05,180 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:53:05,180 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:53:05,181 INFO Report generation finished: ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:53:05,317 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:53:05,318 INFO Retrying request to /v1/messages in 9.000000 seconds
2025-12-14 19:53:06,791 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:53:06,796 INFO LLM (API) provided response for question 15
2025-12-14 19:53:06,796 INFO LLM (API) provided response for question 15
2025-12-14 19:53:06,796 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:53:06,796 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:53:06,796 INFO Report generation finished: ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:53:18,497 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:53:18,502 INFO LLM (API) provided response for question 2
2025-12-14 19:53:18,502 INFO LLM (API) provided response for question 2
2025-12-14 19:53:18,502 INFO Processing question 3
2025-12-14 19:53:18,502 INFO Processing question 3
2025-12-14 19:53:18,503 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:53:18,503 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:53:18,534 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:53:18,534 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:53:18,535 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:53:18,535 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:53:18,834 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:53:18,838 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:53:31,535 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:53:31,542 INFO LLM (API) provided response for question 3
2025-12-14 19:53:31,542 INFO LLM (API) provided response for question 3
2025-12-14 19:53:31,542 INFO Processing question 4
2025-12-14 19:53:31,542 INFO Processing question 4
2025-12-14 19:53:31,543 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:53:31,543 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:53:31,566 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:53:31,566 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:53:31,567 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:53:31,567 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:53:31,906 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:53:31,907 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:53:42,477 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:53:42,516 INFO LLM (API) provided response for question 4
2025-12-14 19:53:42,516 INFO LLM (API) provided response for question 4
2025-12-14 19:53:42,517 INFO Processing question 5
2025-12-14 19:53:42,517 INFO Processing question 5
2025-12-14 19:53:42,518 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:53:42,518 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:53:42,550 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:53:42,550 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:53:42,550 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:53:42,550 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:53:43,313 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:53:43,313 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:53:54,732 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:53:54,741 INFO LLM (API) provided response for question 5
2025-12-14 19:53:54,741 INFO LLM (API) provided response for question 5
2025-12-14 19:53:54,741 INFO Processing question 6
2025-12-14 19:53:54,741 INFO Processing question 6
2025-12-14 19:53:54,742 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:53:54,742 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:53:54,771 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:53:54,771 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:53:54,771 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:53:54,771 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:53:55,248 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:53:55,249 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:54:08,533 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:54:08,539 INFO LLM (API) provided response for question 6
2025-12-14 19:54:08,539 INFO LLM (API) provided response for question 6
2025-12-14 19:54:08,539 INFO Processing question 7
2025-12-14 19:54:08,539 INFO Processing question 7
2025-12-14 19:54:08,540 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:08,540 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:08,570 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:08,570 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:08,570 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:08,570 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:08,858 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:08,859 INFO Retrying request to /v1/messages in 5.000000 seconds
2025-12-14 19:54:09,434 INFO Received form responses; launching background generation
2025-12-14 19:54:09,434 INFO Background report generation started
2025-12-14 19:54:09,435 INFO 127.0.0.1 - - [14/Dec/2025 19:54:09] "POST /submit HTTP/1.1" 200 -
2025-12-14 19:54:09,436 INFO Starting report generation
2025-12-14 19:54:09,436 INFO Starting report generation
2025-12-14 19:54:09,439 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:54:09,439 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:54:09,439 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 327, in generate_report
    first = out[0]
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:54:09,439 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 327, in generate_report
    first = out[0]
    
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:54:09,440 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:54:09,440 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 19:54:09,440 INFO Processing question 1
2025-12-14 19:54:09,440 INFO Processing question 1
2025-12-14 19:54:09,440 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:09,440 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:09,455 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:09,455 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:09,455 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:09,455 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:09,739 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:09,739 INFO Retrying request to /v1/messages in 4.000000 seconds
2025-12-14 19:54:14,179 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:14,182 INFO Retrying request to /v1/messages in 12.000000 seconds
2025-12-14 19:54:17,697 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:54:17,705 INFO LLM (API) provided response for question 1
2025-12-14 19:54:17,705 INFO LLM (API) provided response for question 1
2025-12-14 19:54:17,705 INFO Processing question 2
2025-12-14 19:54:17,705 INFO Processing question 2
2025-12-14 19:54:17,706 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:17,706 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:17,734 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:17,734 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:17,734 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:17,734 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:18,315 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:18,317 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 19:54:26,593 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:26,595 INFO Retrying request to /v1/messages in 11.000000 seconds
2025-12-14 19:54:30,087 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:54:30,091 INFO LLM (API) provided response for question 7
2025-12-14 19:54:30,091 INFO LLM (API) provided response for question 7
2025-12-14 19:54:30,091 INFO Processing question 8
2025-12-14 19:54:30,091 INFO Processing question 8
2025-12-14 19:54:30,092 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:30,092 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:30,107 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:30,107 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:30,107 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:30,107 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:30,412 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:30,412 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 19:54:39,075 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:39,076 INFO Retrying request to /v1/messages in 11.000000 seconds
2025-12-14 19:54:43,207 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:54:43,211 INFO LLM (API) provided response for question 2
2025-12-14 19:54:43,211 INFO LLM (API) provided response for question 2
2025-12-14 19:54:43,212 INFO Processing question 3
2025-12-14 19:54:43,212 INFO Processing question 3
2025-12-14 19:54:43,212 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:43,212 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:43,228 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:43,228 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:43,228 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:43,228 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:43,943 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:43,944 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:54:51,305 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:51,308 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:54:51,308 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:54:51,308 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:54:51,308 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:54:51,469 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:54:51,471 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:54:51,471 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:54:51,471 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:54:51,471 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:54:51,647 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:54:51,677 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:54:51,677 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:54:51,678 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:54:51,678 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:54:51,850 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:54:51,851 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:54:51,851 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:54:51,851 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:54:51,851 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:54:52,039 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:54:52,041 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:54:52,041 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:54:52,042 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7idzE5kaz6GdgCMhjhp'}
2025-12-14 19:54:52,042 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7idzE5kaz6GdgCMhjhp'}
2025-12-14 19:54:52,046 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:52,046 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:52,046 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:52,046 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:52,761 INFO Anthropic HTTP response status: 400
2025-12-14 19:54:52,761 INFO Anthropic HTTP response status: 400
2025-12-14 19:54:52,762 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ie1ZCver3vwNRf6uPj"}
2025-12-14 19:54:52,762 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ie1ZCver3vwNRf6uPj"}
2025-12-14 19:54:52,762 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:54:52,762 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:54:52,762 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:52,762 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:53,107 INFO Anthropic HTTP response status: 400
2025-12-14 19:54:53,107 INFO Anthropic HTTP response status: 400
2025-12-14 19:54:53,107 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ie4s8pzonP199dsTod"}
2025-12-14 19:54:53,107 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ie4s8pzonP199dsTod"}
2025-12-14 19:54:53,107 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:54:53,107 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:54:53,110 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:53,110 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:53,404 INFO Anthropic HTTP response status: 400
2025-12-14 19:54:53,404 INFO Anthropic HTTP response status: 400
2025-12-14 19:54:53,404 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ie692rnWRn9UunHctQ"}
2025-12-14 19:54:53,404 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ie692rnWRn9UunHctQ"}
2025-12-14 19:54:53,404 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:54:53,404 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:54:53,406 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:53,406 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:53,760 INFO Anthropic HTTP response status: 400
2025-12-14 19:54:53,760 INFO Anthropic HTTP response status: 400
2025-12-14 19:54:53,761 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ie7ZcR1NkhqMZhAHcq"}
2025-12-14 19:54:53,761 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ie7ZcR1NkhqMZhAHcq"}
2025-12-14 19:54:53,761 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:54:53,761 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:54:53,764 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:53,764 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 8\n\nAnswer: Sample response 8\n\nAssistant:"}
2025-12-14 19:54:54,160 INFO Anthropic HTTP response status: 400
2025-12-14 19:54:54,160 INFO Anthropic HTTP response status: 400
2025-12-14 19:54:54,160 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ie9Abiy9ej1jgxWqSY"}
2025-12-14 19:54:54,160 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ie9Abiy9ej1jgxWqSY"}
2025-12-14 19:54:54,160 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:54:54,160 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:54:54,164 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7idzE5kaz6GdgCMhjhp'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    logger.info('Anthropic HTTP body preview: %s', body_preview)
    ^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    logger.warning('Anthropic Messages API model %s failed: %s', m, getattr(e, '__class__', str(e)))
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:54:54,164 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7idzE5kaz6GdgCMhjhp'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    logger.info('Anthropic HTTP body preview: %s', body_preview)
    ^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    logger.warning('Anthropic Messages API model %s failed: %s', m, getattr(e, '__class__', str(e)))
    ^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:54:54,167 INFO No LLM provider available; returning placeholder
2025-12-14 19:54:54,167 INFO No LLM provider available; returning placeholder
2025-12-14 19:54:54,167 INFO Processing question 9
2025-12-14 19:54:54,167 INFO Processing question 9
2025-12-14 19:54:54,168 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:54,168 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:54,192 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:54,192 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:54,192 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:54,192 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:54,700 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:54,701 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:54:55,680 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:54:55,685 INFO LLM (API) provided response for question 3
2025-12-14 19:54:55,685 INFO LLM (API) provided response for question 3
2025-12-14 19:54:55,686 INFO Processing question 4
2025-12-14 19:54:55,686 INFO Processing question 4
2025-12-14 19:54:55,686 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:55,686 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:54:55,718 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:55,718 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:54:55,718 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:55,718 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:54:56,078 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:54:56,079 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:55:02,639 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:02,642 INFO Retrying request to /v1/messages in 11.000000 seconds
2025-12-14 19:55:10,966 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:55:10,973 INFO LLM (API) provided response for question 9
2025-12-14 19:55:10,973 INFO LLM (API) provided response for question 9
2025-12-14 19:55:10,973 INFO Processing question 10
2025-12-14 19:55:10,973 INFO Processing question 10
2025-12-14 19:55:10,973 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:10,973 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:11,002 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:11,002 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:11,003 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:11,003 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:11,328 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:11,328 INFO Retrying request to /v1/messages in 3.000000 seconds
2025-12-14 19:55:14,559 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:14,561 INFO Retrying request to /v1/messages in 11.000000 seconds
2025-12-14 19:55:18,177 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:55:18,181 INFO LLM (API) provided response for question 4
2025-12-14 19:55:18,181 INFO LLM (API) provided response for question 4
2025-12-14 19:55:18,181 INFO Processing question 5
2025-12-14 19:55:18,181 INFO Processing question 5
2025-12-14 19:55:18,182 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:18,182 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:18,213 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:18,213 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:18,213 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:18,213 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:19,610 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:19,611 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:55:26,053 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:26,056 INFO Retrying request to /v1/messages in 12.000000 seconds
2025-12-14 19:55:29,732 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:55:29,737 INFO LLM (API) provided response for question 10
2025-12-14 19:55:29,737 INFO LLM (API) provided response for question 10
2025-12-14 19:55:29,737 INFO Processing question 11
2025-12-14 19:55:29,737 INFO Processing question 11
2025-12-14 19:55:29,738 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:29,738 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:29,763 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:29,763 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:29,763 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:29,763 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:30,040 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:30,041 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 19:55:38,334 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:38,337 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:55:38,337 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:55:38,338 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:55:38,338 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:55:38,514 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:55:38,516 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:55:38,516 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:55:38,519 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:55:38,519 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:55:38,684 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:55:38,686 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:55:38,686 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:55:38,686 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:55:38,686 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:55:38,849 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:55:38,850 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:55:38,850 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:55:38,851 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:55:38,851 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:55:39,037 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:55:39,038 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:55:39,038 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:55:39,039 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7ihTC9N6jdbgmWsubJM'}
2025-12-14 19:55:39,039 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7ihTC9N6jdbgmWsubJM'}
2025-12-14 19:55:39,058 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:39,058 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:39,059 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:39,059 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:39,347 INFO Anthropic HTTP response status: 400
2025-12-14 19:55:39,347 INFO Anthropic HTTP response status: 400
2025-12-14 19:55:39,348 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ihUWmjFMjsBw7rshc2"}
2025-12-14 19:55:39,348 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ihUWmjFMjsBw7rshc2"}
2025-12-14 19:55:39,348 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:55:39,348 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:55:39,348 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:39,348 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:39,624 INFO Anthropic HTTP response status: 400
2025-12-14 19:55:39,624 INFO Anthropic HTTP response status: 400
2025-12-14 19:55:39,624 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ihVjgspNVoJJNXL3Rv"}
2025-12-14 19:55:39,624 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ihVjgspNVoJJNXL3Rv"}
2025-12-14 19:55:39,625 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:55:39,625 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:55:39,629 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:39,629 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:39,942 INFO Anthropic HTTP response status: 400
2025-12-14 19:55:39,942 INFO Anthropic HTTP response status: 400
2025-12-14 19:55:39,943 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ihWy7DFfugJLrWD8Fg"}
2025-12-14 19:55:39,943 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ihWy7DFfugJLrWD8Fg"}
2025-12-14 19:55:39,944 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:55:39,944 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:55:39,946 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:39,946 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:40,205 INFO Anthropic HTTP response status: 400
2025-12-14 19:55:40,205 INFO Anthropic HTTP response status: 400
2025-12-14 19:55:40,205 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ihYEkr3zu4WZxRjsiP"}
2025-12-14 19:55:40,205 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ihYEkr3zu4WZxRjsiP"}
2025-12-14 19:55:40,206 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:55:40,206 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:55:40,209 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:40,209 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 5\n\nAnswer: None\n\nAssistant:"}
2025-12-14 19:55:40,498 INFO Anthropic HTTP response status: 400
2025-12-14 19:55:40,498 INFO Anthropic HTTP response status: 400
2025-12-14 19:55:40,499 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ihZXPxoPxruraB8KRe"}
2025-12-14 19:55:40,499 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ihZXPxoPxruraB8KRe"}
2025-12-14 19:55:40,499 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:55:40,499 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:55:40,503 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7ihTC9N6jdbgmWsubJM'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    body = {
        ^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    import re
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:55:40,503 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7ihTC9N6jdbgmWsubJM'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    body = {
        ^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    import re
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:55:40,507 INFO No LLM provider available; returning placeholder
2025-12-14 19:55:40,507 INFO No LLM provider available; returning placeholder
2025-12-14 19:55:40,507 INFO Processing question 6
2025-12-14 19:55:40,507 INFO Processing question 6
2025-12-14 19:55:40,508 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:40,508 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:40,537 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:40,537 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:40,537 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:40,537 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:40,798 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:40,798 INFO Retrying request to /v1/messages in 9.000000 seconds
2025-12-14 19:55:42,437 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:55:42,440 INFO LLM (API) provided response for question 11
2025-12-14 19:55:42,440 INFO LLM (API) provided response for question 11
2025-12-14 19:55:42,441 INFO Processing question 12
2025-12-14 19:55:42,441 INFO Processing question 12
2025-12-14 19:55:42,441 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:42,441 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:42,469 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:42,469 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:42,469 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:42,469 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:42,772 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:42,773 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:55:50,152 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:50,154 INFO Retrying request to /v1/messages in 12.000000 seconds
2025-12-14 19:55:54,922 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:55:54,927 INFO LLM (API) provided response for question 12
2025-12-14 19:55:54,927 INFO LLM (API) provided response for question 12
2025-12-14 19:55:54,927 INFO Processing question 13
2025-12-14 19:55:54,927 INFO Processing question 13
2025-12-14 19:55:54,928 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:54,928 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:55:54,948 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:54,948 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:55:54,948 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:54,948 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:55:55,306 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:55:55,307 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:56:02,772 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:56:02,776 INFO Retrying request to /v1/messages in 12.000000 seconds
2025-12-14 19:56:07,970 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:56:07,976 INFO LLM (API) provided response for question 6
2025-12-14 19:56:07,976 INFO LLM (API) provided response for question 6
2025-12-14 19:56:07,977 INFO Processing question 7
2025-12-14 19:56:07,977 INFO Processing question 7
2025-12-14 19:56:07,978 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:56:07,978 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:56:08,008 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:56:08,008 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:56:08,008 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:56:08,008 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:56:08,354 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:56:08,355 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:56:15,254 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:56:15,256 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:56:15,256 WARNING Anthropic Messages API model claude-sonnet-4-20250514 failed: <class 'anthropic.RateLimitError'>
2025-12-14 19:56:15,256 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:56:15,256 INFO Trying Anthropic model (Messages API): claude-2
2025-12-14 19:56:15,914 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:56:15,916 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:56:15,916 WARNING Anthropic Messages API model claude-2 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:56:15,916 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:56:15,916 INFO Trying Anthropic model (Messages API): claude-3
2025-12-14 19:56:16,076 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:56:16,078 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:56:16,078 WARNING Anthropic Messages API model claude-3 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:56:16,079 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:56:16,079 INFO Trying Anthropic model (Messages API): claude-instant-v1
2025-12-14 19:56:16,328 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:56:16,328 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:56:16,328 WARNING Anthropic Messages API model claude-instant-v1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:56:16,328 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:56:16,328 INFO Trying Anthropic model (Messages API): claude-instant-1
2025-12-14 19:56:16,552 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 404 Not Found"
2025-12-14 19:56:16,554 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:56:16,554 WARNING Anthropic Messages API model claude-instant-1 failed: <class 'anthropic.NotFoundError'>
2025-12-14 19:56:16,554 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7ikDQG5CQq4VgLiKqAW'}
2025-12-14 19:56:16,554 ERROR Anthropic python client failed; attempting HTTP fallback
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7ikDQG5CQq4VgLiKqAW'}
2025-12-14 19:56:16,558 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:16,558 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "prompt": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:16,558 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:16,558 INFO Anthropic HTTP body preview: {"model": "claude-sonnet-4-20250514", "messages": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:16,892 INFO Anthropic HTTP response status: 400
2025-12-14 19:56:16,892 INFO Anthropic HTTP response status: 400
2025-12-14 19:56:16,892 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ikF5iKqCVhcJxnnqgT"}
2025-12-14 19:56:16,892 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ikF5iKqCVhcJxnnqgT"}
2025-12-14 19:56:16,893 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:56:16,893 WARNING Anthropic HTTP model claude-sonnet-4-20250514 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:56:16,893 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:16,893 INFO Anthropic HTTP body preview: {"model": "claude-2", "messages": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:17,578 INFO Anthropic HTTP response status: 400
2025-12-14 19:56:17,578 INFO Anthropic HTTP response status: 400
2025-12-14 19:56:17,578 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ikGZ1sW9p2zMyjaB32"}
2025-12-14 19:56:17,578 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ikGZ1sW9p2zMyjaB32"}
2025-12-14 19:56:17,578 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:56:17,578 WARNING Anthropic HTTP model claude-2 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:56:17,581 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:17,581 INFO Anthropic HTTP body preview: {"model": "claude-3", "messages": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:17,904 INFO Anthropic HTTP response status: 400
2025-12-14 19:56:17,904 INFO Anthropic HTTP response status: 400
2025-12-14 19:56:17,904 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ikKLSxYcLKMmDiEA5N"}
2025-12-14 19:56:17,904 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ikKLSxYcLKMmDiEA5N"}
2025-12-14 19:56:17,904 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:56:17,904 WARNING Anthropic HTTP model claude-3 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:56:17,907 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:17,907 INFO Anthropic HTTP body preview: {"model": "claude-instant-v1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:18,284 INFO Anthropic HTTP response status: 400
2025-12-14 19:56:18,284 INFO Anthropic HTTP response status: 400
2025-12-14 19:56:18,284 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ikLui15962S58EmpXb"}
2025-12-14 19:56:18,284 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ikLui15962S58EmpXb"}
2025-12-14 19:56:18,285 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:56:18,285 WARNING Anthropic HTTP model claude-instant-v1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:56:18,288 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:18,288 INFO Anthropic HTTP body preview: {"model": "claude-instant-1", "messages": "\n\nHuman:Context: \n\nQuestion: Question 13\n\nAnswer: Sample response 13\n\nAssistant:"}
2025-12-14 19:56:18,618 INFO Anthropic HTTP response status: 400
2025-12-14 19:56:18,618 INFO Anthropic HTTP response status: 400
2025-12-14 19:56:18,619 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ikNXSLEwiZWZvwm8uv"}
2025-12-14 19:56:18,619 INFO Anthropic HTTP response body (preview): {"type":"error","error":{"type":"invalid_request_error","message":"anthropic-version: header is required"},"request_id":"req_011CW7ikNXSLEwiZWZvwm8uv"}
2025-12-14 19:56:18,620 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:56:18,620 WARNING Anthropic HTTP model claude-instant-1 failed: <class 'requests.exceptions.HTTPError'>
2025-12-14 19:56:18,624 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7ikDQG5CQq4VgLiKqAW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    body = {
        ^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    import re
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:56:18,624 ERROR Anthropic API call failed; falling back
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 223, in _call_llm
    return cont
    
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 190, in _call_llm
    resp = client.messages.create(
        model=m,
        messages=[{"role": "user", "content": anth_prompt}],
        max_tokens=max_tokens,
    )
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_utils/_utils.py", line 282, in wrapper
    return func(*args, **kwargs)
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/resources/messages/messages.py", line 930, in create
    return self._post(
           ~~~~~~~~~~^
        "/v1/messages",
        ^^^^^^^^^^^^^^^
    ...<26 lines>...
        stream_cls=Stream[RawMessageStreamEvent],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1326, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1114, in request
    raise self._make_status_error_from_response(err.response) from None
anthropic.NotFoundError: Error code: 404 - {'type': 'error', 'error': {'type': 'not_found_error', 'message': 'model: claude-instant-1'}, 'request_id': 'req_011CW7ikDQG5CQq4VgLiKqAW'}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 290, in _call_llm
    body = {
        ^^^^
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 268, in _call_llm
    import re
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/.venv/lib/python3.13/site-packages/requests/models.py", line 1026, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.anthropic.com/v1/messages
2025-12-14 19:56:18,627 INFO No LLM provider available; returning placeholder
2025-12-14 19:56:18,627 INFO No LLM provider available; returning placeholder
2025-12-14 19:56:18,627 INFO Processing question 14
2025-12-14 19:56:18,627 INFO Processing question 14
2025-12-14 19:56:18,627 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:56:18,627 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:56:18,650 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:56:18,650 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:56:18,650 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:56:18,650 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:56:18,791 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:56:18,794 INFO LLM (API) provided response for question 7
2025-12-14 19:56:18,794 INFO LLM (API) provided response for question 7
2025-12-14 19:56:18,794 INFO Processing question 8
2025-12-14 19:56:18,794 INFO Processing question 8
2025-12-14 19:56:18,794 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:56:18,794 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:56:18,818 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:56:18,818 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:56:18,818 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:56:18,818 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:56:18,990 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:56:18,991 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:56:19,123 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:56:19,124 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:56:26,544 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:56:26,546 INFO Retrying request to /v1/messages in 11.000000 seconds
2025-12-14 19:56:31,988 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:56:31,994 INFO LLM (API) provided response for question 14
2025-12-14 19:56:31,994 INFO LLM (API) provided response for question 14
2025-12-14 19:56:31,994 INFO Processing question 15
2025-12-14 19:56:31,994 INFO Processing question 15
2025-12-14 19:56:31,995 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:56:31,995 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:56:32,026 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:56:32,026 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:56:32,026 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:56:32,026 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:56:32,331 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:56:32,333 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:56:38,749 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:56:38,751 INFO Retrying request to /v1/messages in 11.000000 seconds
2025-12-14 19:56:42,095 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:56:42,100 INFO LLM (API) provided response for question 8
2025-12-14 19:56:42,100 INFO LLM (API) provided response for question 8
2025-12-14 19:56:42,100 INFO Processing question 9
2025-12-14 19:56:42,100 INFO Processing question 9
2025-12-14 19:56:42,101 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:56:42,101 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:56:42,132 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:56:42,132 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:56:42,132 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:56:42,132 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:56:42,446 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:56:42,447 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 19:56:51,083 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:56:51,086 INFO Retrying request to /v1/messages in 11.000000 seconds
2025-12-14 19:56:57,021 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:56:57,049 INFO LLM (API) provided response for question 15
2025-12-14 19:56:57,049 INFO LLM (API) provided response for question 15
2025-12-14 19:56:57,049 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:56:57,049 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:56:57,050 INFO Report generation finished: ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 19:57:07,438 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:57:07,445 INFO LLM (API) provided response for question 9
2025-12-14 19:57:07,445 INFO LLM (API) provided response for question 9
2025-12-14 19:57:07,446 INFO Processing question 10
2025-12-14 19:57:07,446 INFO Processing question 10
2025-12-14 19:57:07,446 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:57:07,446 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:57:07,476 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:57:07,476 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:57:07,476 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:57:07,476 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:57:07,763 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:57:07,764 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:57:17,470 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:57:17,480 INFO LLM (API) provided response for question 10
2025-12-14 19:57:17,480 INFO LLM (API) provided response for question 10
2025-12-14 19:57:17,482 INFO Processing question 11
2025-12-14 19:57:17,482 INFO Processing question 11
2025-12-14 19:57:17,485 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:57:17,485 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:57:17,513 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:57:17,513 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:57:17,513 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:57:17,513 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:57:17,814 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:57:17,817 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 19:57:31,349 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:57:31,388 INFO LLM (API) provided response for question 11
2025-12-14 19:57:31,388 INFO LLM (API) provided response for question 11
2025-12-14 19:57:31,389 INFO Processing question 12
2025-12-14 19:57:31,389 INFO Processing question 12
2025-12-14 19:57:31,389 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:57:31,389 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:57:31,439 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:57:31,439 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:57:31,439 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:57:31,439 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:57:31,714 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:57:31,715 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:57:42,881 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:57:42,886 INFO LLM (API) provided response for question 12
2025-12-14 19:57:42,886 INFO LLM (API) provided response for question 12
2025-12-14 19:57:42,887 INFO Processing question 13
2025-12-14 19:57:42,887 INFO Processing question 13
2025-12-14 19:57:42,887 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:57:42,887 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:57:42,908 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:57:42,908 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:57:42,908 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:57:42,908 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:57:43,175 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:57:43,175 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 19:57:53,711 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:57:53,717 INFO LLM (API) provided response for question 13
2025-12-14 19:57:53,717 INFO LLM (API) provided response for question 13
2025-12-14 19:57:53,717 INFO Processing question 14
2025-12-14 19:57:53,717 INFO Processing question 14
2025-12-14 19:57:53,718 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:57:53,718 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:57:53,748 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:57:53,748 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:57:53,748 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:57:53,748 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:57:54,167 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:57:54,168 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 19:58:07,866 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:58:07,872 INFO LLM (API) provided response for question 14
2025-12-14 19:58:07,872 INFO LLM (API) provided response for question 14
2025-12-14 19:58:07,872 INFO Processing question 15
2025-12-14 19:58:07,872 INFO Processing question 15
2025-12-14 19:58:07,873 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:58:07,873 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:58:07,903 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:58:07,903 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 19:58:07,903 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:58:07,903 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 19:58:08,263 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 19:58:08,265 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 19:58:18,453 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 19:58:18,460 INFO LLM (API) provided response for question 15
2025-12-14 19:58:18,460 INFO LLM (API) provided response for question 15
2025-12-14 19:58:18,461 INFO Wrote analysis to ./llm_analyses/Full context_ My study is about X-llm-analysis.txt
2025-12-14 19:58:18,461 INFO Wrote analysis to ./llm_analyses/Full context_ My study is about X-llm-analysis.txt
2025-12-14 19:58:18,461 INFO Report generation finished: ./llm_analyses/Full context_ My study is about X-llm-analysis.txt
2025-12-14 19:59:28,878 INFO Starting report generation
2025-12-14 19:59:28,879 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 19:59:28,879 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 397, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 19:59:28,883 ERROR LLM pipeline initialization failed; analyses will contain placeholders
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 448, in generate_report
    from transformers import pipeline
ModuleNotFoundError: No module named 'transformers'
2025-12-14 19:59:28,883 INFO Processing question 1
2025-12-14 19:59:28,883 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:59:28,884 INFO No LLM provider available; returning placeholder
2025-12-14 19:59:28,884 INFO Processing question 2
2025-12-14 19:59:28,884 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:59:28,884 INFO No LLM provider available; returning placeholder
2025-12-14 19:59:28,884 INFO Processing question 3
2025-12-14 19:59:28,884 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:59:28,884 INFO No LLM provider available; returning placeholder
2025-12-14 19:59:28,884 INFO Processing question 4
2025-12-14 19:59:28,884 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:59:28,884 INFO No LLM provider available; returning placeholder
2025-12-14 19:59:28,884 INFO Processing question 5
2025-12-14 19:59:28,884 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 19:59:28,884 INFO No LLM provider available; returning placeholder
2025-12-14 19:59:28,884 INFO Wrote analysis to ./llm_analyses/Test Local-llm-analysis.txt
2025-12-14 20:02:22,391 INFO [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2025-12-14 20:02:22,414 INFO [33mPress CTRL+C to quit[0m
2025-12-14 20:02:24,162 INFO Received form responses; launching background generation
2025-12-14 20:02:24,162 INFO Background report generation started
2025-12-14 20:02:24,165 INFO 127.0.0.1 - - [14/Dec/2025 20:02:24] "POST /submit HTTP/1.1" 200 -
2025-12-14 20:02:24,166 INFO Starting report generation
2025-12-14 20:02:24,166 INFO Starting report generation
2025-12-14 20:02:24,166 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 20:02:24,166 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 20:02:24,166 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 397, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 20:02:24,166 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 397, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 20:02:24,167 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 20:02:24,167 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 20:02:24,167 INFO Processing question 1
2025-12-14 20:02:24,167 INFO Processing question 1
2025-12-14 20:02:24,168 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:24,168 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:24,421 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:24,421 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:24,421 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:24,421 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:30,087 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:02:30,105 INFO LLM (API) provided response for question 1
2025-12-14 20:02:30,105 INFO LLM (API) provided response for question 1
2025-12-14 20:02:30,105 INFO Processing question 2
2025-12-14 20:02:30,105 INFO Processing question 2
2025-12-14 20:02:30,105 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,105 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,105 INFO LLM cache hit
2025-12-14 20:02:30,105 INFO LLM cache hit
2025-12-14 20:02:30,106 INFO LLM (API) provided response for question 2
2025-12-14 20:02:30,106 INFO LLM (API) provided response for question 2
2025-12-14 20:02:30,106 INFO Processing question 3
2025-12-14 20:02:30,106 INFO Processing question 3
2025-12-14 20:02:30,106 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,106 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,106 INFO LLM cache hit
2025-12-14 20:02:30,106 INFO LLM cache hit
2025-12-14 20:02:30,106 INFO LLM (API) provided response for question 3
2025-12-14 20:02:30,106 INFO LLM (API) provided response for question 3
2025-12-14 20:02:30,106 INFO Processing question 4
2025-12-14 20:02:30,106 INFO Processing question 4
2025-12-14 20:02:30,106 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,106 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,106 INFO LLM cache hit
2025-12-14 20:02:30,106 INFO LLM cache hit
2025-12-14 20:02:30,106 INFO LLM (API) provided response for question 4
2025-12-14 20:02:30,106 INFO LLM (API) provided response for question 4
2025-12-14 20:02:30,106 INFO Processing question 5
2025-12-14 20:02:30,106 INFO Processing question 5
2025-12-14 20:02:30,106 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,106 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,106 INFO LLM cache hit
2025-12-14 20:02:30,106 INFO LLM cache hit
2025-12-14 20:02:30,106 INFO LLM (API) provided response for question 5
2025-12-14 20:02:30,106 INFO LLM (API) provided response for question 5
2025-12-14 20:02:30,107 INFO Processing question 6
2025-12-14 20:02:30,107 INFO Processing question 6
2025-12-14 20:02:30,107 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,107 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,107 INFO LLM cache hit
2025-12-14 20:02:30,107 INFO LLM cache hit
2025-12-14 20:02:30,107 INFO LLM (API) provided response for question 6
2025-12-14 20:02:30,107 INFO LLM (API) provided response for question 6
2025-12-14 20:02:30,107 INFO Processing question 7
2025-12-14 20:02:30,107 INFO Processing question 7
2025-12-14 20:02:30,107 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,107 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:30,130 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:30,130 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:30,130 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:30,130 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:34,702 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:02:34,706 INFO LLM (API) provided response for question 7
2025-12-14 20:02:34,706 INFO LLM (API) provided response for question 7
2025-12-14 20:02:34,706 INFO Processing question 8
2025-12-14 20:02:34,706 INFO Processing question 8
2025-12-14 20:02:34,707 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:34,707 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:34,733 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:34,733 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:34,733 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:34,733 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:39,763 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:02:39,765 INFO LLM (API) provided response for question 8
2025-12-14 20:02:39,765 INFO LLM (API) provided response for question 8
2025-12-14 20:02:39,765 INFO Processing question 9
2025-12-14 20:02:39,765 INFO Processing question 9
2025-12-14 20:02:39,765 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:39,765 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:39,789 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:39,789 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:39,789 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:39,789 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:44,385 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:02:44,390 INFO LLM (API) provided response for question 9
2025-12-14 20:02:44,390 INFO LLM (API) provided response for question 9
2025-12-14 20:02:44,391 INFO Processing question 10
2025-12-14 20:02:44,391 INFO Processing question 10
2025-12-14 20:02:44,392 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:44,392 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:44,420 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:44,420 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:44,420 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:44,420 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:49,243 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:02:49,247 INFO LLM (API) provided response for question 10
2025-12-14 20:02:49,247 INFO LLM (API) provided response for question 10
2025-12-14 20:02:49,247 INFO Processing question 11
2025-12-14 20:02:49,247 INFO Processing question 11
2025-12-14 20:02:49,247 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:49,247 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:49,274 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:49,274 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:49,274 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:49,274 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:54,541 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:02:54,555 INFO LLM (API) provided response for question 11
2025-12-14 20:02:54,555 INFO LLM (API) provided response for question 11
2025-12-14 20:02:54,555 INFO Processing question 12
2025-12-14 20:02:54,555 INFO Processing question 12
2025-12-14 20:02:54,556 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:54,556 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:54,578 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:54,578 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:54,578 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:54,578 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:58,294 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:02:58,298 INFO LLM (API) provided response for question 12
2025-12-14 20:02:58,298 INFO LLM (API) provided response for question 12
2025-12-14 20:02:58,298 INFO Processing question 13
2025-12-14 20:02:58,298 INFO Processing question 13
2025-12-14 20:02:58,299 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:58,299 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:02:58,329 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:58,329 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:02:58,329 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:58,329 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:02:58,633 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:02:58,635 INFO Retrying request to /v1/messages in 4.000000 seconds
2025-12-14 20:03:08,397 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:03:08,402 INFO LLM (API) provided response for question 13
2025-12-14 20:03:08,402 INFO LLM (API) provided response for question 13
2025-12-14 20:03:08,402 INFO Processing question 14
2025-12-14 20:03:08,402 INFO Processing question 14
2025-12-14 20:03:08,404 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:03:08,404 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:03:08,438 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:03:08,438 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:03:08,438 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:03:08,438 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:03:08,761 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:03:08,762 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 20:03:19,663 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:03:19,667 INFO LLM (API) provided response for question 14
2025-12-14 20:03:19,667 INFO LLM (API) provided response for question 14
2025-12-14 20:03:19,667 INFO Processing question 15
2025-12-14 20:03:19,667 INFO Processing question 15
2025-12-14 20:03:19,668 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:03:19,668 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:03:19,695 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:03:19,695 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:03:19,695 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:03:19,695 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:03:19,977 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:03:19,978 INFO Retrying request to /v1/messages in 6.000000 seconds
2025-12-14 20:03:30,204 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:03:30,211 INFO LLM (API) provided response for question 15
2025-12-14 20:03:30,211 INFO LLM (API) provided response for question 15
2025-12-14 20:03:30,211 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 20:03:30,211 INFO Wrote analysis to ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 20:03:30,212 INFO Report generation finished: ./llm_analyses/Sample response 1-llm-analysis.txt
2025-12-14 20:04:45,851 INFO 127.0.0.1 - - [14/Dec/2025 20:04:45] "GET / HTTP/1.1" 200 -
2025-12-14 20:04:45,888 INFO 127.0.0.1 - - [14/Dec/2025 20:04:45] "[36mGET /static/js/form.js HTTP/1.1[0m" 304 -
2025-12-14 20:04:45,888 INFO 127.0.0.1 - - [14/Dec/2025 20:04:45] "[36mGET /static/css/form.css HTTP/1.1[0m" 304 -
2025-12-14 20:05:26,356 INFO Received form responses; launching background generation
2025-12-14 20:05:26,358 INFO Background report generation started
2025-12-14 20:05:26,360 INFO 127.0.0.1 - - [14/Dec/2025 20:05:26] "POST /submit HTTP/1.1" 200 -
2025-12-14 20:05:26,361 INFO Starting report generation
2025-12-14 20:05:26,361 INFO Starting report generation
2025-12-14 20:05:26,369 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 20:05:26,369 WARNING Could not import vectordb_storage.documents_text: No module named 'PyPDF2'
2025-12-14 20:05:26,369 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 397, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 20:05:26,369 ERROR Could not initialize retrieval stack (faiss/gensim/nltk)
Traceback (most recent call last):
  File "/Users/nihaarikaagarwal/Downloads/moral-compass/llama_rag.py", line 397, in generate_report
    import faiss
ModuleNotFoundError: No module named 'faiss'
2025-12-14 20:05:26,372 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 20:05:26,372 INFO LLM_PROVIDER=anthropic; skipping local transformers pipeline initialization
2025-12-14 20:05:26,374 INFO Processing question 1
2025-12-14 20:05:26,374 INFO Processing question 1
2025-12-14 20:05:26,375 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:26,375 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:26,405 INFO 127.0.0.1 - - [14/Dec/2025 20:05:26] "[36mGET /static/css/submit_success.css HTTP/1.1[0m" 304 -
2025-12-14 20:05:26,455 INFO 127.0.0.1 - - [14/Dec/2025 20:05:26] "GET /reports/status HTTP/1.1" 200 -
2025-12-14 20:05:26,481 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:26,481 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:26,481 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:26,481 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:28,042 INFO 127.0.0.1 - - [14/Dec/2025 20:05:28] "GET /reports/latest HTTP/1.1" 200 -
2025-12-14 20:05:31,260 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:05:31,265 INFO LLM (API) provided response for question 1
2025-12-14 20:05:31,265 INFO LLM (API) provided response for question 1
2025-12-14 20:05:31,265 INFO Processing question 2
2025-12-14 20:05:31,265 INFO Processing question 2
2025-12-14 20:05:31,265 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:31,265 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:31,298 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:31,298 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:31,298 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:31,298 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:34,722 INFO 127.0.0.1 - - [14/Dec/2025 20:05:34] "[36mGET /reports/latest HTTP/1.1[0m" 304 -
2025-12-14 20:05:36,257 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:05:36,261 INFO LLM (API) provided response for question 2
2025-12-14 20:05:36,261 INFO LLM (API) provided response for question 2
2025-12-14 20:05:36,262 INFO Processing question 3
2025-12-14 20:05:36,262 INFO Processing question 3
2025-12-14 20:05:36,262 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:36,262 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:36,294 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:36,294 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:36,294 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:36,294 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:40,368 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:05:40,375 INFO LLM (API) provided response for question 3
2025-12-14 20:05:40,375 INFO LLM (API) provided response for question 3
2025-12-14 20:05:40,376 INFO Processing question 4
2025-12-14 20:05:40,376 INFO Processing question 4
2025-12-14 20:05:40,379 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:40,379 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:40,412 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:40,412 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:40,412 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:40,412 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:44,677 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:05:44,703 INFO LLM (API) provided response for question 4
2025-12-14 20:05:44,703 INFO LLM (API) provided response for question 4
2025-12-14 20:05:44,703 INFO Processing question 5
2025-12-14 20:05:44,703 INFO Processing question 5
2025-12-14 20:05:44,703 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:44,703 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:44,722 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:44,722 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:44,723 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:44,723 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:49,102 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:05:49,106 INFO LLM (API) provided response for question 5
2025-12-14 20:05:49,106 INFO LLM (API) provided response for question 5
2025-12-14 20:05:49,107 INFO Processing question 6
2025-12-14 20:05:49,107 INFO Processing question 6
2025-12-14 20:05:49,107 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:49,107 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:49,140 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:49,140 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:49,140 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:49,140 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:53,258 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:05:53,264 INFO LLM (API) provided response for question 6
2025-12-14 20:05:53,264 INFO LLM (API) provided response for question 6
2025-12-14 20:05:53,264 INFO Processing question 7
2025-12-14 20:05:53,264 INFO Processing question 7
2025-12-14 20:05:53,265 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:53,265 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:05:53,299 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:53,299 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:05:53,299 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:05:53,299 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:01,928 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:06:01,943 INFO LLM (API) provided response for question 7
2025-12-14 20:06:01,943 INFO LLM (API) provided response for question 7
2025-12-14 20:06:01,943 INFO Processing question 8
2025-12-14 20:06:01,943 INFO Processing question 8
2025-12-14 20:06:01,946 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:01,946 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:01,961 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:01,961 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:01,961 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:01,961 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:02,246 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:06:02,246 INFO Retrying request to /v1/messages in 1.000000 seconds
2025-12-14 20:06:07,761 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:06:07,765 INFO LLM (API) provided response for question 8
2025-12-14 20:06:07,765 INFO LLM (API) provided response for question 8
2025-12-14 20:06:07,766 INFO Processing question 9
2025-12-14 20:06:07,766 INFO Processing question 9
2025-12-14 20:06:07,767 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:07,767 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:07,785 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:07,785 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:07,785 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:07,785 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:08,130 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:06:08,130 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 20:06:18,906 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:06:18,914 INFO LLM (API) provided response for question 9
2025-12-14 20:06:18,914 INFO LLM (API) provided response for question 9
2025-12-14 20:06:18,914 INFO Processing question 10
2025-12-14 20:06:18,914 INFO Processing question 10
2025-12-14 20:06:18,916 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:18,916 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:18,948 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:18,948 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:18,948 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:18,948 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:19,260 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:06:19,261 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 20:06:24,188 INFO 127.0.0.1 - - [14/Dec/2025 20:06:24] "[36mGET /reports/latest HTTP/1.1[0m" 304 -
2025-12-14 20:06:24,896 INFO 127.0.0.1 - - [14/Dec/2025 20:06:24] "[36mGET /reports/latest HTTP/1.1[0m" 304 -
2025-12-14 20:06:31,761 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:06:31,775 INFO LLM (API) provided response for question 10
2025-12-14 20:06:31,775 INFO LLM (API) provided response for question 10
2025-12-14 20:06:31,776 INFO Processing question 11
2025-12-14 20:06:31,776 INFO Processing question 11
2025-12-14 20:06:31,776 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:31,776 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:31,803 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:31,803 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:31,803 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:31,803 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:32,098 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:06:32,100 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 20:06:42,991 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:06:43,006 INFO LLM (API) provided response for question 11
2025-12-14 20:06:43,006 INFO LLM (API) provided response for question 11
2025-12-14 20:06:43,007 INFO Processing question 12
2025-12-14 20:06:43,007 INFO Processing question 12
2025-12-14 20:06:43,009 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:43,009 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:43,041 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:43,041 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:43,041 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:43,041 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:43,322 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:06:43,325 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 20:06:55,177 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:06:55,183 INFO LLM (API) provided response for question 12
2025-12-14 20:06:55,183 INFO LLM (API) provided response for question 12
2025-12-14 20:06:55,184 INFO Processing question 13
2025-12-14 20:06:55,184 INFO Processing question 13
2025-12-14 20:06:55,185 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:55,185 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:06:55,216 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:55,216 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:06:55,216 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:55,216 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:06:55,483 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:06:55,484 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 20:07:08,011 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:07:08,021 INFO LLM (API) provided response for question 13
2025-12-14 20:07:08,021 INFO LLM (API) provided response for question 13
2025-12-14 20:07:08,021 INFO Processing question 14
2025-12-14 20:07:08,021 INFO Processing question 14
2025-12-14 20:07:08,022 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:07:08,022 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:07:08,047 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:07:08,047 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:07:08,047 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:07:08,047 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:07:08,328 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:07:08,331 INFO Retrying request to /v1/messages in 7.000000 seconds
2025-12-14 20:07:19,083 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:07:19,095 INFO LLM (API) provided response for question 14
2025-12-14 20:07:19,095 INFO LLM (API) provided response for question 14
2025-12-14 20:07:19,095 INFO Processing question 15
2025-12-14 20:07:19,095 INFO Processing question 15
2025-12-14 20:07:19,096 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:07:19,096 INFO sentence-transformers unavailable; using simple token-count embeddings
2025-12-14 20:07:19,127 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:07:19,127 INFO Wrote Anthropic debug prompt to ./llm_analyses/debug_anthropic_prompt.txt
2025-12-14 20:07:19,128 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:07:19,128 INFO Trying Anthropic model (Messages API): claude-sonnet-4-20250514
2025-12-14 20:07:19,469 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 429 Too Many Requests"
2025-12-14 20:07:19,471 INFO Retrying request to /v1/messages in 8.000000 seconds
2025-12-14 20:07:31,358 INFO HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-12-14 20:07:31,367 INFO LLM (API) provided response for question 15
2025-12-14 20:07:31,367 INFO LLM (API) provided response for question 15
2025-12-14 20:07:31,370 INFO Wrote analysis to ./llm_analyses/Study on AI-assisted Ethical Feedback Tools_-llm-analysis.txt
2025-12-14 20:07:31,370 INFO Wrote analysis to ./llm_analyses/Study on AI-assisted Ethical Feedback Tools_-llm-analysis.txt
2025-12-14 20:07:31,371 INFO Report generation finished: ./llm_analyses/Study on AI-assisted Ethical Feedback Tools_-llm-analysis.txt
2025-12-14 20:09:11,577 INFO 127.0.0.1 - - [14/Dec/2025 20:09:11] "GET /reports/latest HTTP/1.1" 200 -
2025-12-15 16:48:21,083 INFO 127.0.0.1 - - [15/Dec/2025 16:48:21] "[36mGET /reports/latest HTTP/1.1[0m" 304 -
